{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-22T07:31:53.272686Z",
     "start_time": "2025-08-22T07:31:40.002289Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set your environment paths\n",
    "os.environ[\"HF_HOME\"] = \"E:/Python Scripts/recsys\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"E:/Python Scripts/recsys/data\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"E:/Python Scripts/recsys/models\"\n",
    "\n",
    "# os.environ[\"HF_HOME\"] = \"D:/Python Projects/recommendation_system\"\n",
    "# os.environ['HF_DATASETS_CACHE'] = \"D:/Python Projects/recommendation_system/recsys/data\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = \"D:/Python Projects/recommendation_system/recsys/models\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tensorboardX import SummaryWriter"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:51:59.621354Z",
     "start_time": "2025-08-22T07:51:59.608129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Configuration\n",
    "SOURCE_DOMAIN = \"Movies_and_TV\"\n",
    "TARGET_DOMAIN = \"Video_Games\"\n",
    "DOMAINS = [SOURCE_DOMAIN, TARGET_DOMAIN]\n",
    "\n",
    "MIN_USER_INTERACTIONS = 10\n",
    "MIN_ITEM_INTERACTIONS = 10\n",
    "POSITIVE_THRESHOLD = 4.0"
   ],
   "id": "3592ee135b9f5c81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:31:53.388566Z",
     "start_time": "2025-08-22T07:31:53.383073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_amazon_reviews(domain: str, max_per_domain: int = 100000) -> pd.DataFrame:\n",
    "    \"\"\"Load Amazon reviews dataset\"\"\"\n",
    "    dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "                           f\"raw_review_{domain}\",\n",
    "                           trust_remote_code=True)\n",
    "    rows = []\n",
    "    for i, r in enumerate(dataset[\"full\"]):\n",
    "        if i >= max_per_domain:\n",
    "            break\n",
    "        rows.append({\n",
    "            \"user\": r[\"user_id\"],\n",
    "            \"item\": r[\"parent_asin\"],\n",
    "            \"rating\": float(r[\"rating\"]),\n",
    "            \"domain\": domain,\n",
    "            \"verified_purchase\": r[\"verified_purchase\"],\n",
    "            \"timestamp\": int(r[\"timestamp\"])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ],
   "id": "ae16c2312d236d58",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:31:53.410679Z",
     "start_time": "2025-08-22T07:31:53.401362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizedRatingDataset(Dataset):\n",
    "    \"\"\"Optimized dataset that generates negative samples on-the-fly\"\"\"\n",
    "    def __init__(self, df, negatives_dict, num_neg, is_training=True):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.negatives_dict = negatives_dict\n",
    "        self.num_neg = num_neg\n",
    "        self.is_training = is_training\n",
    "        self.users = df['user_id'].values\n",
    "        self.items = df['item_id'].values\n",
    "        self.ratings = df['rating'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_training:\n",
    "            return len(self.df) * (1 + self.num_neg)\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_training:\n",
    "            # For training, generate positive and negative samples\n",
    "            original_idx = idx // (1 + self.num_neg)\n",
    "            sample_type = idx % (1 + self.num_neg)\n",
    "\n",
    "            user = self.users[original_idx]\n",
    "\n",
    "            if sample_type == 0:\n",
    "                # Positive sample\n",
    "                item = self.items[original_idx]\n",
    "                rating = self.ratings[original_idx]\n",
    "            else:\n",
    "                # Negative sample\n",
    "                neg_items = list(self.negatives_dict[user])\n",
    "                item = random.choice(neg_items)\n",
    "                rating = 0.0\n",
    "\n",
    "            return (torch.tensor(user, dtype=torch.long),\n",
    "                   torch.tensor(item, dtype=torch.long),\n",
    "                   torch.tensor(rating, dtype=torch.float))\n",
    "        else:\n",
    "            # For validation/test, return as is\n",
    "            return (torch.tensor(self.users[idx], dtype=torch.long),\n",
    "                   torch.tensor(self.items[idx], dtype=torch.long),\n",
    "                   torch.tensor(self.ratings[idx], dtype=torch.float))\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "    \"\"\"Simple dataset for evaluation\"\"\"\n",
    "    def __init__(self, user_list, item_list, rating_list):\n",
    "        self.user_list = user_list\n",
    "        self.item_list = item_list\n",
    "        self.rating_list = rating_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.user_list[idx], dtype=torch.long),\n",
    "                torch.tensor(self.item_list[idx], dtype=torch.long),\n",
    "                torch.tensor(self.rating_list[idx], dtype=torch.float))"
   ],
   "id": "473a19479a08bec3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:42.629616Z",
     "start_time": "2025-08-22T08:57:42.604602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizedNCFData(object):\n",
    "    def __init__(self, df, num_neg=4, num_neg_test=99, batch_size=1024):\n",
    "        self.df = df\n",
    "        self.num_neg = num_neg\n",
    "        self.num_neg_test = num_neg_test\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Filter users and items with minimum interactions\n",
    "        user_counts = df['user'].value_counts()\n",
    "        item_counts = df['item'].value_counts()\n",
    "\n",
    "        valid_users = user_counts[user_counts >= 10].index\n",
    "        valid_items = item_counts[item_counts >= 10].index\n",
    "\n",
    "        self.df = df[df['user'].isin(valid_users) & df['item'].isin(valid_items)].copy()\n",
    "        print(f\"Filtered dataset: {len(self.df)} interactions, {self.df['user'].nunique()} users, {self.df['item'].nunique()} items\")\n",
    "\n",
    "        self.preprocess_df = self._reindex(self.df)\n",
    "        self.user_pool = set(self.preprocess_df[\"user_id\"].unique())\n",
    "        self.item_pool = set(self.preprocess_df[\"item_id\"].unique())\n",
    "\n",
    "        self.train_df, self.val_df, self.test_df = self._leave_one_out(self.preprocess_df)\n",
    "        self.negatives = self._negative_sampling(self.preprocess_df)\n",
    "\n",
    "    def _reindex(self, df):\n",
    "        \"\"\"Reindex userID and itemID\"\"\"\n",
    "        user_list = list(df[\"user\"].drop_duplicates())\n",
    "        user2id = {w: i for i, w in enumerate(user_list)}\n",
    "        id2user = {i: w for w, i in user2id.items()}\n",
    "\n",
    "        item_list = list(df[\"item\"].drop_duplicates())\n",
    "        item2id = {w: i for i, w in enumerate(item_list)}\n",
    "        id2item = {i: w for w, i in item2id.items()}\n",
    "\n",
    "        # Store the mappings as instance variables\n",
    "        self.user2id = user2id\n",
    "        self.id2user = id2user\n",
    "        self.item2id = item2id\n",
    "        self.id2item = id2item\n",
    "\n",
    "        df[\"user_id\"] = df[\"user\"].apply(lambda x: user2id[x])\n",
    "        df[\"item_id\"] = df[\"item\"].apply(lambda x: item2id[x])\n",
    "        df[\"rating\"] = df[\"rating\"].apply(lambda x: float(x > 0))\n",
    "\n",
    "        self.n_users = len(user2id)\n",
    "        self.n_items = len(item2id)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _leave_one_out(self, df):\n",
    "        \"\"\"Fixed leave-one-out split\"\"\"\n",
    "        df[\"rank_latest\"] = df.groupby([\"user_id\"])[\"timestamp\"].rank(method=\"first\", ascending=False)\n",
    "\n",
    "        # Keep most recent for test, second most recent for validation\n",
    "        test = df.loc[df[\"rank_latest\"] == 1].copy()\n",
    "        val = df.loc[df[\"rank_latest\"] == 2].copy()\n",
    "        train = df.loc[df[\"rank_latest\"] > 2].copy()\n",
    "\n",
    "        # Only keep users that appear in all three sets\n",
    "        common_users = set(train[\"user_id\"].unique()) & set(val[\"user_id\"].unique()) & set(test[\"user_id\"].unique())\n",
    "\n",
    "        train = train[train[\"user_id\"].isin(common_users)]\n",
    "        val = val[val[\"user_id\"].isin(common_users)]\n",
    "        test = test[test[\"user_id\"].isin(common_users)]\n",
    "\n",
    "        print(f\"Split sizes - Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
    "        print(f\"Common users: {len(common_users)}\")\n",
    "\n",
    "        return (train[[\"user_id\", \"item_id\", \"rating\"]],\n",
    "                val[[\"user_id\", \"item_id\", \"rating\"]],\n",
    "                test[[\"user_id\", \"item_id\", \"rating\"]])\n",
    "\n",
    "    def _negative_sampling(self, df):\n",
    "        \"\"\"Create negative sampling dictionary\"\"\"\n",
    "        interact_status = defaultdict(set)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            interact_status[row[\"user_id\"]].add(row[\"item_id\"])\n",
    "\n",
    "        negatives_dict = {}\n",
    "        for user_id in interact_status:\n",
    "            negatives_dict[user_id] = self.item_pool - interact_status[user_id]\n",
    "\n",
    "        self.user_interactions = interact_status  # Store for later use\n",
    "        return negatives_dict\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        \"\"\"Get optimized training data loader\"\"\"\n",
    "        dataset = OptimizedRatingDataset(\n",
    "            self.train_df,\n",
    "            self.negatives,\n",
    "            self.num_neg,\n",
    "            is_training=True\n",
    "        )\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    def get_val_loader(self):\n",
    "        \"\"\"Get validation data loader for evaluation\"\"\"\n",
    "        users, items, ratings = [], [], []\n",
    "\n",
    "        for _, row in self.val_df.iterrows():\n",
    "            user_id = row[\"user_id\"]\n",
    "\n",
    "            # Add positive sample\n",
    "            users.append(user_id)\n",
    "            items.append(row[\"item_id\"])\n",
    "            ratings.append(1.0)\n",
    "\n",
    "            # Add negative samples\n",
    "            neg_items = list(self.negatives[user_id])\n",
    "            sampled_neg = random.sample(neg_items, min(self.num_neg_test, len(neg_items)))\n",
    "\n",
    "            for neg_item in sampled_neg:\n",
    "                users.append(user_id)\n",
    "                items.append(neg_item)\n",
    "                ratings.append(0.0)\n",
    "\n",
    "        dataset = RatingDataset(users, items, ratings)\n",
    "        return DataLoader(dataset, batch_size=self.num_neg_test + 1, shuffle=False)\n",
    "\n",
    "    def get_test_loader(self):\n",
    "        \"\"\"Get test data loader for evaluation\"\"\"\n",
    "        users, items, ratings = [], [], []\n",
    "\n",
    "        for _, row in self.test_df.iterrows():\n",
    "            user_id = row[\"user_id\"]\n",
    "\n",
    "            # Add positive sample\n",
    "            users.append(user_id)\n",
    "            items.append(row[\"item_id\"])\n",
    "            ratings.append(1.0)\n",
    "\n",
    "            # Add negative samples\n",
    "            neg_items = list(self.negatives[user_id])\n",
    "            sampled_neg = random.sample(neg_items, min(self.num_neg_test, len(neg_items)))\n",
    "\n",
    "            for neg_item in sampled_neg:\n",
    "                users.append(user_id)\n",
    "                items.append(neg_item)\n",
    "                ratings.append(0.0)\n",
    "\n",
    "        dataset = RatingDataset(users, items, ratings)\n",
    "        return DataLoader(dataset, batch_size=self.num_neg_test + 1, shuffle=False)"
   ],
   "id": "208c609e71bba0a8",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:43.607870Z",
     "start_time": "2025-08-22T08:57:43.597470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImprovedMatrixFactorization(nn.Module):\n",
    "    \"\"\"Improved MF model with dropout and better initialization\"\"\"\n",
    "    def __init__(self, n_users, n_items, embedding_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Better initialization\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.dropout(self.user_embedding(user_ids))\n",
    "        item_embeds = self.dropout(self.item_embedding(item_ids))\n",
    "\n",
    "        dot_product = (user_embeds * item_embeds).sum(dim=1, keepdim=True)\n",
    "        output = dot_product + self.user_bias(user_ids) + self.item_bias(item_ids) + self.global_bias\n",
    "\n",
    "        return torch.sigmoid(output).squeeze()\n",
    "\n",
    "    def predict_all_items(self, user_id):\n",
    "        \"\"\"Predict scores for all items for a given user\"\"\"\n",
    "        user_tensor = torch.tensor([user_id], dtype=torch.long).to(next(self.parameters()).device)\n",
    "        all_items = torch.arange(self.item_embedding.num_embeddings).to(next(self.parameters()).device)\n",
    "\n",
    "        user_embed = self.user_embedding(user_tensor)\n",
    "        item_embeds = self.item_embedding(all_items)\n",
    "\n",
    "        scores = torch.matmul(user_embed, item_embeds.T).squeeze()\n",
    "        scores += self.user_bias(user_tensor).squeeze()\n",
    "        scores += self.item_bias(all_items).squeeze()\n",
    "        scores += self.global_bias\n",
    "\n",
    "        return torch.sigmoid(scores)"
   ],
   "id": "cdcc0185d16dae6f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:44.379903Z",
     "start_time": "2025-08-22T08:57:44.364883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def precision_at_k(actual, predicted, k):\n",
    "    \"\"\"Calculate Precision@K\"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    return len(set(actual) & set(predicted)) / len(predicted) if len(predicted) > 0 else 0\n",
    "\n",
    "def recall_at_k(actual, predicted, k):\n",
    "    \"\"\"Calculate Recall@K\"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    return len(set(actual) & set(predicted)) / len(actual) if len(actual) > 0 else 0\n",
    "\n",
    "def hit(ng_item, pred_items):\n",
    "    \"\"\"Calculate hit ratio\"\"\"\n",
    "    return 1 if ng_item in pred_items else 0\n",
    "\n",
    "def ndcg(ng_item, pred_items):\n",
    "    \"\"\"Calculate NDCG\"\"\"\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item)\n",
    "        return np.reciprocal(np.log2(index + 2))\n",
    "    return 0\n",
    "\n",
    "def comprehensive_metrics(model, test_loader, k_values, device):\n",
    "    \"\"\"Calculate comprehensive metrics including HR@K, NDCG@K, Precision@K, and Recall@K\"\"\"\n",
    "    metrics_dict = {k: {'HR': [], 'NDCG': [], 'Precision': [], 'Recall': []} for k in k_values}\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user, item, label in test_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "\n",
    "            predictions = model(user, item)\n",
    "\n",
    "            # Get positive item (first one in the batch)\n",
    "            ng_item = item[0].item()\n",
    "\n",
    "            for k in k_values:\n",
    "                _, indices = torch.topk(predictions, min(k, len(predictions)))\n",
    "                recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "                # HR@K and NDCG@K\n",
    "                metrics_dict[k]['HR'].append(hit(ng_item, recommends))\n",
    "                metrics_dict[k]['NDCG'].append(ndcg(ng_item, recommends))\n",
    "\n",
    "                # Precision@K and Recall@K\n",
    "                actual = [ng_item]  # In leave-one-out, we have one positive item\n",
    "                metrics_dict[k]['Precision'].append(precision_at_k(actual, recommends, k))\n",
    "                metrics_dict[k]['Recall'].append(recall_at_k(actual, recommends, k))\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_metrics = {}\n",
    "    for k in k_values:\n",
    "        avg_metrics[k] = {\n",
    "            'HR': np.mean(metrics_dict[k]['HR']),\n",
    "            'NDCG': np.mean(metrics_dict[k]['NDCG']),\n",
    "            'Precision': np.mean(metrics_dict[k]['Precision']),\n",
    "            'Recall': np.mean(metrics_dict[k]['Recall'])\n",
    "        }\n",
    "\n",
    "    return avg_metrics"
   ],
   "id": "c62c67af3001bdd0",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:45.894430Z",
     "start_time": "2025-08-22T08:57:45.886093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_recommendations(model, user_id, data, top_k=10, exclude_interacted=True):\n",
    "    \"\"\"Get top-k recommendations for a user\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model.predict_all_items(user_id)\n",
    "\n",
    "        if exclude_interacted and user_id in data.user_interactions:\n",
    "            # Set scores of already interacted items to -inf\n",
    "            interacted_items = data.user_interactions[user_id]\n",
    "            for item_id in interacted_items:\n",
    "                scores[item_id] = -float('inf')\n",
    "\n",
    "        # Get top-k items\n",
    "        top_scores, top_indices = torch.topk(scores, top_k)\n",
    "\n",
    "        recommendations = []\n",
    "        for idx, score in zip(top_indices.cpu().numpy(), top_scores.cpu().numpy()):\n",
    "            original_item = data.id2item[idx]\n",
    "            recommendations.append({\n",
    "                'item_id': idx,\n",
    "                'item': original_item,\n",
    "                'score': float(score)\n",
    "            })\n",
    "\n",
    "    return recommendations"
   ],
   "id": "9b5210c04e41a365",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:47.397516Z",
     "start_time": "2025-08-22T08:57:47.382467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_training_history(train_losses, val_losses, val_metrics, save_path='training_history.png'):\n",
    "    \"\"\"Plot training history including train/val loss and metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Training History', fontsize=16)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    axes[0, 0].plot(train_losses, label='Training Loss', color='blue')\n",
    "    axes[0, 0].plot(val_losses, label='Validation Loss', color='red')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training vs Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot HR@10\n",
    "    hr_values = [m['HR'] for m in val_metrics]\n",
    "    axes[0, 1].plot(hr_values, label='Val HR@10', color='green', marker='o')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('HR@10')\n",
    "    axes[0, 1].set_title('Validation Hit Rate@10')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot NDCG@10\n",
    "    ndcg_values = [m['NDCG'] for m in val_metrics]\n",
    "    axes[0, 2].plot(ndcg_values, label='Val NDCG@10', color='orange', marker='s')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('NDCG@10')\n",
    "    axes[0, 2].set_title('Validation NDCG@10')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot Precision@10\n",
    "    precision_values = [m['Precision'] for m in val_metrics]\n",
    "    axes[1, 0].plot(precision_values, label='Val Precision@10', color='purple', marker='^')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision@10')\n",
    "    axes[1, 0].set_title('Validation Precision@10')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot Recall@10\n",
    "    recall_values = [m['Recall'] for m in val_metrics]\n",
    "    axes[1, 1].plot(recall_values, label='Val Recall@10', color='brown', marker='v')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall@10')\n",
    "    axes[1, 1].set_title('Validation Recall@10')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot all metrics together for comparison\n",
    "    axes[1, 2].plot(hr_values, label='HR@10', marker='o')\n",
    "    axes[1, 2].plot(ndcg_values, label='NDCG@10', marker='s')\n",
    "    axes[1, 2].plot(precision_values, label='Precision@10', marker='^')\n",
    "    axes[1, 2].plot(recall_values, label='Recall@10', marker='v')\n",
    "    axes[1, 2].set_xlabel('Epoch')\n",
    "    axes[1, 2].set_ylabel('Score')\n",
    "    axes[1, 2].set_title('All Validation Metrics Comparison')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "4d9c48fed30894e9",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:49.631920Z",
     "start_time": "2025-08-22T08:57:49.622354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_metrics_comparison(metrics_dict, save_path='metrics_comparison.png'):\n",
    "    \"\"\"Plot comparison of different metrics at various K values\"\"\"\n",
    "    k_values = list(metrics_dict.keys())\n",
    "    metric_names = ['HR', 'NDCG', 'Precision', 'Recall']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Metrics Comparison at Different K Values', fontsize=16)\n",
    "\n",
    "    for idx, metric in enumerate(metric_names):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        values = [metrics_dict[k][metric] for k in k_values]\n",
    "\n",
    "        bars = ax.bar(range(len(k_values)), values, color=plt.cm.viridis(np.linspace(0.3, 0.9, len(k_values))))\n",
    "        ax.set_xlabel('K')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_title(f'{metric} at Different K Values')\n",
    "        ax.set_xticks(range(len(k_values)))\n",
    "        ax.set_xticklabels([f'K={k}' for k in k_values])\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "c2dde7d0680cb018",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:51.591613Z",
     "start_time": "2025-08-22T08:57:51.583613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_loss(model, data_loader, device):\n",
    "    \"\"\"Calculate average loss for a dataset\"\"\"\n",
    "    model.eval()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user, item, label in data_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            predictions = model(user, item)\n",
    "            loss = loss_fn(predictions, label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "    return total_loss / batch_count if batch_count > 0 else 0\n"
   ],
   "id": "991fe67255777ab5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:53.375770Z",
     "start_time": "2025-08-22T08:57:53.361744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_with_metrics(model, train_loader, val_loader, epochs, device, learning_rate=0.001, weight_decay=1e-5):\n",
    "    \"\"\"Enhanced training loop with comprehensive metrics tracking on validation set\"\"\"\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    best_hr = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_metrics = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training with progress bar\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}') as pbar:\n",
    "            for batch_idx, (user, item, label) in enumerate(pbar):\n",
    "                user = user.to(device)\n",
    "                item = item.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(user, item)\n",
    "                loss = loss_fn(predictions, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        avg_train_loss = total_loss / batch_count\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Calculate validation loss\n",
    "        avg_val_loss = calculate_loss(model, val_loader, device)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Comprehensive evaluation on VALIDATION set\n",
    "        model.eval()\n",
    "        metrics = comprehensive_metrics(model, val_loader, [10], device)\n",
    "        val_metrics.append(metrics[10])\n",
    "\n",
    "        hr = metrics[10]['HR']\n",
    "        ndcg = metrics[10]['NDCG']\n",
    "        precision = metrics[10]['Precision']\n",
    "        recall = metrics[10]['Recall']\n",
    "\n",
    "        # Learning rate scheduling based on validation HR\n",
    "        scheduler.step(hr)\n",
    "\n",
    "        # Logging to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"Metrics/Val_HR@10\", hr, epoch)\n",
    "        writer.add_scalar(\"Metrics/Val_NDCG@10\", ndcg, epoch)\n",
    "        writer.add_scalar(\"Metrics/Val_Precision@10\", precision, epoch)\n",
    "        writer.add_scalar(\"Metrics/Val_Recall@10\", recall, epoch)\n",
    "        writer.add_scalar(\"Learning_Rate\", optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, \"\n",
    "              f\"Val HR@10={hr:.4f}, Val NDCG@10={ndcg:.4f}, \"\n",
    "              f\"Val Prec@10={precision:.4f}, Val Rec@10={recall:.4f}, \"\n",
    "              f\"Time={elapsed_time:.2f}s, LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Save best model based on validation HR\n",
    "        if hr > best_hr:\n",
    "            best_hr = hr\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"  --> New best model saved with Val HR@10={hr:.4f}\")\n",
    "\n",
    "    writer.close()\n",
    "    return train_losses, val_losses, val_metrics, best_hr"
   ],
   "id": "3833eb2bd7c669e5",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:54.517976Z",
     "start_time": "2025-08-22T08:57:54.510114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def final_evaluation(model, test_loader, device):\n",
    "    \"\"\"Perform final evaluation on test set with multiple K values\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    k_values = [5, 10, 20, 50]\n",
    "    metrics = comprehensive_metrics(model, test_loader, k_values, device)\n",
    "\n",
    "    # Create a nice table for results\n",
    "    print(\"\\nMetrics Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'K':<5} {'HR':<10} {'NDCG':<10} {'Precision':<12} {'Recall':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for k in k_values:\n",
    "        print(f\"{k:<5} {metrics[k]['HR']:<10.4f} {metrics[k]['NDCG']:<10.4f} \"\n",
    "              f\"{metrics[k]['Precision']:<12.4f} {metrics[k]['Recall']:<10.4f}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Plot metrics comparison\n",
    "    plot_metrics_comparison(metrics, 'final_metrics_comparison.png')\n",
    "\n",
    "    return metrics"
   ],
   "id": "bea0fa81fa978bbe",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:57:55.243612Z",
     "start_time": "2025-08-22T08:57:55.225080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_sample_recommendations(model, data, num_users=5):\n",
    "    \"\"\"Show sample recommendations for random users\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SAMPLE RECOMMENDATIONS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Get random users\n",
    "    sample_users = random.sample(list(data.user_interactions.keys()), min(num_users, len(data.user_interactions)))\n",
    "\n",
    "    for user_id in sample_users:\n",
    "        original_user = data.id2user[user_id]\n",
    "        print(f\"\\nUser: {original_user} (ID: {user_id})\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # Get user's interaction history (last 5)\n",
    "        user_items = list(data.user_interactions[user_id])[:5]\n",
    "        print(\"Recent interactions:\")\n",
    "        for item_id in user_items:\n",
    "            original_item = data.id2item[item_id]\n",
    "            print(f\"  - {original_item}\")\n",
    "\n",
    "        # Get recommendations\n",
    "        recommendations = get_recommendations(model, user_id, data, top_k=10)\n",
    "        print(\"\\nTop 10 Recommendations:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"  {i}. {rec['item']} (Score: {rec['score']:.4f})\")\n"
   ],
   "id": "82d4e3651fa4b0cf",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T09:02:58.280157Z",
     "start_time": "2025-08-22T09:02:31.881453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = load_amazon_reviews(SOURCE_DOMAIN, max_per_domain=100000)\n",
    "    print(f\"Loaded {len(df)} reviews\")\n",
    "\n",
    "    # Prepare data\n",
    "    print(\"\\nPreparing data...\")\n",
    "    data = OptimizedNCFData(df, num_neg=4, num_neg_test=99, batch_size=2048)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = data.get_train_loader()\n",
    "    val_loader = data.get_val_loader()  # New validation loader\n",
    "    test_loader = data.get_test_loader()\n",
    "\n",
    "    # Model configuration\n",
    "    embedding_dim = 32\n",
    "    epochs = 30\n",
    "    learning_rate = 0.005\n",
    "    weight_decay=0.0\n",
    "\n",
    "    # Create model\n",
    "    model = ImprovedMatrixFactorization(\n",
    "        data.n_users,\n",
    "        data.n_items,\n",
    "        embedding_dim,\n",
    "        dropout=0.2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    print(f\"\\nModel created with {data.n_users} users and {data.n_items} items\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Train model with comprehensive metrics on validation set\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_losses, val_losses, val_metrics, best_hr = train_model_with_metrics(\n",
    "        model, train_loader, val_loader, epochs, DEVICE, learning_rate, weight_decay\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining completed! Best Validation HR@10: {best_hr:.4f}\")\n",
    "\n",
    "    # Plot training history with both losses\n",
    "    plot_training_history(train_losses, val_losses, val_metrics, 'training_history.png')\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    print(\"\\nLoading best model for final evaluation on TEST set...\")\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "    # Final evaluation on test set (unseen data)\n",
    "    final_metrics = final_evaluation(model, test_loader, DEVICE)\n",
    "\n",
    "    # Show sample recommendations\n",
    "    show_sample_recommendations(model, data, num_users=5)\n",
    "\n",
    "    # Save results to file\n",
    "    with open('evaluation_results.txt', 'w') as f:\n",
    "        f.write(\"FINAL TEST SET EVALUATION RESULTS\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Best Validation HR@10: {best_hr:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"Test Set Metrics:\\n\")\n",
    "        f.write(\"-\"*30 + \"\\n\")\n",
    "        for k in final_metrics.keys():\n",
    "            f.write(f\"K={k}:\\n\")\n",
    "            for metric, value in final_metrics[k].items():\n",
    "                f.write(f\"  {metric}: {value:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"All evaluations completed!\")\n",
    "    print(\"Results saved to 'evaluation_results.txt'\")\n",
    "    print(\"Plots saved to 'training_history.png' and 'final_metrics_comparison.png'\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "7ce54fff4fa82b59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 100000 reviews\n",
      "\n",
      "Preparing data...\n",
      "Filtered dataset: 6666 interactions, 1609 users, 749 items\n",
      "Split sizes - Train: 3888, Val: 873, Test: 873\n",
      "Common users: 873\n",
      "\n",
      "Model created with 1609 users and 749 items\n",
      "Model parameters: 77,815\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 10/10 [00:00<00:00, 17.10it/s, loss=0.661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.6770, Val Loss=0.6388, Val HR@10=0.1478, Val NDCG@10=0.0857, Val Prec@10=0.0148, Val Rec@10=0.1478, Time=5.68s, LR=0.005000\n",
      "  --> New best model saved with Val HR@10=0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 10/10 [00:01<00:00,  8.78it/s, loss=0.629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.6421, Val Loss=0.5895, Val HR@10=0.1695, Val NDCG@10=0.0948, Val Prec@10=0.0170, Val Rec@10=0.1695, Time=6.23s, LR=0.005000\n",
      "  --> New best model saved with Val HR@10=0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 10/10 [00:00<00:00, 18.24it/s, loss=0.596]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# Train model with comprehensive metrics on validation set\u001B[39;00m\n\u001B[32m     35\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mStarting training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m train_losses, val_losses, val_metrics, best_hr = \u001B[43mtrain_model_with_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTraining completed! Best Validation HR@10: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_hr\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# Plot training history with both losses\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[43]\u001B[39m\u001B[32m, line 45\u001B[39m, in \u001B[36mtrain_model_with_metrics\u001B[39m\u001B[34m(model, train_loader, val_loader, epochs, device, learning_rate, weight_decay)\u001B[39m\n\u001B[32m     42\u001B[39m train_losses.append(avg_train_loss)\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# Calculate validation loss\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m avg_val_loss = \u001B[43mcalculate_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     46\u001B[39m val_losses.append(avg_val_loss)\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# Comprehensive evaluation on VALIDATION set\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[42]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mcalculate_loss\u001B[39m\u001B[34m(model, data_loader, device)\u001B[39m\n\u001B[32m      6\u001B[39m batch_count = \u001B[32m0\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    733\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    735\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    737\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    739\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    740\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    789\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    791\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    792\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001B[39m, in \u001B[36mdefault_collate\u001B[39m\u001B[34m(batch)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdefault_collate\u001B[39m(batch):\n\u001B[32m    338\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    339\u001B[39m \u001B[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[32m    340\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    396\u001B[39m \u001B[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[32m    397\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    208\u001B[39m transposed = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*batch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransposed\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    208\u001B[39m transposed = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*batch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m--> \u001B[39m\u001B[32m212\u001B[39m         \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[32m    214\u001B[39m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    154\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    157\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001B[39m, in \u001B[36mcollate_tensor_fn\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    270\u001B[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001B[32m    271\u001B[39m     out = elem.new(storage).resize_(\u001B[38;5;28mlen\u001B[39m(batch), *\u001B[38;5;28mlist\u001B[39m(elem.size()))\n\u001B[32m--> \u001B[39m\u001B[32m272\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:31:30.107279Z",
     "start_time": "2025-08-22T08:31:30.091236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralMatrixFactorization(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Matrix Factorization (NMF) model.\n",
    "\n",
    "    This model combines Generalized Matrix Factorization (GMF) to learn linear\n",
    "    interactions and a Multi-Layer Perceptron (MLP) to learn non-linear\n",
    "    interactions between users and items.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_items, gmf_embedding_dim, mlp_embedding_dim, mlp_hidden_layers, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_users (int): Number of unique users.\n",
    "            n_items (int): Number of unique items.\n",
    "            gmf_embedding_dim (int): Embedding dimension for the GMF path.\n",
    "            mlp_embedding_dim (int): Embedding dimension for the MLP path.\n",
    "            mlp_hidden_layers (list of int): A list of hidden layer sizes for the MLP.\n",
    "                                             Example: [64, 32, 16]\n",
    "            dropout (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.gmf_embedding_dim = gmf_embedding_dim\n",
    "        self.mlp_embedding_dim = mlp_embedding_dim\n",
    "\n",
    "        # --- GMF Path ---\n",
    "        self.gmf_user_embedding = nn.Embedding(n_users, gmf_embedding_dim)\n",
    "        self.gmf_item_embedding = nn.Embedding(n_items, gmf_embedding_dim)\n",
    "\n",
    "        # --- MLP Path ---\n",
    "        self.mlp_user_embedding = nn.Embedding(n_users, mlp_embedding_dim)\n",
    "        self.mlp_item_embedding = nn.Embedding(n_items, mlp_embedding_dim)\n",
    "\n",
    "        # Build MLP layers dynamically\n",
    "        mlp_layers = []\n",
    "        input_size = 2 * mlp_embedding_dim # Concatenated user and item embeddings\n",
    "        for size in mlp_hidden_layers:\n",
    "            mlp_layers.append(nn.Linear(input_size, size))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(dropout))\n",
    "            input_size = size\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "        # --- Fusion and Prediction Layer ---\n",
    "        # The final prediction layer takes the concatenated GMF and MLP outputs\n",
    "        fusion_input_size = gmf_embedding_dim + mlp_hidden_layers[-1]\n",
    "        self.predict_layer = nn.Linear(fusion_input_size, 1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initializes weights using Xavier uniform distribution.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.gmf_user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.gmf_item_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.mlp_user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.mlp_item_embedding.weight)\n",
    "\n",
    "        for m in self.mlp.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.predict_layer.weight)\n",
    "        nn.init.zeros_(self.predict_layer.bias)\n",
    "\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # --- GMF Path ---\n",
    "        gmf_user_embeds = self.gmf_user_embedding(user_ids)\n",
    "        gmf_item_embeds = self.gmf_item_embedding(item_ids)\n",
    "        gmf_vector = gmf_user_embeds * gmf_item_embeds\n",
    "\n",
    "        # --- MLP Path ---\n",
    "        mlp_user_embeds = self.mlp_user_embedding(user_ids)\n",
    "        mlp_item_embeds = self.mlp_item_embedding(item_ids)\n",
    "        mlp_input = torch.cat([mlp_user_embeds, mlp_item_embeds], dim=1)\n",
    "        mlp_vector = self.mlp(mlp_input)\n",
    "\n",
    "        # --- Fusion ---\n",
    "        fused_vector = torch.cat([gmf_vector, mlp_vector], dim=1)\n",
    "\n",
    "        # --- Prediction ---\n",
    "        output = self.predict_layer(fused_vector)\n",
    "\n",
    "        return torch.sigmoid(output).squeeze()\n",
    "\n",
    "    def predict_all_items(self, user_id):\n",
    "        \"\"\"Predict scores for all items for a given user.\"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        user_tensor = torch.tensor([user_id], dtype=torch.long, device=device)\n",
    "        all_item_ids = torch.arange(self.n_items, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # --- GMF Path ---\n",
    "            gmf_user_embed = self.gmf_user_embedding(user_tensor)\n",
    "            gmf_item_embeds = self.gmf_item_embedding(all_item_ids)\n",
    "            # Element-wise product by broadcasting the user embedding\n",
    "            gmf_vectors = gmf_user_embed * gmf_item_embeds\n",
    "\n",
    "            # --- MLP Path ---\n",
    "            mlp_user_embed = self.mlp_user_embedding(user_tensor)\n",
    "            # Repeat the user embedding for each item\n",
    "            mlp_user_embeds_repeated = mlp_user_embed.repeat(self.n_items, 1)\n",
    "            mlp_item_embeds = self.mlp_item_embedding(all_item_ids)\n",
    "            mlp_inputs = torch.cat([mlp_user_embeds_repeated, mlp_item_embeds], dim=1)\n",
    "            mlp_vectors = self.mlp(mlp_inputs)\n",
    "\n",
    "            # --- Fusion ---\n",
    "            fused_vectors = torch.cat([gmf_vectors, mlp_vectors], dim=1)\n",
    "\n",
    "            # --- Prediction ---\n",
    "            scores = self.predict_layer(fused_vectors)\n",
    "\n",
    "        return torch.sigmoid(scores).squeeze()"
   ],
   "id": "1c4295479e61408b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T08:55:50.633806Z",
     "start_time": "2025-08-22T08:54:19.915337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = load_amazon_reviews(SOURCE_DOMAIN, max_per_domain=100000)\n",
    "    print(f\"Loaded {len(df)} reviews\")\n",
    "\n",
    "    # Prepare data\n",
    "    print(\"\\nPreparing data...\")\n",
    "    data = OptimizedNCFData(df, num_neg=4, num_neg_test=99, batch_size=2048)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = data.get_train_loader()\n",
    "    val_loader = data.get_val_loader()  # New validation loader\n",
    "    test_loader = data.get_test_loader()\n",
    "\n",
    "    # Model configuration\n",
    "    epochs = 30\n",
    "    learning_rate = 0.005\n",
    "    weight_decay=5e-3\n",
    "\n",
    "    # Create model\n",
    "    model = NeuralMatrixFactorization(\n",
    "        data.n_users,\n",
    "        data.n_items,\n",
    "        gmf_embedding_dim=64,\n",
    "        mlp_embedding_dim=64,\n",
    "        mlp_hidden_layers=[64, 32, 16, 8],\n",
    "        dropout=0.2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    print(f\"\\nModel created with {data.n_users} users and {data.n_items} items\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Train model with comprehensive metrics on validation set\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_losses, val_losses, val_metrics, best_hr = train_model_with_metrics(\n",
    "        model, train_loader, val_loader, epochs, DEVICE, learning_rate, weight_decay\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining completed! Best Validation HR@10: {best_hr:.4f}\")\n",
    "\n",
    "    # Plot training history with both losses\n",
    "    plot_training_history(train_losses, val_losses, val_metrics, 'training_history.png')\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    print(\"\\nLoading best model for final evaluation on TEST set...\")\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "    # Final evaluation on test set (unseen data)\n",
    "    final_metrics = final_evaluation(model, test_loader, DEVICE)\n",
    "\n",
    "    # Show sample recommendations\n",
    "    show_sample_recommendations(model, data, num_users=5)\n",
    "\n",
    "    # Save results to file\n",
    "    with open('evaluation_results.txt', 'w') as f:\n",
    "        f.write(\"FINAL TEST SET EVALUATION RESULTS\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Best Validation HR@10: {best_hr:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"Test Set Metrics:\\n\")\n",
    "        f.write(\"-\"*30 + \"\\n\")\n",
    "        for k in final_metrics.keys():\n",
    "            f.write(f\"K={k}:\\n\")\n",
    "            for metric, value in final_metrics[k].items():\n",
    "                f.write(f\"  {metric}: {value:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"All evaluations completed!\")\n",
    "    print(\"Results saved to 'evaluation_results.txt'\")\n",
    "    print(\"Plots saved to 'training_history.png' and 'final_metrics_comparison.png'\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "98245dbdadc5ca84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 100000 reviews\n",
      "\n",
      "Preparing data...\n",
      "Filtered dataset: 36411 interactions, 6711 users, 7494 items\n",
      "Split sizes - Train: 24122, Val: 4220, Test: 4220\n",
      "Common users: 4220\n",
      "\n",
      "Model created with 6711 users and 7494 items\n",
      "Model parameters: 1,829,313\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 59/59 [00:11<00:00,  4.98it/s, loss=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.5913, Val Loss=0.2866, Val HR@10=0.1555, Val NDCG@10=0.0790, Val Prec@10=0.0155, Val Rec@10=0.1555, Time=37.60s, LR=0.005000\n",
      "  --> New best model saved with Val HR@10=0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 59/59 [00:11<00:00,  5.11it/s, loss=0.522]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 37\u001B[39m\n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# Train model with comprehensive metrics on validation set\u001B[39;00m\n\u001B[32m     36\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mStarting training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m train_losses, val_losses, val_metrics, best_hr = \u001B[43mtrain_model_with_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTraining completed! Best Validation HR@10: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_hr\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# Plot training history with both losses\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 50\u001B[39m, in \u001B[36mtrain_model_with_metrics\u001B[39m\u001B[34m(model, train_loader, val_loader, epochs, device, learning_rate, weight_decay)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# Comprehensive evaluation on VALIDATION set\u001B[39;00m\n\u001B[32m     49\u001B[39m model.eval()\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m metrics = \u001B[43mcomprehensive_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m val_metrics.append(metrics[\u001B[32m10\u001B[39m])\n\u001B[32m     53\u001B[39m hr = metrics[\u001B[32m10\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mHR\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mcomprehensive_metrics\u001B[39m\u001B[34m(model, test_loader, k_values, device)\u001B[39m\n\u001B[32m     29\u001B[39m model.eval()\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m        \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    733\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    735\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    737\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    739\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    740\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    789\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    791\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    792\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001B[39m, in \u001B[36mdefault_collate\u001B[39m\u001B[34m(batch)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdefault_collate\u001B[39m(batch):\n\u001B[32m    338\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    339\u001B[39m \u001B[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[32m    340\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    396\u001B[39m \u001B[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[32m    397\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    208\u001B[39m transposed = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*batch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransposed\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    208\u001B[39m transposed = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*batch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m--> \u001B[39m\u001B[32m212\u001B[39m         \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[32m    214\u001B[39m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    154\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    157\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001B[39m, in \u001B[36mcollate_tensor_fn\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    270\u001B[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001B[32m    271\u001B[39m     out = elem.new(storage).resize_(\u001B[38;5;28mlen\u001B[39m(batch), *\u001B[38;5;28mlist\u001B[39m(elem.size()))\n\u001B[32m--> \u001B[39m\u001B[32m272\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "366dd2ab33406b95"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
