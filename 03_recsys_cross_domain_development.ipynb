{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cross-Domain Recommendation System Development\n",
    "This notebook is an experiment in building a cross-domain recommendation system using the Amazon Reviews dataset. It uses the best model from the single-domain experiments and extends it to handle multiple domains. The dataset is the same as in the single-domain experiments, but now will combine data from two different domains."
   ],
   "id": "f897965258465d1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T05:24:54.876509Z",
     "start_time": "2025-08-28T05:24:46.915711Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# os.environ[\"HF_HOME\"] = \"D:/Python Projects/recommendation_system\"\n",
    "# os.environ[\"HF_DATASETS_CACHE\"] = \"D:/Python Projects/recommendation_system/recsys/data\"\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/Python Projects/recommendation_system/recsys/models\"\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"E:/Python Scripts/recsys\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"E:/Python Scripts/recsys/data\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"E:/Python Scripts/recsys/models\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import load_dataset, Features, Value\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:24:55.013377Z",
     "start_time": "2025-08-28T05:24:54.936525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)"
   ],
   "id": "7c34635975b115fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single-domain development on best model (SASRec)",
   "id": "f50b5b1c0a2ae4cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:24:55.141115Z",
     "start_time": "2025-08-28T05:24:55.112739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HF_DATASET = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "\n",
    "def load_amazon_reviews(domain, save_dir=\"data\", max_items=None, seed=SEED):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filepath = f\"{save_dir}/amazon_reviews_{domain}.csv\"\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {filepath} not found. Downloading dataset for domain '{domain}'...\")\n",
    "        ds = load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "            f\"raw_review_{domain}\",\n",
    "            split=\"full\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        # Keep only needed columns\n",
    "        ds = ds.select_columns([\"user_id\", \"parent_asin\", \"rating\", \"timestamp\"])\n",
    "        ds = ds.rename_columns({\"user_id\": \"user\", \"parent_asin\": \"item\"})\n",
    "        ds = ds.cast(Features({\n",
    "            \"user\": Value(\"string\"),\n",
    "            \"item\": Value(\"string\"),\n",
    "            \"rating\": Value(\"float32\"),\n",
    "            \"timestamp\": Value(\"int64\"),\n",
    "        }))\n",
    "\n",
    "        # Convert to pandas (Arrow zero-copy where possible)\n",
    "        df = ds.to_pandas()\n",
    "        df.insert(3, \"domain\", domain)\n",
    "        df.to_csv(f\"{save_dir}/amazon_reviews_{domain}.csv\", index=False)\n",
    "        print(f\"Saved amazon_reviews_{domain}.csv to {save_dir}/\")\n",
    "\n",
    "    final_df = pd.read_csv(filepath)\n",
    "    # Random subset if max_items is set\n",
    "    if max_items is not None:\n",
    "        k = min(max_items, len(final_df))\n",
    "        final_df = final_df.sample(n=k, random_state=seed).reset_index(drop=True)\n",
    "    print(f\"Loaded {filepath} with {len(final_df)} rows.\")\n",
    "    return final_df\n",
    "\n",
    "def preprocess_dataset(df, min_user_interactions=5, min_item_interactions=5):\n",
    "    # Make it implicit\n",
    "    df[\"label\"] = 1.0\n",
    "    user_counts = df.groupby(\"user\").size()\n",
    "    valid_users = user_counts[user_counts >= min_user_interactions].index\n",
    "    item_counts = df.groupby(\"item\").size()\n",
    "    valid_items = item_counts[item_counts >= min_item_interactions].index\n",
    "    df_filtered = df[df[\"user\"].isin(valid_users) & df[\"item\"].isin(valid_items)]\n",
    "    print(\"After interactions filtering:\", len(df_filtered), \"rows,\", df_filtered[\"user\"].nunique(), \"users,\", df_filtered[\"item\"].nunique(), \"items\")\n",
    "    return df_filtered\n",
    "\n",
    "def label_encoder(df, shift_item_id=False):\n",
    "    df_encoded = df.copy()\n",
    "    user_enc = LabelEncoder()\n",
    "    item_enc = LabelEncoder()\n",
    "    domain_enc = LabelEncoder()\n",
    "    df_encoded[\"user_id\"] = user_enc.fit_transform(df_encoded[\"user\"])\n",
    "    df_encoded[\"item_id\"] = item_enc.fit_transform(df_encoded[\"item\"])\n",
    "    if shift_item_id:\n",
    "        df_encoded[\"item_id\"] = df_encoded[\"item_id\"] + 1  # Shift item IDs by 1 to reserve 0 for padding if needed\n",
    "    df_encoded[\"domain_id\"] = domain_enc.fit_transform(df_encoded[\"domain\"])\n",
    "    return df_encoded, user_enc, item_enc, domain_enc"
   ],
   "id": "fea6ebca4ab2462c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset preparation",
   "id": "48521a298928c450"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.311256Z",
     "start_time": "2025-08-28T05:24:55.172100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New input\n",
    "SOURCE_DOMAIN = \"Books\"\n",
    "\n",
    "# Loading data from multiple domains\n",
    "df = load_amazon_reviews(SOURCE_DOMAIN, max_items=2_000_000, seed=SEED)\n",
    "print(f\"Total rows in {SOURCE_DOMAIN}: {len(df)}\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "filtered_df = preprocess_dataset(df, min_user_interactions=5, min_item_interactions=5)\n",
    "df_encoded, user_encoder, item_encoder, domain_encoder = label_encoder(filtered_df, shift_item_id=True)\n",
    "\n",
    "NUM_USERS = df_encoded[\"user_id\"].max() + 1\n",
    "NUM_ITEMS = df_encoded[\"item_id\"].max() + 1\n",
    "print(f\"Number of users: {NUM_USERS}, Number of items: {NUM_ITEMS}\")"
   ],
   "id": "872713bce3008a2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/amazon_reviews_Books.csv with 4000000 rows.\n",
      "Total rows in Books: 4000000\n",
      "After interactions filtering: 28280 rows, 5004 users, 10350 items\n",
      "Number of users: 5004, Number of items: 10351\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.584023Z",
     "start_time": "2025-08-28T05:25:43.430273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_user_sequences(df):\n",
    "    df_sorted = df.sort_values([\"user_id\", \"timestamp\"])\n",
    "    user_sequences = {}\n",
    "    for uid, group in df_sorted.groupby(\"user_id\"):\n",
    "        items = group[\"item_id\"].tolist()\n",
    "        user_sequences[uid] = items\n",
    "\n",
    "    print(f\"Number of users: {len(user_sequences)}\")\n",
    "    print(f\"Max sequence length: {max(len(seq) for seq in user_sequences.values())}\")\n",
    "    print(f\"Min sequence length: {min(len(seq) for seq in user_sequences.values())}\")\n",
    "\n",
    "    return user_sequences\n",
    "\n",
    "# Create sequences\n",
    "user_sequences = create_user_sequences(df_encoded)\n",
    "pos_items_by_user = {u: set(seq) for u, seq in user_sequences.items()}"
   ],
   "id": "ca58a698977746d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 5004\n",
      "Max sequence length: 70\n",
      "Min sequence length: 1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.610300Z",
     "start_time": "2025-08-28T05:25:43.599010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequences_loo_split(user_sequences):\n",
    "    train_seqs = {}\n",
    "    val_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for user, seq in user_sequences.items():\n",
    "        if len(seq) < 3:  # Need at least 3 items for train/val/test\n",
    "            continue\n",
    "\n",
    "        train_seqs[user] = seq[:-2]  # All but last two\n",
    "        val_data[user] = (seq[:-2], seq[-2])  # Train on all but last 2, predict second-to-last\n",
    "        test_data[user] = (seq[:-1], seq[-1])  # Train on all but last, predict last\n",
    "\n",
    "    print(f\"Training sequences: {len(train_seqs)}\")\n",
    "    print(f\"Validation users: {len(val_data)}\")\n",
    "    print(f\"Test users: {len(test_data)}\")\n",
    "\n",
    "    return train_seqs, val_data, test_data\n",
    "\n",
    "train_sequences, val_sequences, test_sequences = sequences_loo_split(user_sequences)\n",
    "print(f\"Sequences - Train: {len(train_sequences)}, Val: {len(val_sequences)}, Test: {len(test_sequences)}\")"
   ],
   "id": "f25ac4008c7f94b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences: 3264\n",
      "Validation users: 3264\n",
      "Test users: 3264\n",
      "Sequences - Train: 3264, Val: 3264, Test: 3264\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset and DataLoader",
   "id": "f04c70046f9e7ad2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.793010Z",
     "start_time": "2025-08-28T05:25:43.618295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SASRecDataset(Dataset):\n",
    "    def __init__(self, data, num_items, max_seq_len=50, pos_items_by_user=None, mode=\"train\", neg_samples=1):\n",
    "        self.num_items = num_items\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.mode = mode\n",
    "        self.neg_samples = neg_samples\n",
    "        self.all_pos = pos_items_by_user\n",
    "\n",
    "        self.samples = []\n",
    "        if mode == \"train\":\n",
    "            for user, seq in data.items():\n",
    "                for i in range(1, len(seq)):\n",
    "                    self.samples.append({\n",
    "                        \"user\": user,\n",
    "                        \"input_seq\": seq[:i],\n",
    "                        \"target\": seq[i],\n",
    "                        \"full_seq\": seq # For negative sampling\n",
    "                    })\n",
    "        else:\n",
    "            for user, (seq, target) in data.items():\n",
    "                self.samples.append({\n",
    "                    \"user\": user,\n",
    "                    \"input_seq\": seq,\n",
    "                    \"target\": target,\n",
    "                    \"full_seq\": seq + [target]\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        user = sample[\"user\"]\n",
    "        seq = sample[\"input_seq\"]\n",
    "        target = sample[\"target\"]\n",
    "\n",
    "        # Truncate sequence if > max length\n",
    "        if len(seq) > self.max_seq_len:\n",
    "            seq = seq[-self.max_seq_len:]\n",
    "\n",
    "        # Left-pad sequence with zeros\n",
    "        pad_len = self.max_seq_len - len(seq)\n",
    "        padded_seq = [0] * pad_len + seq\n",
    "\n",
    "        # Negative sampling\n",
    "        forbid = self.all_pos[user] if self.all_pos is not None else set(sample[\"full_seq\"])\n",
    "        neg_items = set()\n",
    "\n",
    "        while len(neg_items) < self.neg_samples:\n",
    "            neg = random.randint(1, self.num_items - 1)\n",
    "            if neg not in forbid:\n",
    "                neg_items.add(neg)\n",
    "\n",
    "        return {\n",
    "            \"user\": sample[\"user\"],\n",
    "            \"input_seq\": torch.tensor(padded_seq, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target, dtype=torch.long),\n",
    "            \"neg_items\": torch.tensor(list(neg_items), dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SASRecDataset(train_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"train\", neg_samples=1)\n",
    "val_dataset = SASRecDataset(val_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"val\", neg_samples=99)\n",
    "test_dataset = SASRecDataset(test_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"test\", neg_samples=99)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "c96da4897f52535c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 15943\n",
      "Validation samples: 3264\n",
      "Test samples: 3264\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.808333Z",
     "start_time": "2025-08-28T05:25:43.803528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data loaders\n",
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "7716857aa0a90ebd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.936352Z",
     "start_time": "2025-08-28T05:25:43.824867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = next(iter(train_loader))\n",
    "print(\"Sample batch from loader:\")\n",
    "print(\"Input sequence shape:\", first[\"input_seq\"].shape)\n",
    "print(\"Target shape:\", first[\"target\"].shape)\n",
    "print(\"Negative items shape:\", first[\"neg_items\"].shape)\n",
    "\n",
    "print(\"\\nSample input sequence:\")\n",
    "random_index = []\n",
    "for _ in range(5):\n",
    "    random_index.append(random.randint(0, len(train_loader) - 1))\n",
    "\n",
    "for i in random_index:\n",
    "    print(first[\"input_seq\"][i])"
   ],
   "id": "9cf8d7b1e3a87a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch from loader:\n",
      "Input sequence shape: torch.Size([4096, 50])\n",
      "Target shape: torch.Size([4096])\n",
      "Negative items shape: torch.Size([4096, 1])\n",
      "\n",
      "Sample input sequence:\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,  138,  192, 2540, 4239, 5030, 2547,\n",
      "         746, 3104])\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0, 1265, 5146, 3114,\n",
      "        3274, 1592])\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0, 6842, 8295, 7585, 2112, 8768,\n",
      "        8013, 7597])\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0, 7791, 7862, 7917, 7330, 8129, 1997, 8485, 8766, 7277, 9031,\n",
      "        9397,  666])\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0, 6842, 8295, 7585, 2112, 8768,\n",
      "        8013, 7597])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create SASRec model",
   "id": "ee51311214a572b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.967305Z",
     "start_time": "2025-08-28T05:25:43.954343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Building SASRec model\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(self.dropout(self.relu(self.w1(x))))\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Layer norms\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Feed-forward network\n",
    "        self.ffn = PointWiseFeedForward(hidden_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # Self-attention with residual connection\n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=attn_mask)\n",
    "        x = self.ln1(x + self.dropout(attn_out))\n",
    "\n",
    "        # Feed-forward network with residual connection\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.ln2(x + self.dropout(ffn_out))\n",
    "\n",
    "        return x\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_items,\n",
    "                 hidden_dim=64,\n",
    "                 max_seq_len=50,\n",
    "                 num_blocks=2,\n",
    "                 num_heads=2,\n",
    "                 dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_items = num_items\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # Embedding layers\n",
    "        self.item_embed = nn.Embedding(num_items, hidden_dim, padding_idx=0)\n",
    "        self.positional_embed = nn.Embedding(max_seq_len, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Stack of SASRec blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            AttentionBlock(hidden_dim, num_heads, dropout) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        # Final layer norm\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_normal_(self.item_embed.weight[1:])  # Skip padding idx\n",
    "        nn.init.xavier_normal_(self.positional_embed.weight)\n",
    "\n",
    "    def forward(self, input_seq, candidate_items=None):\n",
    "        batch_size, seq_len = input_seq.shape\n",
    "\n",
    "        # Get item embeddings\n",
    "        item_embeds = self.item_embed(input_seq)  # [B, L, D]\n",
    "\n",
    "        # Add positional embeddings\n",
    "        positions = torch.arange(seq_len, device=input_seq.device).unsqueeze(0)\n",
    "        pos_embeds = self.positional_embed(positions)  # [1, L, D]\n",
    "        x = self.dropout(item_embeds + pos_embeds)\n",
    "\n",
    "        # Create causal attention mask\n",
    "        attn_mask = self._create_causal_mask(seq_len, input_seq.device)\n",
    "        pad_mask = input_seq.eq(0)\n",
    "\n",
    "        # Pass through transformer blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        # Final layer norm\n",
    "        x = self.ln(x)  # [B, L, D]\n",
    "        x = x.masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "\n",
    "        # If candidate_items provided, score them\n",
    "        if candidate_items is not None:\n",
    "            # Get embeddings for candidate items\n",
    "            cand_emb = self.item_embed(candidate_items) # [B, N, D]\n",
    "\n",
    "            # Use last position's representation for scoring\n",
    "            last_hidden = x[:, -1, :].unsqueeze(1)  # [B, 1, D]\n",
    "\n",
    "            # Compute scores via dot product\n",
    "            scores = torch.matmul(last_hidden, cand_emb.transpose(1, 2)).squeeze(1) # [B, N]\n",
    "            return scores\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _create_causal_mask(self, seq_len, device):\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=device, dtype=torch.bool), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float(\"-inf\"))\n",
    "        return mask\n",
    "\n",
    "    def predict_next(self, input_seq):\n",
    "        # Get sequence representations\n",
    "        seq_repr = self.forward(input_seq)  # [B, L, D]\n",
    "\n",
    "        # Use last position for prediction\n",
    "        last_hidden = seq_repr[:, -1, :]  # [B, D]\n",
    "\n",
    "        # Score against all item embeddings\n",
    "        all_item_embeds = self.item_embed.weight  # [num_items, D]\n",
    "        scores = torch.matmul(last_hidden, all_item_embeds.T)  # [B, num_items]\n",
    "        return scores"
   ],
   "id": "6af96d98ee3a7051",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and evaluation functions",
   "id": "126fb73d3965ec4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:43.984828Z",
     "start_time": "2025-08-28T05:25:43.975303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_sasrec_epoch(model, train_loader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        input_seq = batch[\"input_seq\"].to(device)\n",
    "        pos_items = batch[\"target\"].to(device)\n",
    "        neg_items = batch[\"neg_items\"].to(device)\n",
    "\n",
    "        # Get predictions for last position\n",
    "        seq_output = model(input_seq)  # [B, L, D]\n",
    "        last_hidden = seq_output[:, -1, :]  # [B, D]\n",
    "\n",
    "        # Get embeddings for positive and negative items\n",
    "        pos_embeds = model.item_embed(pos_items)\n",
    "        neg_embeds = model.item_embed(neg_items)\n",
    "\n",
    "        # Compute logits\n",
    "        pos_logits = (last_hidden * pos_embeds).sum(dim=1)\n",
    "        neg_logits = torch.bmm(neg_embeds, last_hidden.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Binary cross-entropy loss with logits\n",
    "        pos_labels = torch.ones_like(pos_logits)\n",
    "        neg_labels = torch.zeros_like(neg_logits)\n",
    "\n",
    "        # Concatenate logits and labels\n",
    "        all_logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)\n",
    "        all_labels = torch.cat([pos_labels.unsqueeze(1), neg_labels], dim=1)\n",
    "\n",
    "        loss = loss_fn(all_logits, all_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches"
   ],
   "id": "89794d62607239d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:44.000878Z",
     "start_time": "2025-08-28T05:25:43.991820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validation loss and ranking metrics\n",
    "@torch.no_grad()\n",
    "def evaluate_sasrec(model, eval_loader, loss_fn, k=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_hr = 0.0\n",
    "    sum_ndcg = 0.0\n",
    "    sum_prec = 0.0\n",
    "    sum_mrr = 0.0\n",
    "\n",
    "    sum_val_loss = 0.0\n",
    "    n_loss_batches = 0\n",
    "\n",
    "    for batch in tqdm(eval_loader, desc=\"Evaluating\"):\n",
    "        input_seq = batch[\"input_seq\"].to(device)\n",
    "        target = batch[\"target\"].to(device)\n",
    "        neg_items = batch[\"neg_items\"].to(device)\n",
    "\n",
    "        batch_size = input_seq.size(0)\n",
    "\n",
    "        # Create candidate set: 1 positive + negatives\n",
    "        seq_output = model(input_seq)  # [B, L, D]\n",
    "        last_hidden = seq_output[:, -1, :]  # [B, D]\n",
    "        candidates = torch.cat([\n",
    "            target.unsqueeze(1),  # [B, 1]\n",
    "            neg_items  # [B, neg_samples]\n",
    "        ], dim=1)  # [B, 1 + neg_samples]\n",
    "\n",
    "        # Get embeddings for all candidates\n",
    "        cand_emb = model.item_embed(candidates)  # [B, 1+neg_samples, D]\n",
    "        scores = torch.bmm(cand_emb, last_hidden.unsqueeze(-1)).squeeze(-1)  # [B, 1+neg_samples]\n",
    "\n",
    "        # sanity: positive not in negatives\n",
    "        if torch.any((candidates[:, 1:] == target.unsqueeze(1)).any(dim=1)):\n",
    "            raise RuntimeError(\"Positive item appeared in negatives for some samples.\")\n",
    "\n",
    "        # Loss calculation\n",
    "        pos_scores = scores[:, 0]\n",
    "        neg_scores = scores[:, 1:]\n",
    "        pos_labels = torch.ones_like(scores[:, 0])\n",
    "        neg_labels = torch.zeros_like(scores[:, 1:])\n",
    "        all_scores = torch.cat([pos_scores.unsqueeze(1), neg_scores], dim=1)\n",
    "        all_labels = torch.cat([pos_labels.unsqueeze(1), neg_labels], dim=1)\n",
    "        batch_loss = loss_fn(all_scores.reshape(-1), all_labels.reshape(-1))\n",
    "        sum_val_loss += batch_loss.item()\n",
    "        n_loss_batches += 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        _, full_idx = torch.sort(scores, dim=1, descending=True)\n",
    "        rank  = (full_idx == 0).nonzero(as_tuple=True)[1] + 1  # Rank of the positive item (1-based)\n",
    "\n",
    "        hit = (rank <= k).float()\n",
    "        ndcg = torch.where(rank <= k, 1.0 / torch.log2(rank.float() + 1), torch.zeros_like(hit))\n",
    "        precision = hit / float(k)\n",
    "        mrr = torch.where(rank <= k, 1.0 / rank.float(), torch.zeros_like(hit))\n",
    "\n",
    "        sum_hr += hit.sum().item()\n",
    "        sum_ndcg += ndcg.sum().item()\n",
    "        sum_prec += precision.sum().item()\n",
    "        sum_mrr += mrr.sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    metrics = {\n",
    "        \"HR@K\": sum_hr / total if total else 0.0,\n",
    "        \"NDCG@K\": sum_ndcg / total if total else 0.0,\n",
    "        \"Precision@K\": sum_prec / total if total else 0.0,\n",
    "        \"MRR@K\": sum_mrr / total if total else 0.0,\n",
    "        \"Val loss\": sum_val_loss / max(n_loss_batches, 1)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "id": "206c2ec3b34e4147",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:25:44.016935Z",
     "start_time": "2025-08-28T05:25:44.008875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sasrec_trainer(\n",
    "        model,\n",
    "        train_loader,\n",
    "        eval_loader,\n",
    "        epochs,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        k=10,\n",
    "        device=\"cpu\",\n",
    "        save_dir=\"model\"\n",
    "    ):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.to(device)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    train_losses, val_losses, val_metrics_log = [], [], []\n",
    "    best_ndcg, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Train (batched)\n",
    "        train_loss = train_sasrec_epoch(model, train_loader, loss_fn, optimizer, device=device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Eval (batched)\n",
    "        m = evaluate_sasrec(model, eval_loader, loss_fn, k=k, device=device)\n",
    "        val_losses.append(m[\"Val loss\"])\n",
    "        val_metrics_log.append({k_: m[k_] for k_ in [\"HR@K\", \"NDCG@K\", \"Precision@K\", \"MRR@K\"]})\n",
    "\n",
    "        # Checkpointing by NDCG\n",
    "        if m[\"NDCG@K\"] > best_ndcg:\n",
    "            best_ndcg = m[\"NDCG@K\"]\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_model_src.pth\"))\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"last_model_src.pth\"))\n",
    "\n",
    "        # TB logs\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", m[\"Val loss\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_HR@{k}\", m[\"HR@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_NDCG@{k}\", m[\"NDCG@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_Precision@{k}\", m[\"Precision@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_MRR@{k}\", m[\"MRR@K\"], epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}  \"\n",
    "            f\"Train loss {train_loss:.4f}  \"\n",
    "            f\"Val loss {m['Val loss']:.4f}  \"\n",
    "            f\"HR@{k} {m['HR@K']:.4f}  \"\n",
    "            f\"NDCG@{k} {m['NDCG@K']:.4f}  \"\n",
    "            f\"Precision@{k} {m['Precision@K']:.4f}  \"\n",
    "            f\"MRR@{k} {m['MRR@K']:.4f}  \"\n",
    "            f\"{'(new best)' if m['NDCG@K'] == best_ndcg and best_epoch==epoch+1 else ''}  \"\n",
    "            f\"Time {time.time()-t0:.2f}s\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nTraining Complete.\")\n",
    "    print(f\"Best epoch: {best_epoch} with NDCG@{k}: {best_ndcg:.4f}\\n\")\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    writer.close()\n",
    "    return train_losses, val_losses, val_metrics_log, best_ndcg"
   ],
   "id": "2cb1cd31cab2153b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model",
   "id": "2199dc5aecc7393a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:26:17.715859Z",
     "start_time": "2025-08-28T05:25:44.024934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters from the original paper, except higher hidden_dim\n",
    "sasrec = SASRec(\n",
    "    num_items=NUM_ITEMS,\n",
    "    hidden_dim=64,\n",
    "    max_seq_len=50,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "loss_fn_sasrec = nn.BCEWithLogitsLoss()\n",
    "optimizer_sasrec = torch.optim.Adam(sasrec.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "train_losses_sasrec, val_losses_sasrec, val_metrics_sasrec, best_ndcg_sasrec = sasrec_trainer(\n",
    "    model=sasrec,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=val_loader,\n",
    "    loss_fn=loss_fn_sasrec,\n",
    "    optimizer=optimizer_sasrec,\n",
    "    epochs=20,\n",
    "    k=10,\n",
    "    device=DEVICE,\n",
    "    save_dir=\"model_sasrec\"\n",
    ")"
   ],
   "id": "52c46a03093c0707",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  Train loss 0.6926  Val loss 0.6928  HR@10 0.1308  NDCG@10 0.0617  Precision@10 0.0131  MRR@10 0.0411  (new best)  Time 2.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.98it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20  Train loss 0.6766  Val loss 0.6884  HR@10 0.1602  NDCG@10 0.0772  Precision@10 0.0160  MRR@10 0.0524  (new best)  Time 1.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20  Train loss 0.6605  Val loss 0.6836  HR@10 0.1811  NDCG@10 0.0886  Precision@10 0.0181  MRR@10 0.0609  (new best)  Time 1.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  5.00it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20  Train loss 0.6453  Val loss 0.6787  HR@10 0.1795  NDCG@10 0.0912  Precision@10 0.0180  MRR@10 0.0647  (new best)  Time 1.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.07it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20  Train loss 0.6317  Val loss 0.6735  HR@10 0.1835  NDCG@10 0.0936  Precision@10 0.0184  MRR@10 0.0665  (new best)  Time 1.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.25it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20  Train loss 0.6190  Val loss 0.6693  HR@10 0.1896  NDCG@10 0.0964  Precision@10 0.0190  MRR@10 0.0684  (new best)  Time 1.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.29it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20  Train loss 0.6080  Val loss 0.6656  HR@10 0.1939  NDCG@10 0.0981  Precision@10 0.0194  MRR@10 0.0694  (new best)  Time 1.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20  Train loss 0.5987  Val loss 0.6620  HR@10 0.1924  NDCG@10 0.0974  Precision@10 0.0192  MRR@10 0.0690    Time 1.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.24it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20  Train loss 0.5922  Val loss 0.6589  HR@10 0.1945  NDCG@10 0.0975  Precision@10 0.0195  MRR@10 0.0684    Time 1.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.88it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20  Train loss 0.5862  Val loss 0.6556  HR@10 0.1884  NDCG@10 0.0964  Precision@10 0.0188  MRR@10 0.0688    Time 1.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20  Train loss 0.5790  Val loss 0.6523  HR@10 0.1924  NDCG@10 0.0979  Precision@10 0.0192  MRR@10 0.0696    Time 1.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.79it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20  Train loss 0.5755  Val loss 0.6497  HR@10 0.1903  NDCG@10 0.0969  Precision@10 0.0190  MRR@10 0.0689    Time 1.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20  Train loss 0.5729  Val loss 0.6453  HR@10 0.1915  NDCG@10 0.0963  Precision@10 0.0191  MRR@10 0.0678    Time 1.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.24it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20  Train loss 0.5692  Val loss 0.6424  HR@10 0.1942  NDCG@10 0.1014  Precision@10 0.0194  MRR@10 0.0735  (new best)  Time 1.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20  Train loss 0.5661  Val loss 0.6396  HR@10 0.1927  NDCG@10 0.0991  Precision@10 0.0193  MRR@10 0.0709    Time 1.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.38it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20  Train loss 0.5649  Val loss 0.6364  HR@10 0.1955  NDCG@10 0.0992  Precision@10 0.0195  MRR@10 0.0703    Time 1.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.65it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20  Train loss 0.5602  Val loss 0.6327  HR@10 0.1952  NDCG@10 0.0988  Precision@10 0.0195  MRR@10 0.0698    Time 1.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.03it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20  Train loss 0.5580  Val loss 0.6300  HR@10 0.1973  NDCG@10 0.1000  Precision@10 0.0197  MRR@10 0.0708    Time 1.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  3.59it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20  Train loss 0.5590  Val loss 0.6284  HR@10 0.1933  NDCG@10 0.0978  Precision@10 0.0193  MRR@10 0.0691    Time 1.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00,  4.39it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20  Train loss 0.5574  Val loss 0.6241  HR@10 0.1979  NDCG@10 0.0990  Precision@10 0.0198  MRR@10 0.0694    Time 1.50s\n",
      "\n",
      "Training Complete.\n",
      "Best epoch: 14 with NDCG@10: 0.1014\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cross-domain development",
   "id": "b431468b22f94a82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T05:26:17.747846Z",
     "start_time": "2025-08-28T05:26:17.743621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load trained model on source domain\n",
    "def load_best_weights(model, ckpt_path=\"model/best_model.pth\", device=\"cpu\"):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.cpu()\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device).eval()\n",
    "    return model"
   ],
   "id": "56a95e546e8757d1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Align users across domains",
   "id": "f20f9dbcb0fe38c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:14:35.968390Z",
     "start_time": "2025-08-28T06:14:35.960444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def compute_user_reprs_from_sequences(model_src, train_seqs_src, user_encoder_src, max_seq_len=50, device=DEVICE):\n",
    "    model_src.eval().to(device)\n",
    "    user_vecs = {}\n",
    "\n",
    "    for user_id, seq in train_seqs_src.items():\n",
    "        if len(seq) < 1:\n",
    "            continue\n",
    "\n",
    "        # Pad-left to max_seq_len\n",
    "        seq = seq[-max_seq_len:]\n",
    "        pad_len = max_seq_len - len(seq)\n",
    "        input_seq = torch.tensor([([0] * pad_len + seq)], dtype=torch.long, device=device)\n",
    "        hidden = model_src(input_seq)\n",
    "        last_hidden = hidden[0, -1, :].squeeze(0)\n",
    "        raw_user = user_encoder_src.inverse_transform([user_id])[0]\n",
    "        user_vecs[raw_user] = last_hidden.detach().cpu().numpy()\n",
    "\n",
    "    print(f\"\\nComputed user representations for {len(user_vecs)} users.\")\n",
    "    return user_vecs"
   ],
   "id": "58042328ee681734",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:15:33.181801Z",
     "start_time": "2025-08-28T06:14:36.473515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-domain evaluation on target domain\n",
    "SOURCE_DOMAIN = \"Books\"\n",
    "TARGET_DOMAIN = \"Movies_and_TV\"\n",
    "ALL_DOMAIN = [SOURCE_DOMAIN, TARGET_DOMAIN]\n",
    "\n",
    "# Load data from target domain\n",
    "df_target = load_amazon_reviews(TARGET_DOMAIN, max_items=4_000_000, seed=SEED)\n",
    "filtered_df_target = preprocess_dataset(df_target, min_user_interactions=20, min_item_interactions=20)\n",
    "df_target_encoded, user_encoder_tgt, item_encoder_tgt, domain_encoder_tgt = label_encoder(filtered_df_target, shift_item_id=True)\n",
    "\n",
    "NUM_USERS_TGT = df_target_encoded[\"user_id\"].max() + 1\n",
    "NUM_ITEMS_TGT = df_target_encoded[\"item_id\"].max() + 1\n",
    "\n",
    "# Rebuild sequences for target domain and split\n",
    "user_sequences_tgt = create_user_sequences(df_target_encoded)\n",
    "pos_items_by_user_tgt = {u: set(seq) for u, seq in user_sequences_tgt.items()}\n",
    "train_sequences_tgt, val_sequences_tgt, test_sequences_tgt = sequences_loo_split(user_sequences_tgt)\n",
    "\n",
    "# Build source user vectors from the trained source model\n",
    "user_vecs_src = compute_user_reprs_from_sequences(\n",
    "    model_src=sasrec,\n",
    "    train_seqs_src=train_sequences,\n",
    "    user_encoder_src=user_encoder,\n",
    "    max_seq_len=50,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Create an aligned matrix of source vectors in target's user_id space\n",
    "embed_dim = 64\n",
    "transfer_src_mat = np.zeros((NUM_USERS_TGT, embed_dim), dtype=np.float32)\n",
    "for raw_user, vec in user_vecs_src.items():\n",
    "    if raw_user in user_encoder_tgt.classes_:\n",
    "        uid_target = user_encoder_tgt.transform([raw_user])[0]\n",
    "        transfer_src_mat[uid_target] = vec # give source user vector to target user_id (shared users)\n",
    "\n",
    "transfer_src_mat = torch.tensor(transfer_src_mat)  # [U_T, D]\n",
    "print(\"\\n\")\n",
    "print(transfer_src_mat)"
   ],
   "id": "85d2e182c914668a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/amazon_reviews_Movies_and_TV.csv with 4000000 rows.\n",
      "After interactions filtering: 98935 rows, 5686 users, 26709 items\n",
      "Number of users: 5686\n",
      "Max sequence length: 270\n",
      "Min sequence length: 1\n",
      "Training sequences: 5534\n",
      "Validation users: 5534\n",
      "Test users: 5534\n",
      "\n",
      "Computed user representations for 3264 users.\n",
      "\n",
      "\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.1074,  1.2010,  1.1540,  ..., -0.9452, -1.1309, -1.0154]])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset and DataLoader for cross-domain",
   "id": "8fe47cc91330d75d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:15:33.290047Z",
     "start_time": "2025-08-28T06:15:33.282987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Additional dataset changes for cross-domain\n",
    "class SASRecDatasetCD(SASRecDataset):\n",
    "    def __init__(self, data, num_items, transfer_src_mat, max_seq_len=50, mode=\"train\", neg_samples=1):\n",
    "        super().__init__(data, num_items, max_seq_len=max_seq_len, mode=mode, neg_samples=neg_samples)\n",
    "        self.transfer_src_mat = transfer_src_mat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out = super().__getitem__(idx)\n",
    "        user_id = out[\"user\"]\n",
    "        out[\"transfer_src\"] = self.transfer_src_mat[user_id].float()\n",
    "        return out"
   ],
   "id": "fb352b01f59749f8",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:15:33.440492Z",
     "start_time": "2025-08-28T06:15:33.308559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Target datasets & loaders\n",
    "train_dataset_tgt = SASRecDatasetCD(train_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"train\", neg_samples=1)\n",
    "val_dataset_tgt = SASRecDatasetCD(val_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"val\", neg_samples=99)\n",
    "test_dataset_tgt = SASRecDatasetCD(test_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"test\", neg_samples=99)\n",
    "\n",
    "train_loader_tgt = DataLoader(train_dataset_tgt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_tgt   = DataLoader(val_dataset_tgt,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_tgt  = DataLoader(test_dataset_tgt,  batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "c95053be10a6e3af",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cross-domain SASRec model\n",
    "This technique is inspired by the paper [Personalized Transfer of User Preferences for Cross-domain Recommendation (2021)](https://arxiv.org/abs/2110.11154)."
   ],
   "id": "822d0dc78c291e13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:15:33.462913Z",
     "start_time": "2025-08-28T06:15:33.456439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class SASRecCD(nn.Module):\n",
    "#     def __init__(self, base_sasrec, hidden_dim=64, bridge_hidden=128, dropout=0.1):\n",
    "#         super().__init__()\n",
    "#         self.base = base_sasrec\n",
    "#         self.bridge = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim, bridge_hidden),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.Linear(bridge_hidden, hidden_dim)\n",
    "#         )\n",
    "#         self.gate = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "#\n",
    "#     def forward(self, input_seq, transfer_src=None, candidate_items=None):\n",
    "#         seq_output = self.base(input_seq)\n",
    "#         last_hidden = seq_output[:, -1, :]\n",
    "#\n",
    "#         if transfer_src is not None:\n",
    "#             bridge_out = self.bridge(transfer_src)\n",
    "#             combined = torch.cat([last_hidden, bridge_out], dim=-1)\n",
    "#             gate = torch.sigmoid(self.gate(combined))\n",
    "#             fused = gate * last_hidden + (1.0 - gate) * bridge_out\n",
    "#         else:\n",
    "#             fused = last_hidden\n",
    "#\n",
    "#         if candidate_items is not None:\n",
    "#             cand_emb = self.base.item_embed(candidate_items)\n",
    "#             scores = torch.bmm(cand_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "#             return scores\n",
    "#\n",
    "#         return fused"
   ],
   "id": "4df69b2ba0f29f83",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:23.479591Z",
     "start_time": "2025-08-28T06:47:23.469422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SASRecCD(nn.Module):\n",
    "    def __init__(self, base_sasrec, hidden_dim=64, bridge_hidden=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.base = base_sasrec\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, bridge_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(bridge_hidden, hidden_dim)\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, transfer_src=None, candidate_items=None):\n",
    "        seq_output = self.base(input_seq)\n",
    "        last_hidden = seq_output[:, -1, :]\n",
    "\n",
    "        if transfer_src is not None:\n",
    "            bridge_out = self.bridge(transfer_src)\n",
    "            has_transfer = (transfer_src.abs().sum(dim=-1, keepdim=True) > 0).float()\n",
    "            last_hidden_n = nn.functional.layer_norm(last_hidden, last_hidden.shape[-1:])\n",
    "            bridge_out_n = nn.functional.layer_norm(bridge_out, bridge_out.shape[-1:])\n",
    "            combined = torch.cat([last_hidden_n, bridge_out_n], dim=-1)\n",
    "            gate = torch.sigmoid(self.linear(combined))\n",
    "            fused_gate = gate * last_hidden + (1.0 - gate) * bridge_out\n",
    "            fused = has_transfer * fused_gate + (1.0 - has_transfer) * last_hidden\n",
    "        else:\n",
    "            fused = last_hidden\n",
    "\n",
    "        if candidate_items is not None:\n",
    "            cand_emb = self.base.item_embed(candidate_items)\n",
    "            scores = torch.bmm(cand_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "            return scores\n",
    "\n",
    "        return fused"
   ],
   "id": "2dbb085a69e59ff",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and evaluation functions for cross-domain",
   "id": "e272ab095ba4ce41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:23.837884Z",
     "start_time": "2025-08-28T06:47:23.829287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch_transfer(model, loader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        inp = batch[\"input_seq\"].to(device)\n",
    "        pos = batch[\"target\"].to(device)\n",
    "        neg = batch[\"neg_items\"].to(device)\n",
    "        transfer = batch[\"transfer_src\"].to(device)\n",
    "\n",
    "        # fused representation\n",
    "        fused = model(inp, transfer_src=transfer)\n",
    "        pos_emb = model.base.item_embed(pos)\n",
    "        neg_emb = model.base.item_embed(neg)\n",
    "\n",
    "        pos_logits = (fused * pos_emb).sum(dim=1)\n",
    "        neg_logits = torch.bmm(neg_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        all_logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], 1)\n",
    "        all_labels = torch.cat([torch.ones_like(pos_logits).unsqueeze(1),\n",
    "                                torch.zeros_like(neg_logits)], 1)\n",
    "\n",
    "        loss = loss_fn(all_logits.reshape(-1), all_labels.reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item(); n += 1\n",
    "    return total / n"
   ],
   "id": "9b5d3f950196aeee",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:24.015821Z",
     "start_time": "2025-08-28T06:47:24.004441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_transfer(model, loader, loss_fn, k=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total = hits = ndcgs = precs = mrrs = 0.0\n",
    "    loss_sum, nb = 0.0, 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "        inp = batch[\"input_seq\"].to(device)\n",
    "        tgt = batch[\"target\"].to(device)\n",
    "        neg = batch[\"neg_items\"].to(device)\n",
    "        transfer = batch[\"transfer_src\"].to(device)\n",
    "\n",
    "        fused = model(inp, transfer_src=transfer)\n",
    "        cand = torch.cat([tgt.unsqueeze(1), neg], dim=1)\n",
    "        cand_emb = model.base.item_embed(cand)\n",
    "        scores = torch.bmm(cand_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # loss\n",
    "        labels = torch.cat([torch.ones_like(scores[:, :1]),\n",
    "                            torch.zeros_like(scores[:, 1:])], dim=1)\n",
    "        batch_loss = loss_fn(scores.reshape(-1), labels.reshape(-1))\n",
    "        loss_sum += batch_loss.item(); nb += 1\n",
    "\n",
    "        # ranks & metrics\n",
    "        _, idx = torch.sort(scores, dim=1, descending=True)\n",
    "        rank = (idx == 0).nonzero(as_tuple=True)[1] + 1  # 1-based\n",
    "        hit = (rank <= k).float()\n",
    "        ndcg = torch.where(rank <= k, 1.0 / torch.log2(rank.float() + 1), torch.zeros_like(hit))\n",
    "        precision = hit / float(k)\n",
    "        mrr = 1.0 / rank.float()\n",
    "\n",
    "        B = inp.size(0)\n",
    "        hits += hit.sum().item()\n",
    "        ndcgs += ndcg.sum().item()\n",
    "        precs += precision.sum().item()\n",
    "        mrrs += mrr.sum().item()\n",
    "        total += B\n",
    "\n",
    "    return {\n",
    "        \"HR@K\": hits / total,\n",
    "        \"NDCG@K\": ndcgs / total,\n",
    "        \"Precision@K\": precs / total,\n",
    "        \"MRR\": mrrs / total,\n",
    "        \"Val loss\": loss_sum / max(nb, 1)\n",
    "    }"
   ],
   "id": "c04555ca03e8ea0",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:24.422859Z",
     "start_time": "2025-08-28T06:47:24.414898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trainer (target domain)\n",
    "def train_target_with_transfer(model, train_loader, val_loader, epochs, lr=1e-3, wd=1e-6, k=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    best_ndcg, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train = train_epoch_transfer(model, train_loader, loss_fn, opt, device=device)\n",
    "        eval = evaluate_transfer(model, val_loader, loss_fn, k=k, device=device)\n",
    "\n",
    "        if eval[\"NDCG@K\"] > best_ndcg:\n",
    "            best_ndcg, best_epoch = eval[\"NDCG@K\"], epoch+1\n",
    "            torch.save(model.state_dict(), \"model_sasrec/transfer_best.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  \"\n",
    "              f\"Train {train:.4f}  \"\n",
    "              f\"Val {eval['Val loss']:.4f}  \"\n",
    "              f\"HR@{k} {eval['HR@K']:.4f}  \"\n",
    "              f\"NDCG@{k} {eval['NDCG@K']:.4f}  \"\n",
    "              f\"Prec@{k} {eval['Precision@K']:.4f}  \"\n",
    "              f\"MRR {eval['MRR']:.4f}  \"\n",
    "              f\"{'(new best)' if eval['NDCG@K']==best_ndcg and best_epoch==epoch+1 else ''}\")\n",
    "\n",
    "    print(f\"\\nBest epoch {best_epoch} NDCG@{k}={best_ndcg:.4f}\")\n",
    "    return best_ndcg"
   ],
   "id": "c51f2eaaf80216e0",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the cross-domain model",
   "id": "56431266d7dc33c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:25.528717Z",
     "start_time": "2025-08-28T06:47:25.483346Z"
    }
   },
   "cell_type": "code",
   "source": "sasrec_base_model = load_best_weights(sasrec, ckpt_path=\"model_sasrec/best_model_src.pth\", device=DEVICE)",
   "id": "6d74d1ba88096a1",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:47:26.004373Z",
     "start_time": "2025-08-28T06:47:25.996997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_src = sasrec_base_model.hidden_dim\n",
    "d_src # hidden dimension of source model (embedding size)"
   ],
   "id": "9a1cfabccd952b80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:50:07.262103Z",
     "start_time": "2025-08-28T06:47:26.603180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-domain wrapper model (bridge maps d_src -> target hidden)\n",
    "sasrec_target_model = SASRec(num_items=NUM_ITEMS_TGT,\n",
    "                             hidden_dim=d_src,\n",
    "                             max_seq_len=50,\n",
    "                             num_blocks=2,\n",
    "                             num_heads=2,\n",
    "                             dropout=0.2)\n",
    "\n",
    "transfer_model = SASRecCD(sasrec_target_model,\n",
    "                          hidden_dim=d_src,\n",
    "                          bridge_hidden=128,\n",
    "                          dropout=0.1).to(DEVICE)\n",
    "\n",
    "best_ndcg_tgt = train_target_with_transfer(transfer_model,\n",
    "                                           train_loader_tgt,\n",
    "                                           val_loader_tgt,\n",
    "                                           epochs=20,\n",
    "                                           lr=1e-3,\n",
    "                                           wd=1e-6,\n",
    "                                           k=10,\n",
    "                                           device=DEVICE)"
   ],
   "id": "ec9016ad1cf5c06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  Train 0.6851  Val 0.6906  HR@10 0.1737  NDCG@10 0.0878  Prec@10 0.0174  MRR 0.0848  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20  Train 0.6514  Val 0.6836  HR@10 0.1970  NDCG@10 0.0983  Prec@10 0.0197  MRR 0.0904  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20  Train 0.6310  Val 0.6735  HR@10 0.1961  NDCG@10 0.0967  Prec@10 0.0196  MRR 0.0892  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20  Train 0.6189  Val 0.6615  HR@10 0.1980  NDCG@10 0.0976  Prec@10 0.0198  MRR 0.0899  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20  Train 0.6101  Val 0.6554  HR@10 0.1970  NDCG@10 0.0985  Prec@10 0.0197  MRR 0.0912  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20  Train 0.6036  Val 0.6462  HR@10 0.1935  NDCG@10 0.0978  Prec@10 0.0194  MRR 0.0917  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20  Train 0.5965  Val 0.6339  HR@10 0.1957  NDCG@10 0.0992  Prec@10 0.0196  MRR 0.0928  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20  Train 0.5904  Val 0.6455  HR@10 0.1962  NDCG@10 0.0975  Prec@10 0.0196  MRR 0.0909  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20  Train 0.5860  Val 0.6485  HR@10 0.2031  NDCG@10 0.1010  Prec@10 0.0203  MRR 0.0934  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20  Train 0.5712  Val 0.6437  HR@10 0.2192  NDCG@10 0.1106  Prec@10 0.0219  MRR 0.1006  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20  Train 0.5565  Val 0.6313  HR@10 0.2262  NDCG@10 0.1148  Prec@10 0.0226  MRR 0.1041  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20  Train 0.5392  Val 0.6416  HR@10 0.2421  NDCG@10 0.1200  Prec@10 0.0242  MRR 0.1055  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20  Train 0.5225  Val 0.6240  HR@10 0.2452  NDCG@10 0.1234  Prec@10 0.0245  MRR 0.1095  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20  Train 0.5061  Val 0.6146  HR@10 0.2539  NDCG@10 0.1288  Prec@10 0.0254  MRR 0.1139  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20  Train 0.4911  Val 0.6132  HR@10 0.2604  NDCG@10 0.1317  Prec@10 0.0260  MRR 0.1157  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20  Train 0.4779  Val 0.6035  HR@10 0.2653  NDCG@10 0.1350  Prec@10 0.0265  MRR 0.1185  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20  Train 0.4631  Val 0.5908  HR@10 0.2674  NDCG@10 0.1391  Prec@10 0.0267  MRR 0.1230  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20  Train 0.4454  Val 0.5759  HR@10 0.2667  NDCG@10 0.1374  Prec@10 0.0267  MRR 0.1214  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20  Train 0.4361  Val 0.5607  HR@10 0.2774  NDCG@10 0.1430  Prec@10 0.0277  MRR 0.1249  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20  Train 0.4224  Val 0.5480  HR@10 0.2772  NDCG@10 0.1433  Prec@10 0.0277  MRR 0.1255  (new best)\n",
      "\n",
      "Best epoch 20 NDCG@10=0.1433\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison of baseline and cross-domain models",
   "id": "5a519e04b37667e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:00:23.142975Z",
     "start_time": "2025-08-28T06:57:48.791021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline on target-only SASRec (no transfer)\n",
    "sasrec_tgt_baseline = SASRec(\n",
    "    num_items=NUM_ITEMS_TGT,\n",
    "    hidden_dim=64,\n",
    "    max_seq_len=50,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    "    dropout=0.2\n",
    ").to(DEVICE)\n",
    "\n",
    "loss_fn_tgt_baseline = nn.BCEWithLogitsLoss()\n",
    "optimizer_tgt_baseline = torch.optim.Adam(sasrec_tgt_baseline.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "best_ndcg_tgt_baseline = 0.0\n",
    "best_epoch_tgt_baseline = 0\n",
    "EPOCHS = 20\n",
    "k = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_sasrec_epoch(sasrec_tgt_baseline, train_loader_tgt, loss_fn_tgt_baseline, optimizer_tgt_baseline, device=DEVICE)\n",
    "    eval_metrics = evaluate_sasrec(sasrec_tgt_baseline, val_loader_tgt, loss_fn_tgt_baseline, k=k , device=DEVICE)\n",
    "\n",
    "    if eval_metrics[\"NDCG@K\"] > best_ndcg_tgt_baseline:\n",
    "        best_ndcg_tgt_baseline = eval_metrics[\"NDCG@K\"]\n",
    "        torch.save(sasrec_tgt_baseline.state_dict(), \"model_sasrec/baseline_target_only_best.pth\")\n",
    "        best_epoch_tgt_baseline = epoch + 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  \"\n",
    "          f\"Train loss {train_loss:.4f}  \"\n",
    "          f\"Val loss {eval_metrics['Val loss']:.4f}  \"\n",
    "          f\"HR@10 {eval_metrics['HR@K']:.4f}  \"\n",
    "          f\"NDCG@10 {eval_metrics['NDCG@K']:.4f}  \"\n",
    "          f\"Precision@10 {eval_metrics['Precision@K']:.4f}  \"\n",
    "          f\"MRR@10 {eval_metrics['MRR@K']:.4f}  \"\n",
    "          f\"{'(new best)' if eval_metrics['NDCG@K']==best_ndcg_tgt_baseline else ''}\")\n",
    "\n",
    "print(f\"\\nBest epoch {best_epoch_tgt_baseline} NDCG@{k}={best_ndcg_tgt_baseline:.4f}\")"
   ],
   "id": "c3dbde3410be4fdb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.99it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  Train loss 0.6856  Val loss 0.6903  HR@10 0.1850  NDCG@10 0.0907  Precision@10 0.0185  MRR@10 0.0624  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20  Train loss 0.6508  Val loss 0.6823  HR@10 0.1926  NDCG@10 0.0950  Precision@10 0.0193  MRR@10 0.0657  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20  Train loss 0.6320  Val loss 0.6729  HR@10 0.1961  NDCG@10 0.0974  Precision@10 0.0196  MRR@10 0.0676  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20  Train loss 0.6220  Val loss 0.6645  HR@10 0.2002  NDCG@10 0.0987  Precision@10 0.0200  MRR@10 0.0683  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20  Train loss 0.6176  Val loss 0.6543  HR@10 0.1948  NDCG@10 0.0982  Precision@10 0.0195  MRR@10 0.0691  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20  Train loss 0.6170  Val loss 0.6439  HR@10 0.1953  NDCG@10 0.0984  Precision@10 0.0195  MRR@10 0.0691  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20  Train loss 0.6124  Val loss 0.6432  HR@10 0.1999  NDCG@10 0.0973  Precision@10 0.0200  MRR@10 0.0666  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20  Train loss 0.6060  Val loss 0.6379  HR@10 0.1975  NDCG@10 0.0974  Precision@10 0.0198  MRR@10 0.0675  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20  Train loss 0.5970  Val loss 0.6342  HR@10 0.2073  NDCG@10 0.1018  Precision@10 0.0207  MRR@10 0.0702  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20  Train loss 0.5772  Val loss 0.6407  HR@10 0.2149  NDCG@10 0.1071  Precision@10 0.0215  MRR@10 0.0748  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20  Train loss 0.5579  Val loss 0.6312  HR@10 0.2174  NDCG@10 0.1092  Precision@10 0.0217  MRR@10 0.0766  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20  Train loss 0.5343  Val loss 0.6287  HR@10 0.2262  NDCG@10 0.1144  Precision@10 0.0226  MRR@10 0.0808  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20  Train loss 0.5193  Val loss 0.6283  HR@10 0.2336  NDCG@10 0.1186  Precision@10 0.0234  MRR@10 0.0841  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20  Train loss 0.4992  Val loss 0.6117  HR@10 0.2445  NDCG@10 0.1239  Precision@10 0.0244  MRR@10 0.0877  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.04it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20  Train loss 0.4813  Val loss 0.6060  HR@10 0.2454  NDCG@10 0.1255  Precision@10 0.0245  MRR@10 0.0895  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20  Train loss 0.4683  Val loss 0.5960  HR@10 0.2514  NDCG@10 0.1278  Precision@10 0.0251  MRR@10 0.0907  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.01it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20  Train loss 0.4539  Val loss 0.5855  HR@10 0.2530  NDCG@10 0.1307  Precision@10 0.0253  MRR@10 0.0940  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:07<00:00,  2.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20  Train loss 0.4396  Val loss 0.5693  HR@10 0.2519  NDCG@10 0.1326  Precision@10 0.0252  MRR@10 0.0966  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20  Train loss 0.4262  Val loss 0.5601  HR@10 0.2541  NDCG@10 0.1323  Precision@10 0.0254  MRR@10 0.0957  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 21/21 [00:06<00:00,  3.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20  Train loss 0.4136  Val loss 0.5371  HR@10 0.2606  NDCG@10 0.1375  Precision@10 0.0261  MRR@10 0.1005  (new best)\n",
      "\n",
      "Best epoch 20 NDCG@10=0.1375\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build cold/warm user splits from target domain training sequences",
   "id": "a7f2963f3390c130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:01:45.116874Z",
     "start_time": "2025-08-28T07:01:45.102737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_cold_warm(train_sequences_tgt, cold_threshold=1):\n",
    "    cold_users = {u for u, seq in train_sequences_tgt.items() if len(seq) <= cold_threshold}\n",
    "    warm_users = {u for u, seq in train_sequences_tgt.items() if len(seq) >= (cold_threshold + 1)}\n",
    "    return cold_users, warm_users\n",
    "\n",
    "def filter_split(split_dict, keep_users):\n",
    "    return {u: v for u, v in split_dict.items() if u in keep_users}\n",
    "\n",
    "COLD_THRESHOLD = 3\n",
    "cold_users, warm_users = split_cold_warm(train_sequences_tgt, cold_threshold=COLD_THRESHOLD)\n",
    "test_cold = filter_split(test_sequences_tgt, cold_users)\n",
    "test_warm = filter_split(test_sequences_tgt, warm_users)\n",
    "\n",
    "print(f\"Test cold users: {len(test_cold)}, Test warm users: {len(test_warm)}\")"
   ],
   "id": "b5a9898d31d2fc2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cold users: 359, Test warm users: 5175\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:01:47.237865Z",
     "start_time": "2025-08-28T07:01:47.202382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "overlap_mask = (transfer_src_mat.norm(dim=1) > 0)  # [U_T]\n",
    "test_cold_users = set(u for u, _ in test_sequences_tgt.items() if len(test_sequences_tgt.get(u, [])) <= COLD_THRESHOLD)\n",
    "cold_overlap = sum(int(overlap_mask[u].item()) for u in test_cold_users)\n",
    "print(f\"TEST/Cold users: {len(test_cold_users)}, with source-overlap: {cold_overlap} ({cold_overlap/len(test_cold_users):.1%})\")"
   ],
   "id": "71c1c2ef268193a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST/Cold users: 5534, with source-overlap: 245 (4.4%)\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:02:14.712321Z",
     "start_time": "2025-08-28T07:02:14.689969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_loader_from_split(split_dict, transfer_src_mat, num_items, mode=\"val\", max_seq_len=50, neg_samples=99, batch_size=4096):\n",
    "    ds = SASRecDatasetCD(split_dict, num_items, transfer_src_mat, max_seq_len=max_seq_len, mode=mode, neg_samples=neg_samples)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader_all = test_loader_tgt\n",
    "test_loader_cold = make_loader_from_split(test_cold, transfer_src_mat, NUM_ITEMS_TGT)\n",
    "test_loader_warm = make_loader_from_split(test_warm, transfer_src_mat, NUM_ITEMS_TGT)"
   ],
   "id": "345946d6baed10ca",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate baseline vs transfer models on target domain",
   "id": "6ff8d9bd16b13028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:03:36.255656Z",
     "start_time": "2025-08-28T07:03:36.149647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sasrec_tgt_baseline.load_state_dict(torch.load(\"model_sasrec/baseline_target_only_best.pth\", map_location=DEVICE))\n",
    "transfer_model.load_state_dict(torch.load(\"model_sasrec/transfer_best.pth\", map_location=DEVICE))\n",
    "sasrec_tgt_baseline.to(DEVICE).eval()\n",
    "transfer_model.to(DEVICE).eval()"
   ],
   "id": "d46d5c1826e23e56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRecCD(\n",
       "  (base): SASRec(\n",
       "    (item_embed): Embedding(26710, 64, padding_idx=0)\n",
       "    (positional_embed): Embedding(50, 64)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x AttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): PointWiseFeedForward(\n",
       "          (w1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (bridge): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:03:41.843928Z",
     "start_time": "2025-08-28T07:03:37.907195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "# Compute metrics on all / cold / warm for val and test sets\n",
    "def eval_all():\n",
    "    suites = {\n",
    "        \"All [Test]\": (test_loader_all,),\n",
    "        \"Cold [Test]\": (test_loader_cold,),\n",
    "        \"Warm [Test]\": (test_loader_warm,),\n",
    "    }\n",
    "    rows = []\n",
    "    for name, (loader,) in suites.items():\n",
    "        mb = evaluate_sasrec(sasrec_tgt_baseline, loader, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "        mx = evaluate_transfer(transfer_model, loader, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "        rows.append({\n",
    "            \"Split\": name,\n",
    "            \"Baseline HR@10\": mb[\"HR@K\"], \"Transfer HR@10\": mx[\"HR@K\"],\n",
    "            \"Baseline NDCG@10\": mb[\"NDCG@K\"], \"Transfer NDCG@10\": mx[\"NDCG@K\"],\n",
    "            # \"Baseline P@10\": mb[\"Precision@K\"], \"Transfer P@10\": mx[\"Precision@K\"],\n",
    "            # \"Baseline MRR\": mb.get(\"MRR\", math.nan), \"Transfer MRR\": mx.get(\"MRR\", math.nan)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "results_df = eval_all()\n",
    "print(\"\\n=== COMPARISON TABLE ===\")\n",
    "print(results_df.to_string(index=False))"
   ],
   "id": "532468c4825ea565",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON TABLE ===\n",
      "      Split  Baseline HR@10  Transfer HR@10  Baseline NDCG@10  Transfer NDCG@10\n",
      " All [Test]        0.218648        0.234008          0.115246          0.120982\n",
      "Cold [Test]        0.150418        0.164345          0.072169          0.081755\n",
      "Warm [Test]        0.231111        0.240000          0.121394          0.123521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:05:19.891882Z",
     "start_time": "2025-08-28T07:05:19.387281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bar plots\n",
    "def barplot_metric(df, metric_col_baseline, metric_col_transfer, title, outfile):\n",
    "    labels = df[\"Split\"].tolist()\n",
    "    baseline = df[metric_col_baseline].tolist()\n",
    "    transfer = df[metric_col_transfer].tolist()\n",
    "    xs = range(len(labels))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(xs, baseline, width=0.4, label=\"Baseline\")\n",
    "    plt.bar([i+0.4 for i in xs], transfer, width=0.4, label=\"Transfer\")\n",
    "    plt.xticks([i+0.2 for i in xs], labels)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "barplot_metric(results_df, \"Baseline HR@10\", \"Transfer HR@10\", \"HR@10: Baseline vs Transfer\", \"hr10.png\")\n",
    "barplot_metric(results_df, \"Baseline NDCG@10\", \"Transfer NDCG@10\", \"NDCG@10: Baseline vs Transfer\", \"ndcg10.png\")\n",
    "print(\"Saved charts: hr10.png, ndcg10.png\")"
   ],
   "id": "2731e17714ba563a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAJOCAYAAABBfN/cAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQgFJREFUeJzt3QeYVOW9P/AXUMCKBQNYEXtFRTQaDUkkoib+1ahBrwmIRhONLcQeBWwBe4lejRpbohFN1BQNtoiJiqLYYo14VVCkqBGsoLD/5/feZ+buwqIs7MvuwufzPOdhZ+bMmTOzw9nzPb+3tKqpqalJAAAAQBGty2wWAAAACII3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAsRlq1apWGDBlSvX3dddfl+15//fUm3S9S+vzzz9Pxxx+f1lhjjdS6deu05557NvUuAdBIBG8A5kkloD3xxBP1Pv6Nb3wjbbrppnXu69q1a35OZVlmmWXSNttsk2644YYGvfaHH36YZs2a9aXrvfzyy+lnP/tZ2n777VP79u2/NFD++c9/TltttVVed80110yDBw/O4Wd+RaCt/X4jPHXp0iV997vfTY8++uh8b5cF+z3MbYnvbHNyzTXXpHPPPTfts88+6frrr8/fZQAWDUs09Q4AsGjbYost0s9//vP889tvv52uvvrq1L9//zR9+vR0yCGH1Pucmpqa9Ic//CFde+216R//+Ef66KOP0pJLLpk22GCDtN9++6UjjzwyLb/88nM8b9SoUemSSy5JG2+8cdpoo43S008/Pdf9+tvf/pYrihG+fvWrX6V//etf6cwzz0yTJ09Ol19++QK953j+sssumy8WjB8/Pl111VXp61//eho9enT+PJqTH/7wh/kzbdeuXVpUfO9730vrrrtunQs3hx12WNprr73yYxWdOnVKzcnf//73tNpqq6ULL7ywqXcFgEYmeANQVASJH/zgB9XbBx54YOrWrVsOF/UF7ylTpqS99947V4gjGF9wwQVp9dVXT1OnTk1PPfVUDrWx3HTTTTnM1vb//t//S++//35abrnl0nnnnfeFwfvYY49Nm2++ebrnnnvSEkv875/DCPO//OUv09FHH5023HDD+X7PUbHs2LFj9Xa8j2gNcOuttza74N2mTZu8LEri9xpLxTvvvJODd9xX+7s4u08//TS1bds2t1RoCnHRZ4UVVmi07cUFrHhPSy21VKNtE4D5o6k5AAvVKquskkPtq6++OsdjH3zwQerVq1cO2c8//3y65ZZb0qGHHpp22223tP/++6dzzjknvfLKK2nfffdN3/nOd+Zo9r7SSivl0P1lXnjhhbzEtiuhOxx++OHVanvFZ599ll566aVcrZ9fnTt3zv/Wfq0ZM2akQYMGpR49eqQOHTrkZvg77rhjeuCBB+Z4/s0335zXi/cWFwc222yzdPHFF9dZJy44HHPMMbl/cFSvo+J79tlnf2kT/fr6eEcXgWge/9BDD+WuAdEUPy6W1NdFYH5fN7Yf26zPdtttl7beeuvq7XvvvTftsMMOOZRGS4Jo+XDyySenBTFy5Mj8vuOzPeWUU/IFoqWXXjpNmzYtvffee/nCTHzO8Xrxme+6667pmWeeqXcb8T0966yz8gWi+Kx22mmnNHbs2Drrxvc2LijFdyHWiXWjpUF81+Ozj+3E7z6+95Wm8LH9EJ/lRRddlDbZZJP83KjU//jHP07/+c9/6rxG5fd29913588vAvevf/3rBfqcAGgcKt4ANEgEhaggzi4C6ryIPtRvvvlmWnHFFed4LAJchNMIfJUAPXPmzNwsPUJRvEZU8KJaHpXJaLIeTcQbWqGMynmoHe7CqquumgNR5fHw1ltv5Wbr8VoRUudFBLdKYIrnn3HGGTkwff/736+uEwEvmt3HBYWo/MdFh9/85jepT58+dZqkR+iMdSLMRaANL774Ynr44YdzZT58/PHH+YJFvFYEsuiv/sgjj6STTjopXzCI0NZQERyjcn/wwQfn9x79j6O1QlwAiAC4oK/bt2/f1K9fv/T444+nnj17Vu9/4403cmuH6OscIohGmIxq9emnn57DfexbvP/GEL+b+C5F0I7vWfwcF2XuuOOOfIFn7bXXTpMmTcoBNt5rPBbfk9qGDRuWv4Oxjfj/EReIDjjggPTYY49VL7LE7zW2H90kInzHZ/bXv/41X7iIi1G//e1vc3iPZvFDhw7Nz4vvXYjPNr57AwYMSEcddVR67bXX0qWXXpq/p/E5RDeM2uMcxPclnhPfq7hIAUAzUAMA8+Daa6+tiT8bX7RssskmdZ6z1lpr1ey88841U6ZMycu//vWvmh/+8Id53Z/+9Kd11h07dmzNEkssUfPUU09V7zvttNNqlllmmbz+9ttvX3PNNdfkbYbp06fXdO7cueaee+6pd3/PPffc/LzXXnttro+NGzdujsd69uxZ89WvfrV6O54f6/bv3/9LP6PBgwfX+7mssMIKNSNGjKiz7ueff57fQ23/+c9/ajp16lRz0EEHVe87+uija5Zffvm8/tycccYZ+XP697//Xef+E088saZNmzZ13mfsT+zn7L/X2p9TfMZx3z/+8Y/qfZMnT65p165dzc9//vP5et3ZTZ06dY7thXPOOaemVatWNW+88Ua+feGFF+Z9ie/P/Irnzv6+H3jggXxft27daj7++OM663/66ac1M2fOrHNffD6xv6effvoc29hoo43q/C4vvvjifH9830N8p+P2rbfe+oX72atXrzn+D/3zn//Mz73xxhvr3B/fp9nvr/zeZv+uAdD0NDUHoEEuu+yyXIWdfandp7a26EMdFb1YouluVPaiclepaFbcfvvteTTySqU3bp922mm5+XdUH6P5cVT7KqIyGc1/K81xG+KTTz7J/9Y3oFhUpiuPV5rvRl6d12p3+OMf/5g/k3jvMUDc+uuvn5sZRzW4IvpVx3uoVMajSh6tAaIK/+STT1bXi+bVMbhcbG9uou94NFOPVgTRGqGy9O7dO7cYiAHqGioGqIttVsTvL6qn//M//9Mor1tpvh3NtP/3esD/Gj58ePrqV7+aq+eV9x/+9Kc/zdPI9g0V1fzZ+0DH96LSiiLex7vvvltt4l77d1MR3+fK7zJUPrfKZxVdCUI0AY9WAg0Rn3E8/9vf/nadzzhaHsQ+zd41ISr0UV0HoHnR1ByABok+v7M30Q6V8DW7bbfdNo8WHgHmueeeyz9H39TaQSWMGTMmffOb36zejpHAIxRFs92wxx575O3XDtrR1zUGY2uoStCKpr+za4zBqGLQt9qDq0WT7fXWWy83M473WRFTRp1//vm5D3ntpvoRniriwkOE0wip0Q955513zk3Wd9lllzr9h5999tkcjuc2aFdDVYLv7L/j2v2KF/R1o7l5XFSJ0ejjokv0+4/Pp3YT9VgnmuT/6Ec/SieeeGJuch8jk8dn2hiDoNX+rCsi4Ecf+v/+7//Ozbrju1ux8sorf+lnVelGUfms4jUGDhyYBwq88cYbczCPgQBjoLdKKJ+b+Iyj+fpXvvKVefqM63s/ADQ9wRuAoiKARgU0RCUuBlaLPrsRbCKMVERVsXbf2Rhwavfdd58j9NcO3jFVVwzq1VAxt3aIfsizPz/ui9dpTFGZjAsQUbWN6nUMpPa73/0u95mOEc+PO+64HKyiCh79e2sPPBf3x+jsUS2NKdBiiSp69I+O4F4JilERPf744+t9/ai4N9TcRjqvXZ1e0NeN32/03Y8LCxG8498I09G3uiIugkTlPCq7d955ZxoxYkSuin/rW9/KLQoWdET2+i6yxMj2p556ajrooINyH/AYtC/2K8YgqK/qPi+fVVxgid93fAdiv6P1Rvyuoz97jCswN/F68R2IwF6f2S96GMEcoHkSvAFYqGI08hikKsJNDAAVIbTS9DgqexUxANXsI5/XbuYclb4IMVExbahKc/YYFb12yJ4wYUIe+C1GO29s0Yw8xOBZ8Z5j5PQY1fu2227LI1hXDB48eI7nRuuACKmxRBCLKngM9hXhMEYRX2eddfJ2Kxc4FpYFfd34HOIiTDSnjmpwBOqoBs8+eFmE3qh0xxLrxXfnF7/4RQ7jJd5z/G6i9UUMdldbDIRWuyVDQ0VXi1hiFPXodvC1r30tXXHFFbkVyBd9xvfdd19eV6gGaLn08QZgoTvhhBNyhTuak1fECM6VUaDDXnvtlUNJzNcdI13//ve/T1deeWVu9hvV3whGMcVUhLGGilG5o/Je2V5FzA8eITiaMTfmdGLRfzuCVlxMqDQZrlRJa1dF4/1Hs+va4nOaPYRW+tNXmspH0/N4Xnwus4uwWAn9ja0xXjeakscFj2hOHtN1xe36Roiv78JJfV0FGkP8bmr/XkJcHIiRyOdHjGA/+2cRATx+l1/2HuIzju9oVN5nF9uMzxmA5k/FG4CFLvorb7rpprl6+dOf/jRPhxSVz2iOGwE3moL/5Cc/yZW+mJap0rc2mmTH3NfRPzamuTrvvPPqbDcq5r/61a/yz5XppmLapRigK5Yjjjiium4M7hbbiT7TMZ9y9D+PdaMvcWUap/mdTiwqptG8PMJbhMqonEZ/37iQUKlux/uNandcYIhWANGXOB6PQc2iilwR+xPhM5pWR5PkuAgR7zHCZ2U/43P585//nLdZmfIrmrTHVGuxL9Fsf0EqtXPTGK8bc7TH1HExFVcE3hiErraYQiyamsdntNZaa+WWDtH3Oj6LuPBSQryfeN0YNC2awMf7iabec5t3/Mv8/e9/z9+9aEIfze8jMMcgg/W939lF65BoGRLN0qPLQXxf4/9L9P2OiwHRZaP2hSIAmifBG4AmEUErwloEmvg3+kBHs+8I4jEqeISLaEoec1ZHaI2gGfMhx6BiUbGOvsGzi/Wi+XVtEeZDhLbawbsSfGPk9Bj0LPrKnnzyyTnYL6jDDjusTnPqqFDHHM21+y7He544cWJuMh4V4wjc0e87wlTtfuwxAFdU5iNsRnUzquZRFR4yZEh1cLH4LB588MHcBDuef8MNN+Sm+xHy4v192QBe86sxXjdGkY8LIPE9iGbjsw8iFo9FgI95xGNwvQjyEUZLvq/4HsQFhGhtEc3ft9pqq9y/PAZ3mx/du3fP4xv85S9/yRdy4nOL+6K/fozg/mXigkxc1IjvSuxbzHUfo+3HdyOaoAPQ/LWKOcWaeicAIEQVr2fPnrkKGM2+Zx/5PMRUXzG1VgQyAICWQPAGoFmJfs4RqqNSHBXqqG5GFTSqndFk95JLLslNdGMaq2jODQDQ3AneADQ7MTd39LGN5se1542OZsaV+ZxLNTMGAGhsgjcAzVaM5vzyyy/nancMrhYjkS/ovM0AAAub4A0AAAAFmccbAAAAChK8AQAAoKBFYh7vWbNmpQkTJqTlllsutWrVqql3BwAAgEVcTU1N+uCDD9Kqq66aWrf+kpp2zXy49NJLa9Zaa62adu3a1WyzzTY1jz322FzXvfLKK2t22GGHmhVWWCEvO+200xzr9+/fP/qZ11n69Okzz/szfvz4OZ5vsVgsFovFYrFYLBZLKrxEHv0yDa54Dx8+PA0cODBdccUVadttt00XXXRR6tOnTx51NuZZnd3IkSPT/vvvn7bffvvUvn37dPbZZ6edd945Pf/882m11VarrrfLLruka6+9tnq7Xbt287xPUekO48ePT8svv3xD3xIAAAA0yLRp09Iaa6xRzaONOqp5hO2ePXumSy+9tNrMO17syCOPzPOqzsvUMCuuuGJ+fr9+/fJ9Bx54YHr//ffTHXfckeb3Dcd8rlOnThW8AQAAKK4hObRBg6vNmDEjjRkzJvXu3fv/NtC6db49atSoedrGxx9/nD777LO00korzVEZj4r5BhtskA477LD07rvvznUb06dPz2+y9gIAAADNUYOC9zvvvJMr1p06dapzf9yeOHHiPG3jhBNOyJ3Pa4f3aGZ+ww03pPvvvz83RX/wwQfTrrvuml+rPkOHDs1XFipLVNwBAAAgLe6jmg8bNizdfPPNubod/b0r9ttvv+rPm222Wdp8883TOuusk9fbaaed5tjOSSedlPuZz962HgAAAFp08O7YsWNq06ZNmjRpUp3743bnzp2/8LnnnXdeDt733XdfDtZfpFu3bvm1xo4dW2/wjoHXGjL4WkVU0KOZO81b27Ztv3w4fgAAgEUxeEcg6tGjR24Svueee1YHV4vbRxxxxFyfd84556Szzjor3X333Wnrrbf+0td58803cx/vLl26pMYQ48dFU/gYwI3mL0L32muvnb9vAAAAi11T82ji3b9//xygt9lmmzyd2EcffZQGDBiQH4+RymOasOiHHaLP9qBBg9JNN92UunbtWu0Lvuyyy+blww8/TKeddlrae++9c9X81VdfTccff3xad9118zRljaESumPwtqWXXjq1atWqUbZL44sLORMmTEhvv/12WnPNNf2uAACAxS949+3bN02ZMiWH6Qi0W2yxRRoxYkR1wLVx48bVaSZ8+eWX59HQ99lnnzrbGTx4cBoyZEhuuv7ss8+m66+/PofjGHgt5vk+44wz5qs5eX3Nyyuhe+WVV17g7VHeKqusksP3559/npZccsmm3h0AAIAF0uB5vFva/Gmffvppeu2113K1famllmqyfWTeffLJJ+n111/Pzc1rD8IHAACwyM/j3ZJpstxy+F0BAACLksUmeAMAAEBTELz5QtFEPwbQq12NvuOOO5p0nwAAABbpwdUWJV1PvHOhvt7rw77ToPUPPPDAPOhcxUorrZR69uyZp2f7srnQS4nRxldcccUmeW0AAICWSMW7mdtll11y2I0l5ktfYokl0ne/+90m25+Y8q0xRpsHAABYXAjezVyE3Ai7scTUbSeeeGIaP358ntItnHDCCWn99dfP85N369YtnXrqqemzzz6rPv+ZZ55J3/zmN9Nyyy2XR9rr0aNHeuKJJ6qPP/TQQ2nHHXfMI76vscYa6aijjsrzss9N7abmMfJ43L7tttvya8Q+dO/ePY0aNarOcxr6GgAAAIsSwbsF+fDDD9Pvfve7tO6661bnJI9Afd1116UXXnghXXzxxemqq65KF154YfU5BxxwQFp99dXT448/nsaMGZODe2Vu7FdffTVX1Pfee+88l/rw4cNzSD7iiCMatF+/+MUv0rHHHpuefvrpfBFg//33z3NwN+ZrAAAAtFSLdR/vluCvf/1rWnbZZfPPUSXu0qVLvq916/+9ZnLKKafUGQgtAvDNN9+cjj/++HzfuHHj0nHHHZc23HDDfHu99darrj906NAczI855pjqY5dccknq1atXuvzyy+d5Du14ze9853/7r5922mlpk002SWPHjs2v2VivAQAA0FKpeDdz0YQ7KsmxjB49OvXp0yftuuuu6Y033siPRwX5a1/7Wm6KHgE9gniE7YqBAwemH/3oR6l3795p2LBhuQJduxl6VMvjeZUltj9r1qz02muvzfM+1h7oLS4MhMmTJzfqawAAALRUgnczt8wyy+Sm5bHEiOZXX311rnxHk/LoSx3V5N122y1XwZ966qnc7HvGjBnV5w8ZMiQ9//zzuSL997//PW288cbp9ttvrzZd//GPf1wN9rFEUH7llVfSOuusM8/7WGm6HqLPd4hg3ZivAQAA0FJpat7CRLCNZuaffPJJeuSRR9Jaa62Vw3ZFpRJeW/S7juVnP/tZ7n997bXXpr322itttdVWuW94hPpSFsZrAAAANGcq3s3c9OnT08SJE/Py4osvpiOPPDJXkXfffffcXzqalUef7mhCHn2nK9XsEOE8BjEbOXJkDuQPP/xwHmRto402qo6IHuE91olKdFSh//SnPzXqwGcL4zUAAACaMxXvZm7EiBHVftMxgnkMWHbrrbemb3zjG/m+qGJHiI2AHs3JYzqxaF4e2rRpk959993Ur1+/NGnSpNSxY8f0ve99Lw+AVumb/eCDD+aKeUz3VVNTk5t/9+3bt9H2f2G8BgAAQHPWqiaSUAs3bdq01KFDhzR16tQ8V3Vtn376aR7Ea+211zaCdgvhdwYAALTkHDo7FW8AAKBlGdKhqfeA0oZMTYsSfbwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8aZCJEyemb3/722mZZZZJK6ywQlPvDgAAQLO3RFqcDemwkF9v6jyv2qpVqy98fPDgwWnIkCFpYbvwwgvT22+/nZ5++unUocNC/vwAAABaoMU7eDdjEW4rhg8fngYNGpRefvnl6n3LLrts9eeampo0c+bMtMQS5X+dr776aurRo0dab7315nsbM2bMSG3btm3U/QIAAGiuNDVvpjp37lxdorIcFfDK7Zdeeiktt9xy6W9/+1sOwe3atUsPPfRQDsV77LFH6tSpUw7mPXv2TPfdd1+d7Xbt2jX98pe/TAcddFDexpprrpmuvPLKOqH4iCOOSF26dEnt27dPa621Vho6dGj1uX/84x/TDTfckPfnwAMPzPe///776Uc/+lFaZZVV0vLLL5++9a1vpWeeeaa6zajMb7HFFunqq69Oa6+9dt4uAADA4kLFuwU78cQT03nnnZe6deuWVlxxxTR+/Pi02267pbPOOiuH8QjIu+++e66UR8CuOP/889MZZ5yRTj755PSHP/whHXbYYalXr15pgw02SJdcckn685//nG655Zb8nNhmLOHxxx9P/fr1y+H64osvTksttVS+f999980/x4WAuEjw61//Ou20007p3//+d1pppZXyOmPHjs2h/bbbbktt2rRJi7SF3YWBha8B3UYAAEDwbsFOP/30PNBZRYTc7t27V29HuL799ttzkI4qdkWE88MPPzz/fMIJJ+R+2w888EAO3uPGjcvNyHfYYYdc1Y6Kd0VUtCPQR8iOynuISvvo0aPT5MmT82MhLgbccccdOdQfeuih1Up6XAiIbQAAACxONDVvwbbeeus6tz/88MN07LHHpo022iiPOB7NzV988cUcpmvbfPPNqz9XmrBHcA7RfDwGTosQftRRR6V77rnnC/chmpTH66688sr59SrLa6+9lpu+V0SAF7oBAIDFkYp3CxZTetUWofvee+/NFed11103V6b32WefXG2ubckll6xzO8L3rFmz8s9bbbVVDs3RbDz6h3//+99PvXv3ztXr+kTojv7gI0eOnOOx2tONzb6vAAAAiwvBexHy8MMP54r1XnvtVQ3Fr7/+eoO3E324+/btm5cI7rvsskt67733qv21a4ugHnN7x4jqMfgaAAAAdQnei5Domx2Dl8WAalHFPvXUU6uV7Hl1wQUX5Ar2lltumVq3bp1uvfXW3BS9dvW6tqiGb7fddmnPPfdM55xzTlp//fXThAkT0p133pkvAMzeHB4AAGBxI3gvQiI0xzRh22+/ferYsWMeOG3atGkN2kZMMRYB+pVXXsmjj8eUZHfddVcO4fWJgB+P/+IXv0gDBgxIU6ZMyUH961//ep7WDABgYet64p1NvQsU9rrZaWlhWtXU1NSkFi7CZUxjNXXq1NxMurZPP/0091k2f3TL0eJ/Z6YTW/SZTgygWRO8F32vt/+vpt4FShsytUXn0NkZ1RwAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAApabIJ3Q+ezpuksAgPtAwAALD7zeLdt2zbPQT1hwoS0yiqr5Nsx9zTNN3THXODxO1pyySWbencAAAAW2CIfvCN0x3zQb7/9dg7fNH8RuldfffXUpk2bpt4VAACABbbIB+8QVe4111wzff7552nmzJlNvTt8iah0C90AAMCiYrEI3qHSdFnzZQAAABamxWZwNQAAAGgKgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUtETJjVO/rife2dS7QEGvt2/qPQAAAJoTFW8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAaG7B+7LLLktdu3ZN7du3T9tuu20aPXr0XNe96qqr0o477phWXHHFvPTu3XuO9WtqatKgQYNSly5d0lJLLZXXeeWVV+Zn1wAAAKBlB+/hw4engQMHpsGDB6cnn3wyde/ePfXp0ydNnjy53vVHjhyZ9t9///TAAw+kUaNGpTXWWCPtvPPO6a233qquc84556RLLrkkXXHFFemxxx5LyyyzTN7mp59+umDvDgAAAFpa8L7gggvSIYcckgYMGJA23njjHJaXXnrpdM0119S7/o033pgOP/zwtMUWW6QNN9wwXX311WnWrFnp/vvvr1a7L7roonTKKaekPfbYI22++ebphhtuSBMmTEh33HHHgr9DAAAAaCnBe8aMGWnMmDG5KXh1A61b59tRzZ4XH3/8cfrss8/SSiutlG+/9tpraeLEiXW22aFDh9yEfW7bnD59epo2bVqdBQAAAFp88H7nnXfSzJkzU6dOnercH7cjPM+LE044Ia266qrVoF15XkO2OXTo0BzOK0s0XwcAAIC0uI9qPmzYsHTzzTen22+/PQ/MNr9OOumkNHXq1Ooyfvz4Rt1PAAAAaCxLNGTljh07pjZt2qRJkybVuT9ud+7c+Qufe9555+Xgfd999+V+3BWV58U2YlTz2tuMfuH1adeuXV4AAABgkap4t23bNvXo0aM6MFqoDJS23XbbzfV5MWr5GWeckUaMGJG23nrrOo+tvfbaOXzX3mb02Y7Rzb9omwAAALDIVbxDTCXWv3//HKC32WabPCL5Rx99lEc5D/369UurrbZa7ocdzj777DxH90033ZTn/q7021522WXz0qpVq3TMMcekM888M6233no5iJ966qm5H/iee+7Z2O8XAAAAmnfw7tu3b5oyZUoO0xGiozl4VLIrg6ONGzcuj3Recfnll+fR0PfZZ58624l5wIcMGZJ/Pv7443N4P/TQQ9P777+fdthhh7zNBekHDgAAAM1Bq5qYSLuFi6bpMbp5DLS2/PLLp+au64l3NvUuUNDr7f+rqXeB0oZMbeo9AOALONda9DnfWgwMmbpI5dCFOqo5AAAALG4EbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChoiZIbBwBagCEdmnoPKG3I1KbeA4DFmoo3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAQYI3AAAAFCR4AwAAQEGCNwAAABQkeAMAAEBBgjcAAAAUJHgDAABAcwvel112WeratWtq37592nbbbdPo0aPnuu7zzz+f9t5777x+q1at0kUXXTTHOkOGDMmP1V423HDD+dk1AAAAaNnBe/jw4WngwIFp8ODB6cknn0zdu3dPffr0SZMnT653/Y8//jh169YtDRs2LHXu3Hmu291kk03S22+/XV0eeuihhu4aAAAAtPzgfcEFF6RDDjkkDRgwIG288cbpiiuuSEsvvXS65ppr6l2/Z8+e6dxzz0377bdfateu3Vy3u8QSS+RgXlk6duzY0F0DAACAlh28Z8yYkcaMGZN69+79fxto3TrfHjVq1ALtyCuvvJJWXXXVXB0/4IAD0rhx4+a67vTp09O0adPqLAAAANAcLdGQld955500c+bM1KlTpzr3x+2XXnppvnci+olfd911aYMNNsjNzE877bS04447pueeey4tt9xyc6w/dOjQvA4AC0fXE+9s6l2goNfbN/UeAMCirVmMar7rrrumfffdN22++ea5v/hdd92V3n///XTLLbfUu/5JJ52Upk6dWl3Gjx+/0PcZAAAAGr3iHf2u27RpkyZNmlTn/rj9RQOnNdQKK6yQ1l9//TR27Nh6H4++4l/UXxwAAABaZMW7bdu2qUePHun++++v3jdr1qx8e7vttmu0nfrwww/Tq6++mrp06dJo2wQAAIBmX/EOMZVY//7909Zbb5222WabPC/3Rx99lEc5D/369UurrbZa7oddGZDthRdeqP781ltvpaeffjotu+yyad111833H3vssWn33XdPa621VpowYUKeqiwq6/vvv3/jvlsAAABo7sG7b9++acqUKWnQoEFp4sSJaYsttkgjRoyoDrgWo5HHSOcVEaS33HLL6u3zzjsvL7169UojR47M97355ps5ZL/77rtplVVWSTvssEN69NFH888AAACwWAXvcMQRR+SlPpUwXdG1a9dUU1Pzhdu7+eab52c3AAAAoNlrFqOaAwAAwKJK8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAAAoSPAGAACAggRvAAAAKEjwBgAAgIIEbwAAAChI8AYAAICCBG8AAABobsH7sssuS127dk3t27dP2267bRo9evRc133++efT3nvvnddv1apVuuiiixZ4mwAAALDIBu/hw4engQMHpsGDB6cnn3wyde/ePfXp0ydNnjy53vU//vjj1K1btzRs2LDUuXPnRtkmAAAALLLB+4ILLkiHHHJIGjBgQNp4443TFVdckZZeeul0zTXX1Lt+z54907nnnpv222+/1K5du0bZJgAAACySwXvGjBlpzJgxqXfv3v+3gdat8+1Ro0bN1w7MzzanT5+epk2bVmcBAACAFh+833nnnTRz5szUqVOnOvfH7YkTJ87XDszPNocOHZo6dOhQXdZYY435em0AAAAorUWOan7SSSelqVOnVpfx48c39S4BAABAvZZIDdCxY8fUpk2bNGnSpDr3x+25DZxWYpvRV3xu/cUBAACgxVa827Ztm3r06JHuv//+6n2zZs3Kt7fbbrv52oES2wQAAIAWWfEOMe1X//7909Zbb5222WabPC/3Rx99lEckD/369UurrbZa7oddGTzthRdeqP781ltvpaeffjotu+yyad11152nbQIAAMBiE7z79u2bpkyZkgYNGpQHP9tiiy3SiBEjqoOjjRs3Lo9KXjFhwoS05ZZbVm+fd955eenVq1caOXLkPG0TAAAAFpvgHY444oi81KcSpiu6du2aampqFmibAAAA0FK1yFHNAQAAoKUQvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAACaW/C+7LLLUteuXVP79u3Ttttum0aPHv2F6996661pww03zOtvttlm6a677qrz+IEHHphatWpVZ9lll13mZ9cAAACgZQfv4cOHp4EDB6bBgwenJ598MnXv3j316dMnTZ48ud71H3nkkbT//vungw8+OD311FNpzz33zMtzzz1XZ70I2m+//XZ1+f3vfz//7woAAABaavC+4IIL0iGHHJIGDBiQNt5443TFFVekpZdeOl1zzTX1rn/xxRfnUH3ccceljTbaKJ1xxhlpq622Spdeemmd9dq1a5c6d+5cXVZcccX5f1cAAADQEoP3jBkz0pgxY1Lv3r3/bwOtW+fbo0aNqvc5cX/t9UNUyGdff+TIkekrX/lK2mCDDdJhhx2W3n333bnux/Tp09O0adPqLAAAANDig/c777yTZs6cmTp16lTn/rg9ceLEep8T93/Z+lERv+GGG9L999+fzj777PTggw+mXXfdNb9WfYYOHZo6dOhQXdZYY42GvA0AAABYaJZIzcB+++1X/TkGX9t8883TOuusk6vgO+200xzrn3TSSbmfeUVUvIVvAAAAWnzFu2PHjqlNmzZp0qRJde6P29Evuz5xf0PWD926dcuvNXbs2Hofj/7gyy+/fJ0FAAAAWnzwbtu2berRo0duEl4xa9asfHu77bar9zlxf+31w7333jvX9cObb76Z+3h36dKlIbsHAAAALX9U82jifdVVV6Xrr78+vfjii3kgtI8++iiPch769euXm4JXHH300WnEiBHp/PPPTy+99FIaMmRIeuKJJ9IRRxyRH//www/ziOePPvpoev3113NI32OPPdK6666bB2EDAACAxaqPd9++fdOUKVPSoEGD8gBpW2yxRQ7WlQHUxo0bl0c6r9h+++3TTTfdlE455ZR08sknp/XWWy/dcccdadNNN82PR9P1Z599Ngf5999/P6266qpp5513ztOORZNyAAAAWOwGV4tqdaViPbsYEG12++67b17qs9RSS6W77757fnYDAAAAFr2m5gAAAMC8E7wBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAmlvwvuyyy1LXrl1T+/bt07bbbptGjx79hevfeuutacMNN8zrb7bZZumuu+6q83hNTU0aNGhQ6tKlS1pqqaVS79690yuvvDI/uwYAAAAtO3gPHz48DRw4MA0ePDg9+eSTqXv37qlPnz5p8uTJ9a7/yCOPpP333z8dfPDB6amnnkp77rlnXp577rnqOuecc0665JJL0hVXXJEee+yxtMwyy+Rtfvrppwv27gAAAKClBe8LLrggHXLIIWnAgAFp4403zmF56aWXTtdcc02961988cVpl112Sccdd1zaaKON0hlnnJG22mqrdOmll1ar3RdddFE65ZRT0h577JE233zzdMMNN6QJEyakO+64Y8HfIQAAADShJRqy8owZM9KYMWPSSSedVL2vdevWuWn4qFGj6n1O3B8V8tqiml0J1a+99lqaOHFi3kZFhw4dchP2eO5+++03xzanT5+el4qpU6fmf6dNm5ZaglnTP27qXaCgaa1qmnoXKK2FHGsak+PWos1xazGwmB23HLMWfY5bi4Fpzf+4VcmfUUxu1OD9zjvvpJkzZ6ZOnTrVuT9uv/TSS/U+J0J1fevH/ZXHK/fNbZ3ZDR06NJ122mlz3L/GGms05O1AER2aegcob5jfMosW3+jFgOMWixjf6MXAsJbzW/7ggw9y8bjRgndzERX32lX0WbNmpffeey+tvPLKqVWrVk26byze4qpXXAAaP358Wn755Zt6dwC+lOMW0NI4btFcRKU7Qveqq676pes2KHh37NgxtWnTJk2aNKnO/XG7c+fO9T4n7v+i9Sv/xn0xqnntdbbYYot6t9muXbu81LbCCis05K1AUfFHwB8CoCVx3AJaGsctmoMvq3TP1+Bqbdu2TT169Ej3339/nWpz3N5uu+3qfU7cX3v9cO+991bXX3vttXP4rr1OXMWK0c3ntk0AAABoKRrc1DyaePfv3z9tvfXWaZtttskjkn/00Ud5lPPQr1+/tNpqq+V+2OHoo49OvXr1Sueff376zne+k26++eb0xBNPpCuvvDI/Hk3DjznmmHTmmWem9dZbLwfxU089NZfrY9oxAAAAWKyCd9++fdOUKVPSoEGD8uBn0Rx8xIgR1cHRxo0bl0c6r9h+++3TTTfdlKcLO/nkk3O4jhHNN9100+o6xx9/fA7vhx56aHr//ffTDjvskLfZvn37xnqfsFBEF4iY4372rhAAzZXjFtDSOG7RErWqmZexzwEAAID50qA+3gAAAEDDCN4AAABQkOANAAAABQnekFIaOXJkHmE/BvcL11133RfODf/666/n9WOZ23zzC2ufYzEDACyehgwZ8qXHoAMPPPALjxFxvKscS2KWkaZ6H5V9iNlSABqqa9eu1eNI5XxuYau8/hedQ7L4ErxZbIwaNSq1adMmT2vXWO67777qHPS1D/j1LXHyO79i27OfjMaMAW+//Xb6/ve/v8DvA1j4YmaQI488MnXr1i2PzLvGGmuk3XffvXpMWZiWX375fDw544wz6lxYnNsSYX1+VLb99NNP17n/2GOPza+/+uqrN9I7AubXFVdckZZbbrn0+eefV+/78MMP05JLLpm+8Y1v1FsEePXVV1NzcPrpp+djSYcOHfJ51xcdx+Lcan7N7YJmvLaLhzTadGLQUv3mN7/JJ7nx74QJE/Jc8Qtq5ZVXzkt4/PHH08yZM/PPjzzySNp7773Tyy+/nE9ow1JLLZUaU9u2bVPnzp3zdqdPn96o2wbKigD6ta99LVdFzj333LTZZpulzz77LN19993ppz/9aXrppZcW6v7ESWgcT8LSSy+dTx4rzjvvvDzFZ1xorIiT2sa07LLL5iUujgJN65vf/GYO2k888UT66le/mu/75z//mY8Rjz32WPr000+rU/4+8MADac0110zrrLNOg18nJlaK86Yllmi8OBIXDCrHsosvvjgNGzas+liXLl3Stddem3bZZZd8u8TxJl67sY+PLDpUvFksxB+Q4cOHp8MOOyxXvOe3WvNFVllllXzAjWWllVbK933lK1+p3hdXhbfaaqv8xyoqXKeddlr1anL88YmmlvHHKypfcVHgqKOOyo/F1eU33ngj/exnP6tepQVatsMPPzz/Xx49enS+SLf++uunTTbZJA0cODA9+uij1fXGjRuX9thjjxxK4yJetHCZNGnSXLcbJ7GxjQj0cVHw+OOPz8eXhoiT0cpxK5Z47TgxrtyO41pUdNZee+184a979+7pD3/4Q/X5//nPf9IBBxyQj4nx+HrrrZdPdkM8J2y55Zb5/c9ePQOa3gYbbJBDapy3VMTPcSyK/8O1j1FxfwT18Nvf/jZtvfXW1fD7X//1X2ny5Ml11o3/93/7299Sjx498vnOQw89lI8DURiJri4rrrhi6tSpU7rqqqvSRx99lAYMGJC3t+666+bnNUQE4NrHshDHxsrtOJbuuuuu+RgXr/nDH/4wvfPOO9Xnx3EtLorGcSyOp7179877FOdr119/ffrTn/5UPS+r/VnB3AjeLBZuueWWtOGGG+Y/Jj/4wQ/SNddc0+CT0QURV4r79euXjj766PTCCy+kX//61zn8n3XWWfnxP/7xj+nCCy/M97/yyivpjjvuyAf7cNttt+Xml5XmU7UrUUDL89577+UKclS2l1lmmTker/QNnDVrVj7RjfUffPDBdO+996b/+Z//SX379p3rts8///x8bIljXJzQxnNvv/32Rt3/oUOHphtuuCE3R33++efzRcE4rsY+hlNPPTUf5+Ik+cUXX0yXX3556tixY34sLjSEqJ7HsSyOb0DzE2E6qtkV8XME5F69elXv/+STT3IFvBK8o9VOdFd55pln8nlMtOypr5vdiSeemCvRcXzYfPPN830RZOM4EceICOFRKNl3331zt7onn3wy7bzzzjkYf/zxx43y/qIP+Le+9a18ETAq+3FMjiBe6b4Xx6f9998/HXTQQXk/I1h/73vfy+eO0TUm1ovKeeW8LPYTvoym5iwWonl5nBiGOFBOnTo1nyQurGpLVLfjD03//v3z7ah4xx+nqEYNHjw4V7Xi6mtcTY0+VFH53mabbfK6UT2PClTt5lNAyzV27Nh88hYXA79I9PX+17/+lV577bXc/ztE4I3KeHRt6dmz5xzPiUr0SSedlE8QQ4TjaL7eWKJbyy9/+cscnLfbbrvq8SxCflw4jJPyOJ7FyWxUvkLtfpRRBQ9RPXI8g+YrwnRUoKNlXgTsp556Kv//jnAdx5XK2DlxTKgE7wipFXFcuOSSS/JxKlodRlW5IgoJ3/72t+u8XrScOeWUU/LPcQyLYB5B/JBDDsn3DRo0KF/Ee/bZZ6vN3xfEpZdemo9TcTyriAuWcaz997//nfc53nscS9daa638eKUgEird/BzHaAgVbxZ50c86rqDGlcsQTSajYhRhfGGJq7/xh6bSjzGW+GMSV0nj6m1c1Y0/bPGHKu6PClXtQU2ARce8traJKkucBFZCd9h4441zRTwem11cUIxjyrbbblu9L453lQDcWBcN4pgVJ821j2dxQaAyuFJUqm6++eY82npcXIwxL4CWJQoT0aw6LvJFq73oDhMXziJ8V/p5RxU4zluiWBDGjBmTB4iM21EsiHVDXIyrrb5jUqXyHaLYEBfnagfdaAoeajddX9Dzsqjc1z6OVS6GxrEsLgTstNNOeR/iHC2avkc3GlgQKt4s8iJgR4itPZhanPhG36K44rkwBsGIK6dR9a5UoWqLPt9xYh0XCKKKFM1Jo/9nDLgUVfmogAOLjujzHH0CF/YAao11LAt33nlnWm211eo8FsfUEH0mY1yKu+66Kx/P4uQ1mtXHIG1AyxB9qqObW4TTCJyVEB3nUnHOEhfU4rForh0ipPfp0ycvN954Yw7pEbjj9owZM+psu74uNrOf68QxsvZ9lfFtogtOYx3L4iLB2WefPcdj0b89wn8cv+J93nPPPelXv/pV+sUvfpEvOlTGqoCGUvFmkRaBOyox0e8xpq+pLHGlM/54/P73v18o+xGDqkWwjj9ksy+tW7euNluKPwLRNCuuIkcTrmhmWhnBvDJiOtCyRfeROBm97LLL8snq7Crzz2600UZp/PjxeamIvtPxeFS+ZxcXEeOEMU4Max8DowrVWOJ1I2DHCfXsx7Lalfk46Y6uNb/73e9y8/crr7yyeiwLjmfQ/EUT8jgfiaV217yvf/3reQyHaE1YaWYeFxLffffd3ER8xx13zNXjxqpOlzovizEqoivM7MeyyoWBCPsx+0QUTqKpfRy/KmNmOC9jfqh4s0j761//mq/UHnzwwXNUtmMk4aiG/+QnPym+H9E36bvf/W5ufrXPPvvksB3h/7nnnktnnnlmHgwpDuDRRDSm8omT1QjilX5F8YfhH//4R9pvv/3ySW9loCKgZYrQHSd0MZZDdEOJZpYRkqPCEv0Yoyl5jPkQzRxjhPAIr/F4tIaJytPcmo/HAI5x4htV9TjxveCCC6pBvjFE89EYWCgGVIvK0w477JCbuD/88MN51PUI23G8ixGLoy969IGM43BcRAgxInoc22Igo6imRYsfU+9A8xShOlqrRL/uSsU7xM9HHHFErmRXgnec30QYjcpwnFfF+U2MZdNcxfuK5uPRDTG6xMQF0ehKE91krr766jzgWoyzEYO6xXErLmhOmTKleiyL87IYPyOKKtEsPo5jWijyZVS8WaRFsI6T1/pO7CJ4x4E1BuooLapbcfIZzZVioJEYGCRGMa8E6+izGX8A4kQ8TsCjyflf/vKX6hzhcWIeo4PGPJmVwYmAliv6RcZIvXHS+vOf/zxtuummud90nOhF8K5UW2K6mpheJypMcSyL58XUiHMT24qRfyMAx+BnEZT32muvRt33OJmOkctjdPM4CY0BK6PpeaX5ZZx8x+BIcSyL/Y4mm3EyW+lzHq16YiC2aHUUo7YDzVMcn2L8magCV/pYV4L3Bx98UJ12LMS5SRQRbr311twyJi4ANufuJXH8iQuGUfSIcB0XOWMwuTgfi+JIXEiMgsduu+2W+7fHwG/RejK60oQYjyfef1wEjfce24Iv06pmYc6pBIuICMFxkhlNj2IAoaYUU3VERSum7gBoqDhZjhPOxqyMz6+oIsW+xALQEo8fzemYSvOi4g0LIOZtbKq5G2OU0RiFMwYxAVgQ0Vw8jicnnHBCk7x+TOkTrz/76McADRHHsDiWxDGtKcRrL4wujLRMKt4wH6KvZVS9Q/S5rj2o0MISzb/eeuut6oHeXJLA/Igmo5MmTco/RzPLphhD4r333stLiGab+n0DDRWzKUR/9BDdciqD1y5M0U88RBcbo58zO8EbAAAACtLUHAAAAAoSvAEAAKAgwRsAAAAKErwBAACgIMEbAAAAChK8AQAAoCDBGwAAAAoSvAEAAKAgwRsAAABSOf8fHXAj9qw1BqwAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved charts: hr10.png, ndcg10.png\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41ffa7c5da9ce986"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
