{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cross-Domain Recommendation System Development\n",
    "This notebook is an experiment in building a cross-domain recommendation system using the Amazon Reviews dataset. It uses the best model from the single-domain experiments and extends it to handle multiple domains."
   ],
   "id": "f897965258465d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:02:10.227470Z",
     "start_time": "2025-08-28T19:02:04.867231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"D:/Python Projects/recommendation_system\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"D:/Python Projects/recommendation_system/recsys/data\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/Python Projects/recommendation_system/recsys/models\"\n",
    "\n",
    "# os.environ[\"HF_HOME\"] = \"E:/Python Scripts/recsys\"\n",
    "# os.environ['HF_DATASETS_CACHE'] = \"E:/Python Scripts/recsys/data\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = \"E:/Python Scripts/recsys/models\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import load_dataset, Features, Value\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter"
   ],
   "id": "34a5366879dad399",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:02:10.269744Z",
     "start_time": "2025-08-28T19:02:10.240002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)"
   ],
   "id": "bf6eb90595456a15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single-domain development on best model (SASRec)",
   "id": "f50b5b1c0a2ae4cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:02:10.298396Z",
     "start_time": "2025-08-28T19:02:10.290375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HF_DATASET = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "\n",
    "def load_amazon_reviews(domain, save_dir=\"data\", max_items=None, seed=SEED):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filepath = f\"{save_dir}/amazon_reviews_{domain}.csv\"\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {filepath} not found. Downloading dataset for domain '{domain}'...\")\n",
    "        ds = load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "            f\"raw_review_{domain}\",\n",
    "            split=\"full\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        # Keep only needed columns\n",
    "        ds = ds.select_columns([\"user_id\", \"parent_asin\", \"rating\", \"timestamp\"])\n",
    "        ds = ds.rename_columns({\"user_id\": \"user\", \"parent_asin\": \"item\"})\n",
    "        ds = ds.cast(Features({\n",
    "            \"user\": Value(\"string\"),\n",
    "            \"item\": Value(\"string\"),\n",
    "            \"rating\": Value(\"float32\"),\n",
    "            \"timestamp\": Value(\"int64\"),\n",
    "        }))\n",
    "\n",
    "        # Convert to pandas (Arrow zero-copy where possible)\n",
    "        df = ds.to_pandas()\n",
    "        df.insert(3, \"domain\", domain)\n",
    "        df.to_csv(f\"{save_dir}/amazon_reviews_{domain}.csv\", index=False)\n",
    "        print(f\"Saved amazon_reviews_{domain}.csv to {save_dir}/\")\n",
    "\n",
    "    final_df = pd.read_csv(filepath)\n",
    "    # Random subset if max_items is set\n",
    "    if max_items is not None:\n",
    "        k = min(max_items, len(final_df))\n",
    "        final_df = final_df.sample(n=k, random_state=seed).reset_index(drop=True)\n",
    "    print(f\"Loaded {filepath} with {len(final_df)} rows.\")\n",
    "    return final_df\n",
    "\n",
    "def preprocess_dataset(df, min_user_interactions=5, min_item_interactions=5):\n",
    "    # Make it implicit\n",
    "    df[\"label\"] = 1.0\n",
    "    user_counts = df.groupby(\"user\").size()\n",
    "    valid_users = user_counts[user_counts >= min_user_interactions].index\n",
    "    item_counts = df.groupby(\"item\").size()\n",
    "    valid_items = item_counts[item_counts >= min_item_interactions].index\n",
    "    df_filtered = df[df[\"user\"].isin(valid_users) & df[\"item\"].isin(valid_items)]\n",
    "    print(\"After interactions filtering:\", len(df_filtered), \"rows,\", df_filtered[\"user\"].nunique(), \"users,\", df_filtered[\"item\"].nunique(), \"items\")\n",
    "    return df_filtered\n",
    "\n",
    "def label_encoder(df, shift_item_id=False):\n",
    "    df_encoded = df.copy()\n",
    "    user_enc = LabelEncoder()\n",
    "    item_enc = LabelEncoder()\n",
    "    domain_enc = LabelEncoder()\n",
    "    df_encoded[\"user_id\"] = user_enc.fit_transform(df_encoded[\"user\"])\n",
    "    df_encoded[\"item_id\"] = item_enc.fit_transform(df_encoded[\"item\"])\n",
    "    if shift_item_id:\n",
    "        df_encoded[\"item_id\"] = df_encoded[\"item_id\"] + 1  # Shift item IDs by 1 to reserve 0 for padding if needed\n",
    "    df_encoded[\"domain_id\"] = domain_enc.fit_transform(df_encoded[\"domain\"])\n",
    "    return df_encoded, user_enc, item_enc, domain_enc"
   ],
   "id": "fea6ebca4ab2462c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset preparation",
   "id": "48521a298928c450"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:03:58.730801Z",
     "start_time": "2025-08-28T19:02:10.307543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New input\n",
    "SOURCE_DOMAIN = \"Books\"\n",
    "\n",
    "# Loading data from multiple domains\n",
    "df = load_amazon_reviews(SOURCE_DOMAIN, max_items=15_000_000, seed=SEED)\n",
    "print(f\"Total rows in {SOURCE_DOMAIN}: {len(df)}\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "filtered_df = preprocess_dataset(df, min_user_interactions=10, min_item_interactions=10)\n",
    "df_encoded, user_encoder, item_encoder, domain_encoder = label_encoder(filtered_df, shift_item_id=True)\n",
    "\n",
    "NUM_USERS = df_encoded[\"user_id\"].max() + 1\n",
    "NUM_ITEMS = df_encoded[\"item_id\"].max() + 1"
   ],
   "id": "469ec0275e5a1c20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/amazon_reviews_Books.csv with 15000000 rows.\n",
      "Total rows in Books: 15000000\n",
      "After interactions filtering: 2002738 rows, 154220 users, 236541 items\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:07.255489Z",
     "start_time": "2025-08-28T19:03:58.795106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_user_sequences(df):\n",
    "    df_sorted = df.sort_values([\"user_id\", \"timestamp\"])\n",
    "    user_sequences = {}\n",
    "    for uid, group in df_sorted.groupby(\"user_id\"):\n",
    "        items = group[\"item_id\"].tolist()\n",
    "        user_sequences[uid] = items\n",
    "\n",
    "    print(f\"Number of users: {len(user_sequences)}\")\n",
    "    print(f\"Max sequence length: {max(len(seq) for seq in user_sequences.values())}\")\n",
    "    print(f\"Min sequence length: {min(len(seq) for seq in user_sequences.values())}\")\n",
    "\n",
    "    return user_sequences\n",
    "\n",
    "# Create sequences\n",
    "user_sequences = create_user_sequences(df_encoded)\n",
    "pos_items_by_user = {u: set(seq) for u, seq in user_sequences.items()}"
   ],
   "id": "c76b37ce901249d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 154220\n",
      "Max sequence length: 1146\n",
      "Min sequence length: 1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:08.706319Z",
     "start_time": "2025-08-28T19:04:07.265050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequences_loo_split(user_sequences):\n",
    "    train_seqs = {}\n",
    "    val_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for user, seq in user_sequences.items():\n",
    "        if len(seq) < 3:  # Need at least 3 items for train/val/test\n",
    "            continue\n",
    "\n",
    "        train_seqs[user] = seq[:-2]  # All but last two\n",
    "        val_data[user] = (seq[:-2], seq[-2])  # Train on all but last 2, predict second-to-last\n",
    "        test_data[user] = (seq[:-1], seq[-1])  # Train on all but last, predict last\n",
    "\n",
    "    print(f\"Training sequences: {len(train_seqs)}\")\n",
    "    print(f\"Validation users: {len(val_data)}\")\n",
    "    print(f\"Test users: {len(test_data)}\")\n",
    "\n",
    "    return train_seqs, val_data, test_data\n",
    "\n",
    "train_sequences, val_sequences, test_sequences = sequences_loo_split(user_sequences)\n",
    "print(f\"Sequences - Train: {len(train_sequences)}, Val: {len(val_sequences)}, Test: {len(test_sequences)}\")"
   ],
   "id": "f25ac4008c7f94b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences: 145957\n",
      "Validation users: 145957\n",
      "Test users: 145957\n",
      "Sequences - Train: 145957, Val: 145957, Test: 145957\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset and DataLoader",
   "id": "f04c70046f9e7ad2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:13.988100Z",
     "start_time": "2025-08-28T19:04:08.726907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SASRecDataset(Dataset):\n",
    "    def __init__(self, data, num_items, max_seq_len=50, pos_items_by_user=None, mode=\"train\", neg_samples=1):\n",
    "        self.num_items = num_items\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.mode = mode\n",
    "        self.neg_samples = neg_samples\n",
    "        self.all_pos = pos_items_by_user\n",
    "\n",
    "        self.samples = []\n",
    "        if mode == \"train\":\n",
    "            for user, seq in data.items():\n",
    "                for i in range(1, len(seq)):\n",
    "                    self.samples.append({\n",
    "                        \"user\": user,\n",
    "                        \"input_seq\": seq[:i],\n",
    "                        \"target\": seq[i],\n",
    "                        \"full_seq\": seq # For negative sampling\n",
    "                    })\n",
    "        else:\n",
    "            for user, (seq, target) in data.items():\n",
    "                self.samples.append({\n",
    "                    \"user\": user,\n",
    "                    \"input_seq\": seq,\n",
    "                    \"target\": target,\n",
    "                    \"full_seq\": seq + [target]\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        user = sample[\"user\"]\n",
    "        seq = sample[\"input_seq\"]\n",
    "        target = sample[\"target\"]\n",
    "\n",
    "        # Truncate sequence if > max length\n",
    "        if len(seq) > self.max_seq_len:\n",
    "            seq = seq[-self.max_seq_len:]\n",
    "\n",
    "        # Left-pad sequence with zeros\n",
    "        pad_len = self.max_seq_len - len(seq)\n",
    "        padded_seq = [0] * pad_len + seq\n",
    "\n",
    "        # Negative sampling\n",
    "        forbid = self.all_pos[user] if self.all_pos is not None else set(sample[\"full_seq\"])\n",
    "        neg_items = set()\n",
    "\n",
    "        while len(neg_items) < self.neg_samples:\n",
    "            neg = random.randint(1, self.num_items - 1)\n",
    "            if neg not in forbid:\n",
    "                neg_items.add(neg)\n",
    "\n",
    "        return {\n",
    "            \"user\": sample[\"user\"],\n",
    "            \"input_seq\": torch.tensor(padded_seq, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target, dtype=torch.long),\n",
    "            \"neg_items\": torch.tensor(list(neg_items), dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SASRecDataset(train_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"train\", neg_samples=4)\n",
    "val_dataset = SASRecDataset(val_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"val\", neg_samples=99)\n",
    "test_dataset = SASRecDataset(test_sequences, NUM_ITEMS, pos_items_by_user=pos_items_by_user, max_seq_len=50, mode=\"test\", neg_samples=99)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ],
   "id": "cfbf122d3ffecc46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1551543\n",
      "Validation samples: 145957\n",
      "Test samples: 145957\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.014511Z",
     "start_time": "2025-08-28T19:04:14.004638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data loaders\n",
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "c787a877f937b32b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.204708Z",
     "start_time": "2025-08-28T19:04:14.023058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = next(iter(train_loader))\n",
    "print(\"Sample batch from loader:\")\n",
    "print(\"Input sequence shape:\", first[\"input_seq\"].shape)\n",
    "print(\"Target shape:\", first[\"target\"].shape)\n",
    "print(\"Negative items shape:\", first[\"neg_items\"].shape)\n",
    "\n",
    "batch_size_in_first = first[\"input_seq\"].shape[0]\n",
    "\n",
    "print(\"\\nSample input sequence:\")\n",
    "random_index = []\n",
    "for _ in range(5):\n",
    "    random_index.append(random.randint(0, batch_size_in_first - 1))\n",
    "\n",
    "for i in random_index:\n",
    "    print(first[\"input_seq\"][i])"
   ],
   "id": "ad31e89eec90a58c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch from loader:\n",
      "Input sequence shape: torch.Size([512, 50])\n",
      "Target shape: torch.Size([512])\n",
      "Negative items shape: torch.Size([512, 4])\n",
      "\n",
      "Sample input sequence:\n",
      "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0, 94948, 29184, 29171])\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,  28797, 204941,\n",
      "        209828, 209614, 141818, 206079, 217247])\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0, 148739, 221022, 220825, 192594, 149400, 224099, 220505, 223373,\n",
      "        226930, 109090, 227734, 228297, 228489])\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,  38891,  15957,  43155,  43987,\n",
      "          3422, 113151,     41,  24575, 118325])\n",
      "tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,  90276,\n",
      "         22968,  23002,  66796, 157286,  36044,  36043,    648,  23080,  60690,\n",
      "         69025,  40755,  28990,  49673,  23131])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create SASRec model",
   "id": "ee51311214a572b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.228571Z",
     "start_time": "2025-08-28T19:04:14.212637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Building SASRec model\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(self.dropout(self.relu(self.w1(x))))\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Layer norms\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Feed-forward network\n",
    "        self.ffn = PointWiseFeedForward(hidden_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # Self-attention with residual connection\n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=attn_mask)\n",
    "        x = self.ln1(x + self.dropout(attn_out))\n",
    "\n",
    "        # Feed-forward network with residual connection\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.ln2(x + self.dropout(ffn_out))\n",
    "\n",
    "        return x\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_items,\n",
    "                 hidden_dim=64,\n",
    "                 max_seq_len=50,\n",
    "                 num_blocks=2,\n",
    "                 num_heads=2,\n",
    "                 dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_items = num_items\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # Embedding layers\n",
    "        self.item_embed = nn.Embedding(num_items, hidden_dim, padding_idx=0)\n",
    "        self.positional_embed = nn.Embedding(max_seq_len, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Stack of SASRec blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            AttentionBlock(hidden_dim, num_heads, dropout) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        # Final layer norm\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_normal_(self.item_embed.weight[1:])  # Skip padding idx\n",
    "        nn.init.xavier_normal_(self.positional_embed.weight)\n",
    "\n",
    "    def forward(self, input_seq, candidate_items=None):\n",
    "        batch_size, seq_len = input_seq.shape\n",
    "\n",
    "        # Get item embeddings\n",
    "        item_embeds = self.item_embed(input_seq)  # [B, L, D]\n",
    "\n",
    "        # Add positional embeddings\n",
    "        positions = torch.arange(seq_len, device=input_seq.device).unsqueeze(0)\n",
    "        pos_embeds = self.positional_embed(positions)  # [1, L, D]\n",
    "        x = self.dropout(item_embeds + pos_embeds)\n",
    "\n",
    "        # Create causal attention mask\n",
    "        attn_mask = self._create_causal_mask(seq_len, input_seq.device)\n",
    "        pad_mask = input_seq.eq(0)\n",
    "\n",
    "        # Pass through transformer blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "\n",
    "        # Final layer norm\n",
    "        x = self.ln(x)  # [B, L, D]\n",
    "        x = x.masked_fill(pad_mask.unsqueeze(-1), 0.0)\n",
    "\n",
    "        # If candidate_items provided, score them\n",
    "        if candidate_items is not None:\n",
    "            # Get embeddings for candidate items\n",
    "            cand_emb = self.item_embed(candidate_items) # [B, N, D]\n",
    "\n",
    "            # Use last position's representation for scoring\n",
    "            last_hidden = x[:, -1, :].unsqueeze(1)  # [B, 1, D]\n",
    "\n",
    "            # Compute scores via dot product\n",
    "            scores = torch.matmul(last_hidden, cand_emb.transpose(1, 2)).squeeze(1) # [B, N]\n",
    "            return scores\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _create_causal_mask(self, seq_len, device):\n",
    "        mask = torch.full((seq_len, seq_len), 0.0, device=device)\n",
    "        mask = mask.masked_fill(torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1).bool(), float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def predict_next(self, input_seq):\n",
    "        # Get sequence representations\n",
    "        seq_repr = self.forward(input_seq)  # [B, L, D]\n",
    "\n",
    "        # Use last position for prediction\n",
    "        last_hidden = seq_repr[:, -1, :]  # [B, D]\n",
    "\n",
    "        # Score against all item embeddings\n",
    "        all_item_embeds = self.item_embed.weight  # [num_items, D]\n",
    "        scores = torch.matmul(last_hidden, all_item_embeds.T)  # [B, num_items]\n",
    "        return scores"
   ],
   "id": "6af96d98ee3a7051",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and evaluation functions",
   "id": "126fb73d3965ec4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.241155Z",
     "start_time": "2025-08-28T19:04:14.235096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_sasrec_epoch(model, train_loader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        input_seq = batch[\"input_seq\"].to(device)\n",
    "        pos_items = batch[\"target\"].to(device)\n",
    "        neg_items = batch[\"neg_items\"].to(device)\n",
    "\n",
    "        # Get predictions for last position\n",
    "        seq_output = model(input_seq)  # [B, L, D]\n",
    "        last_hidden = seq_output[:, -1, :]  # [B, D]\n",
    "\n",
    "        # Get embeddings for positive and negative items\n",
    "        pos_embeds = model.item_embed(pos_items)\n",
    "        neg_embeds = model.item_embed(neg_items)\n",
    "\n",
    "        # Compute logits\n",
    "        pos_logits = (last_hidden * pos_embeds).sum(dim=1)\n",
    "        neg_logits = torch.bmm(neg_embeds, last_hidden.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # Binary cross-entropy loss with logits\n",
    "        pos_labels = torch.ones_like(pos_logits)\n",
    "        neg_labels = torch.zeros_like(neg_logits)\n",
    "\n",
    "        # Concatenate logits and labels\n",
    "        all_logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)\n",
    "        all_labels = torch.cat([pos_labels.unsqueeze(1), neg_labels], dim=1)\n",
    "\n",
    "        loss = loss_fn(all_logits, all_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches"
   ],
   "id": "89794d62607239d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.257172Z",
     "start_time": "2025-08-28T19:04:14.249179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validation loss and ranking metrics\n",
    "@torch.no_grad()\n",
    "def evaluate_sasrec(model, eval_loader, loss_fn, k=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_hr = 0.0\n",
    "    sum_ndcg = 0.0\n",
    "    sum_prec = 0.0\n",
    "    sum_mrr = 0.0\n",
    "\n",
    "    sum_val_loss = 0.0\n",
    "    n_loss_batches = 0\n",
    "\n",
    "    for batch in tqdm(eval_loader, desc=\"Evaluating\"):\n",
    "        input_seq = batch[\"input_seq\"].to(device)\n",
    "        target = batch[\"target\"].to(device)\n",
    "        neg_items = batch[\"neg_items\"].to(device)\n",
    "\n",
    "        batch_size = input_seq.size(0)\n",
    "\n",
    "        # Create candidate set: 1 positive + negatives\n",
    "        seq_output = model(input_seq)  # [B, L, D]\n",
    "        last_hidden = seq_output[:, -1, :]  # [B, D]\n",
    "        candidates = torch.cat([\n",
    "            target.unsqueeze(1),  # [B, 1]\n",
    "            neg_items  # [B, neg_samples]\n",
    "        ], dim=1)  # [B, 1 + neg_samples]\n",
    "\n",
    "        # Get embeddings for all candidates\n",
    "        cand_emb = model.item_embed(candidates)  # [B, 1+neg_samples, D]\n",
    "        scores = torch.bmm(cand_emb, last_hidden.unsqueeze(-1)).squeeze(-1)  # [B, 1+neg_samples]\n",
    "\n",
    "        # sanity: positive not in negatives\n",
    "        if torch.any((candidates[:, 1:] == target.unsqueeze(1)).any(dim=1)):\n",
    "            raise RuntimeError(\"Positive item appeared in negatives for some samples.\")\n",
    "\n",
    "        # Loss calculation\n",
    "        pos_scores = scores[:, 0]\n",
    "        neg_scores = scores[:, 1:]\n",
    "        pos_labels = torch.ones_like(scores[:, 0])\n",
    "        neg_labels = torch.zeros_like(scores[:, 1:])\n",
    "        all_scores = torch.cat([pos_scores.unsqueeze(1), neg_scores], dim=1)\n",
    "        all_labels = torch.cat([pos_labels.unsqueeze(1), neg_labels], dim=1)\n",
    "        batch_loss = loss_fn(all_scores.reshape(-1), all_labels.reshape(-1))\n",
    "        sum_val_loss += batch_loss.item()\n",
    "        n_loss_batches += 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        _, full_idx = torch.sort(scores, dim=1, descending=True)\n",
    "        rank  = (full_idx == 0).nonzero(as_tuple=True)[1] + 1  # Rank of the positive item (1-based)\n",
    "\n",
    "        hit = (rank <= k).float()\n",
    "        ndcg = torch.where(rank <= k, 1.0 / torch.log2(rank.float() + 1), torch.zeros_like(hit))\n",
    "        precision = hit / float(k)\n",
    "        mrr = torch.where(rank <= k, 1.0 / rank.float(), torch.zeros_like(hit))\n",
    "\n",
    "        sum_hr += hit.sum().item()\n",
    "        sum_ndcg += ndcg.sum().item()\n",
    "        sum_prec += precision.sum().item()\n",
    "        sum_mrr += mrr.sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    metrics = {\n",
    "        \"HR@K\": sum_hr / total if total else 0.0,\n",
    "        \"NDCG@K\": sum_ndcg / total if total else 0.0,\n",
    "        \"Precision@K\": sum_prec / total if total else 0.0,\n",
    "        \"MRR@K\": sum_mrr / total if total else 0.0,\n",
    "        \"Val loss\": sum_val_loss / max(n_loss_batches, 1)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "id": "206c2ec3b34e4147",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:04:14.272709Z",
     "start_time": "2025-08-28T19:04:14.265686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sasrec_trainer(\n",
    "        model,\n",
    "        train_loader,\n",
    "        eval_loader,\n",
    "        epochs,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        k=10,\n",
    "        device=\"cpu\",\n",
    "        save_dir=\"model\"\n",
    "    ):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.to(device)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    train_losses, val_losses, val_metrics_log = [], [], []\n",
    "    best_ndcg, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Train (batched)\n",
    "        train_loss = train_sasrec_epoch(model, train_loader, loss_fn, optimizer, device=device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Eval (batched)\n",
    "        m = evaluate_sasrec(model, eval_loader, loss_fn, k=k, device=device)\n",
    "        val_losses.append(m[\"Val loss\"])\n",
    "        val_metrics_log.append({k_: m[k_] for k_ in [\"HR@K\", \"NDCG@K\", \"Precision@K\", \"MRR@K\"]})\n",
    "\n",
    "        # Checkpointing by NDCG\n",
    "        if m[\"NDCG@K\"] > best_ndcg:\n",
    "            best_ndcg = m[\"NDCG@K\"]\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_model_src.pth\"))\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"last_model_src.pth\"))\n",
    "\n",
    "        # TB logs\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", m[\"Val loss\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_HR@{k}\", m[\"HR@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_NDCG@{k}\", m[\"NDCG@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_Precision@{k}\", m[\"Precision@K\"], epoch)\n",
    "        writer.add_scalar(f\"Metrics/Val_MRR@{k}\", m[\"MRR@K\"], epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}  \"\n",
    "            f\"Train loss {train_loss:.4f}  \"\n",
    "            f\"Val loss {m['Val loss']:.4f}  \"\n",
    "            f\"HR@{k} {m['HR@K']:.4f}  \"\n",
    "            f\"NDCG@{k} {m['NDCG@K']:.4f}  \"\n",
    "            f\"Precision@{k} {m['Precision@K']:.4f}  \"\n",
    "            f\"MRR@{k} {m['MRR@K']:.4f}  \"\n",
    "            f\"{'(new best)' if m['NDCG@K'] == best_ndcg and best_epoch==epoch+1 else ''}  \"\n",
    "            f\"Time {time.time()-t0:.2f}s\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nTraining Complete.\")\n",
    "    print(f\"Best epoch: {best_epoch} with NDCG@{k}: {best_ndcg:.4f}\\n\")\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    writer.close()\n",
    "    return train_losses, val_losses, val_metrics_log, best_ndcg"
   ],
   "id": "2cb1cd31cab2153b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model",
   "id": "2199dc5aecc7393a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:23:02.560637Z",
     "start_time": "2025-08-28T19:08:36.391292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters from the original paper, except higher hidden_dim\n",
    "sasrec = SASRec(\n",
    "    num_items=NUM_ITEMS,\n",
    "    hidden_dim=64,\n",
    "    max_seq_len=50,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    "    dropout=0.4\n",
    ")\n",
    "\n",
    "loss_fn_sasrec = nn.BCEWithLogitsLoss()\n",
    "optimizer_sasrec = torch.optim.Adam(sasrec.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "train_losses_sasrec, val_losses_sasrec, val_metrics_sasrec, best_ndcg_sasrec = sasrec_trainer(\n",
    "    model=sasrec,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=val_loader,\n",
    "    loss_fn=loss_fn_sasrec,\n",
    "    optimizer=optimizer_sasrec,\n",
    "    epochs=5,\n",
    "    k=10,\n",
    "    device=DEVICE,\n",
    "    save_dir=\"model_sasrec\"\n",
    ")"
   ],
   "id": "bce990fff974cbdb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3031/3031 [02:38<00:00, 19.10it/s]\n",
      "Evaluating: 100%|██████████| 286/286 [00:19<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  Train loss 0.4474  Val loss 0.2384  HR@10 0.4171  NDCG@10 0.2553  Precision@10 0.0417  MRR@10 0.2056  (new best)  Time 178.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3031/3031 [02:31<00:00, 20.02it/s]\n",
      "Evaluating: 100%|██████████| 286/286 [00:19<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  Train loss 0.3467  Val loss 0.2077  HR@10 0.5234  NDCG@10 0.3357  Precision@10 0.0523  MRR@10 0.2777  (new best)  Time 171.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3031/3031 [02:28<00:00, 20.41it/s]\n",
      "Evaluating: 100%|██████████| 286/286 [00:19<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  Train loss 0.2892  Val loss 0.1892  HR@10 0.5702  NDCG@10 0.3789  Precision@10 0.0570  MRR@10 0.3195  (new best)  Time 168.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3031/3031 [02:31<00:00, 20.02it/s]\n",
      "Evaluating: 100%|██████████| 286/286 [00:20<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  Train loss 0.2466  Val loss 0.1691  HR@10 0.5918  NDCG@10 0.4028  Precision@10 0.0592  MRR@10 0.3438  (new best)  Time 172.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3031/3031 [02:30<00:00, 20.12it/s]\n",
      "Evaluating: 100%|██████████| 286/286 [00:21<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  Train loss 0.2166  Val loss 0.1684  HR@10 0.6019  NDCG@10 0.4161  Precision@10 0.0602  MRR@10 0.3581  (new best)  Time 172.27s\n",
      "\n",
      "Training Complete.\n",
      "Best epoch: 5 with NDCG@10: 0.4161\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cross-domain development",
   "id": "b431468b22f94a82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:23:02.606392Z",
     "start_time": "2025-08-28T19:23:02.600987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load trained model on source domain\n",
    "def load_best_weights(model, ckpt_path=\"model/best_model.pth\", device=\"cpu\"):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.cpu()\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device).eval()\n",
    "    return model"
   ],
   "id": "56a95e546e8757d1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Align users across domains",
   "id": "f20f9dbcb0fe38c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:23:02.636565Z",
     "start_time": "2025-08-28T19:23:02.631066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def compute_user_reprs_from_sequences(model_src, train_seqs_src, user_encoder_src, max_seq_len=50, device=DEVICE):\n",
    "    model_src.eval().to(device)\n",
    "    user_vecs = {}\n",
    "\n",
    "    for user_id, seq in train_seqs_src.items():\n",
    "        if len(seq) < 1:\n",
    "            continue\n",
    "\n",
    "        # Pad-left to max_seq_len\n",
    "        seq = seq[-max_seq_len:]\n",
    "        pad_len = max_seq_len - len(seq)\n",
    "        input_seq = torch.tensor([([0] * pad_len + seq)], dtype=torch.long, device=device)\n",
    "        hidden = model_src(input_seq)\n",
    "        last_hidden = hidden[0, -1, :].squeeze(0)\n",
    "        raw_user = user_encoder_src.inverse_transform([user_id])[0]\n",
    "        user_vecs[raw_user] = last_hidden.detach().cpu().numpy()\n",
    "\n",
    "    print(f\"\\nComputed user representations for {len(user_vecs)} users.\")\n",
    "    return user_vecs"
   ],
   "id": "58042328ee681734",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:32.899843Z",
     "start_time": "2025-08-28T19:23:02.653675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-domain evaluation on target domain\n",
    "TARGET_DOMAIN = \"Movies_and_TV\"\n",
    "\n",
    "# Load data from target domain\n",
    "df_target = load_amazon_reviews(TARGET_DOMAIN, max_items=10_000_000, seed=SEED)\n",
    "filtered_df_target = preprocess_dataset(df_target, min_user_interactions=10, min_item_interactions=10)\n",
    "df_target_encoded, user_encoder_tgt, item_encoder_tgt, domain_encoder_tgt = label_encoder(filtered_df_target, shift_item_id=True)\n",
    "\n",
    "NUM_USERS_TGT = df_target_encoded[\"user_id\"].max() + 1\n",
    "NUM_ITEMS_TGT = df_target_encoded[\"item_id\"].max() + 1\n",
    "\n",
    "# Rebuild sequences for target domain and split\n",
    "user_sequences_tgt = create_user_sequences(df_target_encoded)\n",
    "pos_items_by_user_tgt = {u: set(seq) for u, seq in user_sequences_tgt.items()}\n",
    "train_sequences_tgt, val_sequences_tgt, test_sequences_tgt = sequences_loo_split(user_sequences_tgt)\n",
    "\n",
    "# Build source user vectors from the trained source model\n",
    "user_vecs_src = compute_user_reprs_from_sequences(\n",
    "    model_src=sasrec,\n",
    "    train_seqs_src=train_sequences,\n",
    "    user_encoder_src=user_encoder,\n",
    "    max_seq_len=50,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Create an aligned matrix of source vectors in target's user_id space\n",
    "embed_dim = 64\n",
    "transfer_src_mat = np.zeros((NUM_USERS_TGT, embed_dim), dtype=np.float32)\n",
    "for raw_user, vec in user_vecs_src.items():\n",
    "    if raw_user in user_encoder_tgt.classes_:\n",
    "        uid_target = user_encoder_tgt.transform([raw_user])[0]\n",
    "        transfer_src_mat[uid_target] = vec # give source user vector to target user_id (shared users)\n",
    "\n",
    "transfer_src_mat = torch.tensor(transfer_src_mat)  # [U_T, D]\n",
    "print(\"\\n\")\n",
    "print(transfer_src_mat)"
   ],
   "id": "791cedac970eb443",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/amazon_reviews_Movies_and_TV.csv with 10000000 rows.\n",
      "After interactions filtering: 1821870 rows, 106001 users, 127365 items\n",
      "Number of users: 106001\n",
      "Max sequence length: 1452\n",
      "Min sequence length: 1\n",
      "Training sequences: 105548\n",
      "Validation users: 105548\n",
      "Test users: 105548\n",
      "\n",
      "Computed user representations for 145957 users.\n",
      "\n",
      "\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T02:13:11.617379Z",
     "start_time": "2025-08-29T02:13:11.470734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def build_transfer_matrix_fast(user_vecs_src, user_encoder_tgt, num_users_tgt, dtype=torch.float16):\n",
    "#     tgt_index = {u: i for i, u in enumerate(user_encoder_tgt.classes_)}\n",
    "#     D = len(next(iter(user_vecs_src.values())))\n",
    "#     mat = np.zeros((num_users_tgt, D), dtype=np.float32)  # keep float32 for fill speed\n",
    "#     hits = 0\n",
    "#     for raw_user, vec in user_vecs_src.items():\n",
    "#         idx = tgt_index.get(raw_user)\n",
    "#         if idx is not None:\n",
    "#             mat[idx] = vec; hits += 1\n",
    "#     print(f\"[xfer] aligned {hits} users → target space\")\n",
    "#     t = torch.from_numpy(mat)\n",
    "#     return t.to(dtype)   # cast once at the end if you like half precision\n",
    "#\n",
    "# # usage\n",
    "# transfer_src_mat = build_transfer_matrix_fast(\n",
    "#     user_vecs_src, user_encoder_tgt, NUM_USERS_TGT, dtype=torch.float16\n",
    "# )\n",
    "#\n",
    "# transfer_src_mat = build_transfer_matrix_fast(\n",
    "#     user_vecs_src, user_encoder_tgt, NUM_USERS_TGT, dtype=torch.float16\n",
    "# )\n",
    "\n",
    "# save\n",
    "torch.save(transfer_src_mat, \"model_sasrec/transfer_src_mat.pt\")\n",
    "\n",
    "# load (future runs)\n",
    "transfer_src_mat = torch.load(\"model_sasrec/transfer_src_mat.pt\", map_location=DEVICE)"
   ],
   "id": "1d5a476fb3605b62",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:34.182501Z",
     "start_time": "2025-08-28T20:55:32.948595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_user_overlap(df_source, df_target):\n",
    "    users_src = set(df_source[\"user\"].unique())\n",
    "    users_tgt = set(df_target[\"user\"].unique())\n",
    "    common_users = users_src.intersection(users_tgt)\n",
    "\n",
    "    print(f\"Source domain users: {len(users_src)}\")\n",
    "    print(f\"Target domain users: {len(users_tgt)}\")\n",
    "    print(f\"Common users: {len(common_users)}\")\n",
    "    print(f\"Percentage of target users in source: {len(common_users) / len(users_tgt) * 100:.2f}%\")\n",
    "    print(f\"Percentage of source users in target: {len(common_users) / len(users_src) * 100:.2f}%\")\n",
    "\n",
    "analyze_user_overlap(filtered_df, filtered_df_target)"
   ],
   "id": "7e5793bf40db5654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source domain users: 154220\n",
      "Target domain users: 106001\n",
      "Common users: 16657\n",
      "Percentage of target users in source: 15.71%\n",
      "Percentage of source users in target: 10.80%\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset and DataLoader for cross-domain",
   "id": "8fe47cc91330d75d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:34.196684Z",
     "start_time": "2025-08-28T20:55:34.191177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Additional dataset changes for cross-domain\n",
    "class SASRecDatasetCD(SASRecDataset):\n",
    "    def __init__(self, data, num_items, transfer_src_mat, max_seq_len=50, mode=\"train\", neg_samples=1):\n",
    "        super().__init__(data, num_items, max_seq_len=max_seq_len, mode=mode, neg_samples=neg_samples)\n",
    "        self.transfer_src_mat = transfer_src_mat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out = super().__getitem__(idx)\n",
    "        user_id = out[\"user\"]\n",
    "        out[\"transfer_src\"] = self.transfer_src_mat[user_id].float()\n",
    "        return out"
   ],
   "id": "fb352b01f59749f8",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:42.657920Z",
     "start_time": "2025-08-28T20:55:34.218529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Target datasets & loaders\n",
    "train_dataset_tgt = SASRecDatasetCD(train_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"train\", neg_samples=4)\n",
    "val_dataset_tgt = SASRecDatasetCD(val_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"val\", neg_samples=99)\n",
    "test_dataset_tgt = SASRecDatasetCD(test_sequences_tgt, NUM_ITEMS_TGT, transfer_src_mat, max_seq_len=50, mode=\"test\", neg_samples=99)\n",
    "\n",
    "train_loader_tgt = DataLoader(train_dataset_tgt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_tgt   = DataLoader(val_dataset_tgt,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_tgt  = DataLoader(test_dataset_tgt,  batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "90c6068e118edc4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cross-domain SASRec model\n",
    "This technique is inspired by the paper [Personalized Transfer of User Preferences for Cross-domain Recommendation (2021)](https://arxiv.org/abs/2110.11154)."
   ],
   "id": "822d0dc78c291e13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:42.677846Z",
     "start_time": "2025-08-28T20:55:42.667464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SASRecCD(nn.Module):\n",
    "    def __init__(self, base_sasrec, hidden_dim, bridge_hidden, dropout, fusion_mode='gate'):\n",
    "        super().__init__()\n",
    "        self.base = base_sasrec\n",
    "        self.fusion_mode = fusion_mode\n",
    "\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, bridge_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(bridge_hidden, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # Conditionally define layers based on the fusion mode\n",
    "        if self.fusion_mode in [\"gate\", \"concat\"]:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        elif self.fusion_mode == \"add\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid fusion_mode: '{self.fusion_mode}'. Must be 'gate', 'add', or 'concat'.\")\n",
    "\n",
    "    def forward(self, input_seq, transfer_src=None):\n",
    "        seq_output = self.base(input_seq)\n",
    "        last_hidden = seq_output[:, -1, :]\n",
    "\n",
    "        if transfer_src is not None:\n",
    "            bridge_out = self.bridge(transfer_src)\n",
    "            # A mask to identify which users in the batch have a source vector\n",
    "            has_transfer = (transfer_src.abs().sum(dim=-1, keepdim=True) > 0).float()\n",
    "\n",
    "            fused_logic = None\n",
    "            if self.fusion_mode == \"gate\":\n",
    "                last_hidden_n = nn.functional.layer_norm(last_hidden, last_hidden.shape[-1:])\n",
    "                bridge_out_n = nn.functional.layer_norm(bridge_out, bridge_out.shape[-1:])\n",
    "                combined = torch.cat([last_hidden_n, bridge_out_n], dim=-1)\n",
    "                gate = torch.sigmoid(self.linear(combined))\n",
    "                fused_logic = gate * last_hidden + (1.0 - gate) * bridge_out\n",
    "\n",
    "            elif self.fusion_mode == \"add\":\n",
    "                fused_logic = last_hidden + bridge_out\n",
    "\n",
    "            elif self.fusion_mode == \"concat\":\n",
    "                # Concatenation followed by a linear projection\n",
    "                combined = torch.cat([last_hidden, bridge_out], dim=-1)\n",
    "                fused_logic = self.linear(combined)\n",
    "\n",
    "            # Apply the fusion logic only to users with a transfer vector.\n",
    "            # Other users just get their original `last_hidden` representation.\n",
    "            fused = has_transfer * fused_logic + (1.0 - has_transfer) * last_hidden\n",
    "        else:\n",
    "            # If no transfer source is provided at all, default to the base model's output\n",
    "            fused = last_hidden\n",
    "\n",
    "        return fused\n",
    "\n",
    "    def predict_next(self, input_seq, transfer_src=None):\n",
    "        fused_repr = self.forward(input_seq, transfer_src)\n",
    "        all_item_embeds = self.base.item_embed.weight\n",
    "        scores = torch.matmul(fused_repr, all_item_embeds.T)\n",
    "        return scores"
   ],
   "id": "f2232fdc87c075e4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and evaluation functions for cross-domain",
   "id": "e272ab095ba4ce41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:42.692901Z",
     "start_time": "2025-08-28T20:55:42.686370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch_transfer(model, loader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        inp = batch[\"input_seq\"].to(device)\n",
    "        pos = batch[\"target\"].to(device)\n",
    "        neg = batch[\"neg_items\"].to(device)\n",
    "        transfer = batch[\"transfer_src\"].to(device)\n",
    "\n",
    "        # fused representation\n",
    "        fused = model(inp, transfer_src=transfer)\n",
    "        pos_emb = model.base.item_embed(pos)\n",
    "        neg_emb = model.base.item_embed(neg)\n",
    "\n",
    "        pos_logits = (fused * pos_emb).sum(dim=1)\n",
    "        neg_logits = torch.bmm(neg_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        all_logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], 1)\n",
    "        all_labels = torch.cat([torch.ones_like(pos_logits).unsqueeze(1),\n",
    "                                torch.zeros_like(neg_logits)], 1)\n",
    "\n",
    "        loss = loss_fn(all_logits.reshape(-1), all_labels.reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item(); n += 1\n",
    "    return total / n"
   ],
   "id": "9b5d3f950196aeee",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:42.706985Z",
     "start_time": "2025-08-28T20:55:42.699956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_transfer(model, loader, loss_fn, k=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total = hits = ndcgs = precs = mrrs = 0.0\n",
    "    loss_sum, nb = 0.0, 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "        inp = batch[\"input_seq\"].to(device)\n",
    "        tgt = batch[\"target\"].to(device)\n",
    "        neg = batch[\"neg_items\"].to(device)\n",
    "        transfer = batch[\"transfer_src\"].to(device)\n",
    "\n",
    "        fused = model(inp, transfer_src=transfer)\n",
    "        cand = torch.cat([tgt.unsqueeze(1), neg], dim=1)\n",
    "        cand_emb = model.base.item_embed(cand)\n",
    "        scores = torch.bmm(cand_emb, fused.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # loss\n",
    "        labels = torch.cat([torch.ones_like(scores[:, :1]),\n",
    "                            torch.zeros_like(scores[:, 1:])], dim=1)\n",
    "        batch_loss = loss_fn(scores.reshape(-1), labels.reshape(-1))\n",
    "        loss_sum += batch_loss.item(); nb += 1\n",
    "\n",
    "        # ranks & metrics\n",
    "        _, idx = torch.sort(scores, dim=1, descending=True)\n",
    "        rank = (idx == 0).nonzero(as_tuple=True)[1] + 1  # 1-based\n",
    "        hit = (rank <= k).float()\n",
    "        ndcg = torch.where(rank <= k, 1.0 / torch.log2(rank.float() + 1), torch.zeros_like(hit))\n",
    "        precision = hit / float(k)\n",
    "        mrr = 1.0 / rank.float()\n",
    "\n",
    "        B = inp.size(0)\n",
    "        hits += hit.sum().item()\n",
    "        ndcgs += ndcg.sum().item()\n",
    "        precs += precision.sum().item()\n",
    "        mrrs += mrr.sum().item()\n",
    "        total += B\n",
    "\n",
    "    return {\n",
    "        \"HR@K\": hits / total,\n",
    "        \"NDCG@K\": ndcgs / total,\n",
    "        \"Precision@K\": precs / total,\n",
    "        \"MRR\": mrrs / total,\n",
    "        \"Val loss\": loss_sum / max(nb, 1)\n",
    "    }"
   ],
   "id": "c04555ca03e8ea0",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:42.719725Z",
     "start_time": "2025-08-28T20:55:42.714151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trainer (target domain)\n",
    "def train_target_with_transfer(model, train_loader, val_loader, epochs, lr=1e-3, wd=1e-6, k=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    best_ndcg, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train = train_epoch_transfer(model, train_loader, loss_fn, opt, device=device)\n",
    "        eval = evaluate_transfer(model, val_loader, loss_fn, k=k, device=device)\n",
    "\n",
    "        if eval[\"NDCG@K\"] > best_ndcg:\n",
    "            best_ndcg, best_epoch = eval[\"NDCG@K\"], epoch+1\n",
    "            torch.save(model.state_dict(), \"model_sasrec/transfer_best.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  \"\n",
    "              f\"Train {train:.4f}  \"\n",
    "              f\"Val {eval['Val loss']:.4f}  \"\n",
    "              f\"HR@{k} {eval['HR@K']:.4f}  \"\n",
    "              f\"NDCG@{k} {eval['NDCG@K']:.4f}  \"\n",
    "              f\"Prec@{k} {eval['Precision@K']:.4f}  \"\n",
    "              f\"MRR {eval['MRR']:.4f}  \"\n",
    "              f\"{'(new best)' if eval['NDCG@K']==best_ndcg and best_epoch==epoch+1 else ''}\")\n",
    "\n",
    "    print(f\"\\nBest epoch {best_epoch} NDCG@{k}={best_ndcg:.4f}\")\n",
    "    return best_ndcg"
   ],
   "id": "c51f2eaaf80216e0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the cross-domain model",
   "id": "56431266d7dc33c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:43.095370Z",
     "start_time": "2025-08-28T20:55:42.726736Z"
    }
   },
   "cell_type": "code",
   "source": "sasrec_base_model = load_best_weights(sasrec, ckpt_path=\"model_sasrec/best_model_src.pth\", device=DEVICE)",
   "id": "6d74d1ba88096a1",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T20:55:43.111785Z",
     "start_time": "2025-08-28T20:55:43.103886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_src = sasrec_base_model.hidden_dim\n",
    "d_src # hidden dimension of source model (embedding size)"
   ],
   "id": "9a1cfabccd952b80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:09:44.887678Z",
     "start_time": "2025-08-28T20:55:43.133974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-domain wrapper model (bridge maps d_src -> target hidden)\n",
    "sasrec_target_model = SASRec(num_items=NUM_ITEMS_TGT,\n",
    "                             hidden_dim=d_src,\n",
    "                             max_seq_len=50,\n",
    "                             num_blocks=2,\n",
    "                             num_heads=2,\n",
    "                             dropout=0.4)\n",
    "\n",
    "transfer_model = SASRecCD(sasrec_target_model,\n",
    "                          hidden_dim=d_src,\n",
    "                          bridge_hidden=128,\n",
    "                          dropout=0.4,\n",
    "                          fusion_mode='gate').to(DEVICE)\n",
    "\n",
    "best_ndcg_tgt = train_target_with_transfer(transfer_model,\n",
    "                                           train_loader_tgt,\n",
    "                                           val_loader_tgt,\n",
    "                                           epochs=5,\n",
    "                                           lr=1e-3,\n",
    "                                           wd=1e-6,\n",
    "                                           k=10,\n",
    "                                           device=DEVICE)"
   ],
   "id": "dee0723f5411fcc0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:34<00:00, 19.08it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  Train 0.4116  Val 0.2049  HR@10 0.5599  NDCG@10 0.3521  Prec@10 0.0560  MRR 0.3056  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:30<00:00, 19.51it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  Train 0.3214  Val 0.1821  HR@10 0.6331  NDCG@10 0.4126  Prec@10 0.0633  MRR 0.3600  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:34<00:00, 19.08it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  Train 0.2826  Val 0.1618  HR@10 0.6754  NDCG@10 0.4530  Prec@10 0.0675  MRR 0.3980  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:31<00:00, 19.37it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  Train 0.2544  Val 0.1561  HR@10 0.6968  NDCG@10 0.4737  Prec@10 0.0697  MRR 0.4176  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:34<00:00, 19.05it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  Train 0.2346  Val 0.1522  HR@10 0.7061  NDCG@10 0.4854  Prec@10 0.0706  MRR 0.4295  (new best)\n",
      "\n",
      "Best epoch 5 NDCG@10=0.4854\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison of baseline and cross-domain models",
   "id": "5a519e04b37667e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:23:18.789452Z",
     "start_time": "2025-08-28T21:09:44.913180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline on target-only SASRec (no transfer)\n",
    "sasrec_tgt_baseline = SASRec(\n",
    "    num_items=NUM_ITEMS_TGT,\n",
    "    hidden_dim=d_src,\n",
    "    max_seq_len=50,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "loss_fn_tgt_baseline = nn.BCEWithLogitsLoss()\n",
    "optimizer_tgt_baseline = torch.optim.Adam(sasrec_tgt_baseline.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "best_ndcg_tgt_baseline = 0.0\n",
    "best_epoch_tgt_baseline = 0\n",
    "EPOCHS = 5\n",
    "k = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_sasrec_epoch(sasrec_tgt_baseline, train_loader_tgt, loss_fn_tgt_baseline, optimizer_tgt_baseline, device=DEVICE)\n",
    "    eval_metrics = evaluate_sasrec(sasrec_tgt_baseline, val_loader_tgt, loss_fn_tgt_baseline, k=k , device=DEVICE)\n",
    "\n",
    "    if eval_metrics[\"NDCG@K\"] > best_ndcg_tgt_baseline:\n",
    "        best_ndcg_tgt_baseline = eval_metrics[\"NDCG@K\"]\n",
    "        torch.save(sasrec_tgt_baseline.state_dict(), \"model_sasrec/baseline_target_only_best.pth\")\n",
    "        best_epoch_tgt_baseline = epoch + 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  \"\n",
    "          f\"Train loss {train_loss:.4f}  \"\n",
    "          f\"Val loss {eval_metrics['Val loss']:.4f}  \"\n",
    "          f\"HR@10 {eval_metrics['HR@K']:.4f}  \"\n",
    "          f\"NDCG@10 {eval_metrics['NDCG@K']:.4f}  \"\n",
    "          f\"Precision@10 {eval_metrics['Precision@K']:.4f}  \"\n",
    "          f\"MRR@10 {eval_metrics['MRR@K']:.4f}  \"\n",
    "          f\"{'(new best)' if eval_metrics['NDCG@K']==best_ndcg_tgt_baseline else ''}\")\n",
    "\n",
    "print(f\"\\nBest epoch {best_epoch_tgt_baseline} NDCG@{k}={best_ndcg_tgt_baseline:.4f}\")"
   ],
   "id": "697b58df54dc975f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:28<00:00, 19.77it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  Train loss 0.4209  Val loss 0.2113  HR@10 0.5407  NDCG@10 0.3382  Precision@10 0.0541  MRR@10 0.2759  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:27<00:00, 19.96it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  Train loss 0.3336  Val loss 0.1925  HR@10 0.6124  NDCG@10 0.3981  Precision@10 0.0612  MRR@10 0.3319  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:28<00:00, 19.81it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:15<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  Train loss 0.2950  Val loss 0.1746  HR@10 0.6561  NDCG@10 0.4372  Precision@10 0.0656  MRR@10 0.3693  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:25<00:00, 20.21it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:14<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  Train loss 0.2676  Val loss 0.1640  HR@10 0.6806  NDCG@10 0.4598  Precision@10 0.0681  MRR@10 0.3911  (new best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2939/2939 [02:28<00:00, 19.79it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:14<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  Train loss 0.2461  Val loss 0.1527  HR@10 0.6957  NDCG@10 0.4750  Precision@10 0.0696  MRR@10 0.4063  (new best)\n",
      "\n",
      "Best epoch 5 NDCG@10=0.4750\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build cold/warm user splits from target domain training sequences",
   "id": "a7f2963f3390c130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:23:18.885599Z",
     "start_time": "2025-08-28T21:23:18.810682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_cold_warm(train_sequences_tgt, cold_threshold=1):\n",
    "    cold_users = {u for u, seq in train_sequences_tgt.items() if len(seq) <= cold_threshold}\n",
    "    warm_users = {u for u, seq in train_sequences_tgt.items() if len(seq) >= (cold_threshold + 1)}\n",
    "    return cold_users, warm_users\n",
    "\n",
    "def filter_split(split_dict, keep_users):\n",
    "    return {u: v for u, v in split_dict.items() if u in keep_users}\n",
    "\n",
    "COLD_THRESHOLD = 3\n",
    "cold_users, warm_users = split_cold_warm(train_sequences_tgt, cold_threshold=COLD_THRESHOLD)\n",
    "test_cold = filter_split(test_sequences_tgt, cold_users)\n",
    "test_warm = filter_split(test_sequences_tgt, warm_users)\n",
    "\n",
    "print(f\"Test cold users: {len(test_cold)}, Test warm users: {len(test_warm)}\")"
   ],
   "id": "b5a9898d31d2fc2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cold users: 2192, Test warm users: 103356\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:23:19.291649Z",
     "start_time": "2025-08-28T21:23:18.913012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "overlap_mask = (transfer_src_mat.norm(dim=1) > 0)  # [U_T]\n",
    "test_cold_users = set(u for u, _ in test_sequences_tgt.items() if len(test_sequences_tgt.get(u, [])) <= COLD_THRESHOLD)\n",
    "cold_overlap = sum(int(overlap_mask[u].item()) for u in test_cold_users)\n",
    "print(f\"TEST/Cold users: {len(test_cold_users)}, with source-overlap: {cold_overlap} ({cold_overlap/len(test_cold_users):.1%})\")"
   ],
   "id": "71c1c2ef268193a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST/Cold users: 105548, with source-overlap: 15860 (15.0%)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:23:19.451236Z",
     "start_time": "2025-08-28T21:23:19.315697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_loader_from_split(split_dict, transfer_src_mat, num_items, mode=\"val\", max_seq_len=50, neg_samples=99, batch_size=4096):\n",
    "    ds = SASRecDatasetCD(split_dict, num_items, transfer_src_mat, max_seq_len=max_seq_len, mode=mode, neg_samples=neg_samples)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader_all = test_loader_tgt\n",
    "test_loader_cold = make_loader_from_split(test_cold, transfer_src_mat, NUM_ITEMS_TGT)\n",
    "test_loader_warm = make_loader_from_split(test_warm, transfer_src_mat, NUM_ITEMS_TGT)"
   ],
   "id": "345946d6baed10ca",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate baseline vs transfer models on target domain",
   "id": "6ff8d9bd16b13028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T21:23:19.564514Z",
     "start_time": "2025-08-28T21:23:19.459381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sasrec_tgt_baseline.load_state_dict(torch.load(\"model_sasrec/baseline_target_only_best.pth\", map_location=DEVICE))\n",
    "transfer_model.load_state_dict(torch.load(\"model_sasrec/transfer_best.pth\", map_location=DEVICE))\n",
    "sasrec_tgt_baseline.to(DEVICE).eval()\n",
    "transfer_model.to(DEVICE).eval()"
   ],
   "id": "d46d5c1826e23e56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRecCD(\n",
       "  (base): SASRec(\n",
       "    (item_embed): Embedding(127366, 64, padding_idx=0)\n",
       "    (positional_embed): Embedding(50, 64)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x AttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): PointWiseFeedForward(\n",
       "          (w1): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (bridge): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T02:02:31.684638Z",
     "start_time": "2025-08-29T02:01:30.974661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "# Compute metrics on all / cold / warm for val and test sets\n",
    "def eval_all():\n",
    "    suites = {\n",
    "        \"All [Test]\": (test_loader_all,),\n",
    "        \"Cold [Test]\": (test_loader_cold,),\n",
    "        \"Warm [Test]\": (test_loader_warm,),\n",
    "    }\n",
    "    rows = []\n",
    "    for name, (loader,) in suites.items():\n",
    "        mb = evaluate_sasrec(sasrec_tgt_baseline, loader, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "        mx = evaluate_transfer(transfer_model, loader, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "        rows.append({\n",
    "            \"Split\": name,\n",
    "            \"Baseline HR@10\": mb[\"HR@K\"], \"Transfer HR@10\": mx[\"HR@K\"],\n",
    "            \"Baseline NDCG@10\": mb[\"NDCG@K\"], \"Transfer NDCG@10\": mx[\"NDCG@K\"],\n",
    "            \"Baseline P@10\": mb[\"Precision@K\"], \"Transfer P@10\": mx[\"Precision@K\"],\n",
    "            \"Baseline MRR\": mb.get(\"MRR\", math.nan), \"Transfer MRR\": mx.get(\"MRR\", math.nan)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "results_df = eval_all()\n",
    "print(\"\\n=== COMPARISON TABLE ===\")\n",
    "print(results_df.to_string(index=False))"
   ],
   "id": "532468c4825ea565",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 207/207 [00:17<00:00, 12.00it/s]\n",
      "Evaluating: 100%|██████████| 207/207 [00:16<00:00, 12.55it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "Evaluating: 100%|██████████| 26/26 [00:13<00:00,  1.98it/s]\n",
      "Evaluating: 100%|██████████| 26/26 [00:13<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON TABLE ===\n",
      "      Split  Baseline HR@10  Transfer HR@10  Baseline NDCG@10  Transfer NDCG@10  Baseline P@10  Transfer P@10  Baseline MRR  Transfer MRR\n",
      " All [Test]        0.646559        0.679672          0.433044          0.473842       0.064656       0.067967           NaN      0.423170\n",
      "Cold [Test]        0.484945        0.528741          0.288172          0.321926       0.048495       0.052874           NaN      0.276561\n",
      "Warm [Test]        0.650528        0.680667          0.436173          0.475916       0.065053       0.068067           NaN      0.425633\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T02:02:32.384223Z",
     "start_time": "2025-08-29T02:02:31.755869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bar plots\n",
    "def barplot_metric(df, metric_col_baseline, metric_col_transfer, title, outfile):\n",
    "    labels = df[\"Split\"].tolist()\n",
    "    baseline = df[metric_col_baseline].tolist()\n",
    "    transfer = df[metric_col_transfer].tolist()\n",
    "    xs = range(len(labels))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(xs, baseline, width=0.4, label=\"Baseline\")\n",
    "    plt.bar([i+0.4 for i in xs], transfer, width=0.4, label=\"Transfer\")\n",
    "    plt.xticks([i+0.2 for i in xs], labels)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "barplot_metric(results_df, \"Baseline HR@10\", \"Transfer HR@10\", \"HR@10: Baseline vs Transfer\", \"hr10.png\")\n",
    "barplot_metric(results_df, \"Baseline NDCG@10\", \"Transfer NDCG@10\", \"NDCG@10: Baseline vs Transfer\", \"ndcg10.png\")\n",
    "print(\"Saved charts: hr10.png, ndcg10.png\")"
   ],
   "id": "3873acdd23318b0d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved charts: hr10.png, ndcg10.png\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment with Reinforcement Learning",
   "id": "4544e8a56f9283af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T02:50:11.316028Z",
     "start_time": "2025-08-29T02:42:15.151110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feedback -> reward mapping\n",
    "FEEDBACK_REWARD = {\n",
    "    \"like\": 1.0, \"purchase\": 1.0, \"click\": 0.3,\n",
    "    \"add_to_cart\": 0.7, \"dislike\": -0.5, \"skip\": 0.0\n",
    "}\n",
    "\n",
    "def events_to_rewards(events, device=\"cpu\"):\n",
    "    \"\"\"events: list[str] length B -> Tensor[B] float rewards\"\"\"\n",
    "    reward = [FEEDBACK_REWARD.get(event, 0.0) for event in events]\n",
    "    return torch.tensor(reward, dtype=torch.float32, device=device)\n",
    "\n",
    "# Tiny policy-gradient trainer wrapping transfer model\n",
    "class PolicyGradientTrainer:\n",
    "    def __init__(self, model, lr=5e-5, entropy_coeff=0.01, temperature=1.0, baseline_momentum=0.9, log_rewards=False, log_every=10, device=\"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.entropy_coeff = entropy_coeff\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self._baseline = 0.0\n",
    "        self._mom = baseline_momentum\n",
    "        self.log_rewards = log_rewards\n",
    "        self.log_every = log_every\n",
    "        self._step = 0\n",
    "\n",
    "    def _scores(self, input_seq, xfer_src, candidates):\n",
    "        candidates = candidates.long()\n",
    "        input_seq = input_seq.long()\n",
    "\n",
    "        fused = self.model(input_seq, transfer_src=xfer_src)                   # [B, D]\n",
    "        cand_emb = self.model.base.item_embed(candidates)                      # [B, N, D]\n",
    "        scores = torch.bmm(cand_emb, fused.unsqueeze(-1)).squeeze(-1)          # [B, N]\n",
    "        return scores\n",
    "\n",
    "    def _policy_loss(self, logits, actions, rewards):\n",
    "        logp_all = torch.log_softmax(logits / self.temperature, dim=1)         # [B, N]\n",
    "        probs = torch.exp(logp_all)                                            # [B, N]\n",
    "        logp_act = logp_all.gather(1, actions.view(-1,1)).squeeze(1)           # [B]\n",
    "        entropy = -(probs * logp_all).sum(dim=1)                               # [B]\n",
    "\n",
    "        # moving baseline to reduce variance\n",
    "        with torch.no_grad():\n",
    "            self._baseline = self._mom * self._baseline + (1 - self._mom) * rewards.mean().item()\n",
    "        adv = rewards - self._baseline\n",
    "\n",
    "        # Objective: maximize E[(R - b) * log pi(a|s)] + beta * H\n",
    "        loss = -(adv * logp_act + self.entropy_coeff * entropy).mean()\n",
    "        return loss, logp_act.mean().item(), entropy.mean().item(), adv.mean().item()\n",
    "\n",
    "    def step_offline_demo_batch(self, batch, sample_actions=True):\n",
    "        self.model.train()\n",
    "        inp = batch[\"input_seq\"].to(self.device)            # [B, L]\n",
    "        tgt = batch[\"target\"].to(self.device)               # [B]\n",
    "        neg = batch[\"neg_items\"].to(self.device)            # [B, nNeg]\n",
    "        xfer = batch[\"transfer_src\"].to(self.device)        # [B, D]\n",
    "\n",
    "        candidates = torch.cat([tgt.unsqueeze(1), neg], dim=1)                  # [B, N]\n",
    "        logits = self._scores(inp, xfer, candidates)                             # [B, N]\n",
    "\n",
    "        if sample_actions:\n",
    "            probs = torch.softmax(logits / self.temperature, dim=1)             # [B, N]\n",
    "            actions = torch.multinomial(probs, num_samples=1).squeeze(1)        # [B]\n",
    "        else:\n",
    "            actions = torch.argmax(logits, dim=1)                                # [B]\n",
    "\n",
    "        # Demo feedback: treat correct pick as a 'click', else 'skip'\n",
    "        events = [\"click\" if a.item() == 0 else \"skip\" for a in actions]\n",
    "        rewards = events_to_rewards(events, device=self.device)                  # [B]\n",
    "\n",
    "        # LOG REWARDS\n",
    "        if self.log_rewards and (self._step % self.log_every == 0):\n",
    "            r = rewards.detach().cpu().numpy()\n",
    "            r_head = np.round(r[:10], 3)  # show first 10\n",
    "            print(f\"   [rewards] mean={r.mean():.3f} std={r.std():.3f} \"\n",
    "                  f\"min={r.min():.3f} p50={np.median(r):.3f} p90={np.quantile(r,0.9):.3f} max={r.max():.3f} \"\n",
    "                  f\"head={r_head.tolist()}\\n\")\n",
    "\n",
    "        self._step += 1\n",
    "\n",
    "        loss, mean_logp, mean_H, mean_adv = self._policy_loss(logits, actions, rewards)\n",
    "        self.opt.zero_grad(); loss.backward(); self.opt.step()\n",
    "\n",
    "        acc = (actions == 0).float().mean().item()  # “hit-rate” on the demo task\n",
    "        return {\"loss\": loss.item(), \"avg_reward\": rewards.mean().item(),\n",
    "                \"hit_rate\": acc, \"mean_logp\": mean_logp, \"entropy\": mean_H, \"adv\": mean_adv}\n",
    "\n",
    "    def offline_demo_finetune(self, loader, steps=1, sample_actions=True):\n",
    "        for ep in range(steps):\n",
    "            stats = []\n",
    "            for batch in loader:\n",
    "                s = self.step_offline_demo_batch(batch, sample_actions=sample_actions)\n",
    "                stats.append(s)\n",
    "            m = {k: float(np.mean([x[k] for x in stats])) for k in stats[0].keys()}\n",
    "            print(f\"[RL demo] Epoch {ep+1}/{steps}  loss {m['loss']:.4f}  \"\n",
    "                  f\"avg_reward {m['avg_reward']:.4f}  hit {m['hit_rate']:.4f}  \"\n",
    "                  f\"H {m['entropy']:.4f}  advantage {m['adv']:.4f}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n=== RL OFFLINE DEMO: fine-tune on VAL, evaluate on TEST ===\")\n",
    "# Evaluate BEFORE RL (for comparison)\n",
    "ev_before = evaluate_transfer(transfer_model, test_loader_tgt, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "print(\"[Before RL]  HR@10={:.4f}  NDCG@10={:.4f}  Precision@10={:.4f}  MRR={:.4f}\".format(\n",
    "    ev_before[\"HR@K\"], ev_before[\"NDCG@K\"], ev_before[\"Precision@K\"], ev_before[\"MRR\"]))\n",
    "\n",
    "# Run a tiny amount of RL demo training\n",
    "rl = PolicyGradientTrainer(\n",
    "    transfer_model,\n",
    "    lr=3e-5,\n",
    "    entropy_coeff=0.01,\n",
    "    temperature=1.0,\n",
    "    baseline_momentum=0.9,\n",
    "    log_rewards=True,\n",
    "    log_every=50,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "rl.offline_demo_finetune(val_loader_tgt, steps=20, sample_actions=True)\n",
    "\n",
    "# Evaluate AFTER RL\n",
    "ev_after = evaluate_transfer(transfer_model, test_loader_tgt, nn.BCEWithLogitsLoss(), device=DEVICE, k=10)\n",
    "print(\"[After  RL]  HR@10={:.4f}  NDCG@10={:.4f}  Precision@10={:.4f}  MRR={:.4f}\".format(\n",
    "    ev_after[\"HR@K\"], ev_after[\"NDCG@K\"], ev_after[\"Precision@K\"], ev_after[\"MRR\"]))"
   ],
   "id": "70864e57ee4bce1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RL OFFLINE DEMO: fine-tune on VAL, evaluate on TEST ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 207/207 [00:14<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Before RL]  HR@10=0.6757  NDCG@10=0.4766  Precision@10=0.0676  MRR=0.4282\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.100 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.096 std=0.140 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 1/20  loss -0.1313  avg_reward 0.1038  hit 0.3461  H 1.5700  advantage 0.0045\n",
      "\n",
      "   [rewards] mean=0.093 std=0.139 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.111 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.096 std=0.140 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 2/20  loss -0.1389  avg_reward 0.1042  hit 0.3474  H 1.5672  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.100 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.098 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 3/20  loss -0.1395  avg_reward 0.1042  hit 0.3475  H 1.5644  advantage -0.0000\n",
      "\n",
      "   [rewards] mean=0.098 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.098 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "[RL demo] Epoch 4/20  loss -0.1390  avg_reward 0.1048  hit 0.3492  H 1.5604  advantage 0.0002\n",
      "\n",
      "   [rewards] mean=0.111 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.113 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.097 std=0.140 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 5/20  loss -0.1379  avg_reward 0.1040  hit 0.3468  H 1.5517  advantage -0.0001\n",
      "\n",
      "   [rewards] mean=0.115 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.104 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.104 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "[RL demo] Epoch 6/20  loss -0.1379  avg_reward 0.1050  hit 0.3499  H 1.5511  advantage 0.0001\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.109 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.112 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "[RL demo] Epoch 7/20  loss -0.1394  avg_reward 0.1060  hit 0.3533  H 1.5457  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.099 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.103 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.111 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.110 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 8/20  loss -0.1397  avg_reward 0.1059  hit 0.3529  H 1.5410  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.108 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.104 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.098 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 9/20  loss -0.1399  avg_reward 0.1053  hit 0.3511  H 1.5445  advantage -0.0001\n",
      "\n",
      "   [rewards] mean=0.093 std=0.139 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.114 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.094 std=0.139 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 10/20  loss -0.1398  avg_reward 0.1062  hit 0.3538  H 1.5355  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.102 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.115 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 11/20  loss -0.1402  avg_reward 0.1066  hit 0.3553  H 1.5361  advantage 0.0002\n",
      "\n",
      "   [rewards] mean=0.104 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.108 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.098 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 12/20  loss -0.1394  avg_reward 0.1070  hit 0.3566  H 1.5272  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.112 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.104 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 13/20  loss -0.1395  avg_reward 0.1072  hit 0.3574  H 1.5215  advantage -0.0000\n",
      "\n",
      "   [rewards] mean=0.110 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.103 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 14/20  loss -0.1399  avg_reward 0.1077  hit 0.3589  H 1.5204  advantage -0.0000\n",
      "\n",
      "   [rewards] mean=0.102 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.112 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.122 std=0.147 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.103 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "[RL demo] Epoch 15/20  loss -0.1393  avg_reward 0.1075  hit 0.3583  H 1.5148  advantage -0.0000\n",
      "\n",
      "   [rewards] mean=0.112 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.114 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.107 std=0.144 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 16/20  loss -0.1396  avg_reward 0.1083  hit 0.3611  H 1.5078  advantage 0.0001\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.111 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 17/20  loss -0.1394  avg_reward 0.1086  hit 0.3620  H 1.4973  advantage 0.0000\n",
      "\n",
      "   [rewards] mean=0.097 std=0.140 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.097 std=0.140 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.101 std=0.142 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896]\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "[RL demo] Epoch 18/20  loss -0.1391  avg_reward 0.1094  hit 0.3645  H 1.4957  advantage 0.0001\n",
      "\n",
      "   [rewards] mean=0.105 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.116 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.106 std=0.143 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.0, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.117 std=0.146 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.30000001192092896]\n",
      "\n",
      "[RL demo] Epoch 19/20  loss -0.1394  avg_reward 0.1092  hit 0.3639  H 1.4892  advantage -0.0001\n",
      "\n",
      "   [rewards] mean=0.110 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "   [rewards] mean=0.110 std=0.145 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.0, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.099 std=0.141 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.0, 0.0, 0.0, 0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.0]\n",
      "\n",
      "   [rewards] mean=0.119 std=0.147 min=0.000 p50=0.000 p90=0.300 max=0.300 head=[0.30000001192092896, 0.30000001192092896, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "\n",
      "[RL demo] Epoch 20/20  loss -0.1397  avg_reward 0.1097  hit 0.3657  H 1.4850  advantage -0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 207/207 [00:14<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After  RL]  HR@10=0.6750  NDCG@10=0.4771  Precision@10=0.0675  MRR=0.4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T02:50:11.945479Z",
     "start_time": "2025-08-29T02:50:11.358949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_recommendations(\n",
    "    raw_user,\n",
    "    k=10,\n",
    "    model=transfer_model,                    # or sasrec_tgt_baseline\n",
    "    user_encoder=user_encoder_tgt,\n",
    "    item_encoder=item_encoder_tgt,\n",
    "    sequences=train_sequences_tgt,          # {encoded_uid: [item_ids...]}\n",
    "    xfer_mat=transfer_src_mat,              # None if using baseline\n",
    "    max_len=50,\n",
    "    device=DEVICE,\n",
    "    pop_items=None                          # optional: precomputed popular raw items\n",
    "):\n",
    "    # Unknown user → fallback\n",
    "    if raw_user not in user_encoder.classes_:\n",
    "        return (pop_items or [])[:k]\n",
    "\n",
    "    uid = int(user_encoder.transform([raw_user])[0])\n",
    "    seq = sequences.get(uid, [])\n",
    "    seen = set(seq)\n",
    "\n",
    "    # Build left-padded input\n",
    "    seq = seq[-max_len:]\n",
    "    inp = torch.tensor([[0]*(max_len-len(seq)) + seq], dtype=torch.long, device=device)\n",
    "\n",
    "    # Get fused user vector (transfer) or last hidden (baseline)\n",
    "    if hasattr(model, \"base\"):  # SASRecCD\n",
    "        xfer = None if xfer_mat is None else xfer_mat[uid:uid+1].to(device)\n",
    "        fused = model(inp, transfer_src=xfer)                 # [1, D]\n",
    "        W = model.base.item_embed.weight                      # [I, D]\n",
    "    else:                   # plain SASRec\n",
    "        seq_repr = model(inp)                                 # [1, L, D]\n",
    "        fused = seq_repr[:, -1, :]                            # [1, D]\n",
    "        W = model.item_embed.weight                           # [I, D]\n",
    "\n",
    "    # Score all items, mask padding & seen\n",
    "    scores = fused @ W.T                                      # [1, num_items]\n",
    "    scores[:, 0] = -1e9\n",
    "    if seen:\n",
    "        scores[0, list(seen)] = -1e9\n",
    "\n",
    "    topk_ids = torch.topk(scores, k, dim=1).indices.squeeze(0).tolist()\n",
    "    # decode back to raw item ids (shift_item_id=True → subtract 1)\n",
    "    rec_items = [item_encoder.inverse_transform([i-1])[0] for i in topk_ids]\n",
    "    return rec_items\n",
    "\n",
    "# Example:\n",
    "u = filtered_df_target[\"user\"].iloc[20]\n",
    "print(sample_recommendations(u, k=10))"
   ],
   "id": "2b16638edcd8faea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B093CNZ7ST', 'B09QH98YG1', 'B09F59CZ7R', 'B097YYZ87F', 'B09ML1QV1S', 'B08QZN6LCM', 'B09JB21878', 'B09HYNH8TK', 'B09PVRLSLB', 'B08WJN83XZ']\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T19:08:32.593924500Z",
     "start_time": "2025-08-28T15:37:35.698722Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cf1d4d44758dfa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "405cd80a8aeddbc8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
