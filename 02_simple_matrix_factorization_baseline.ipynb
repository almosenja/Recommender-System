{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:29.935804Z",
     "start_time": "2025-08-21T12:23:29.930539Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recommenders.datasets.python_splitters import python_chrono_split, python_stratified_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# os.environ[\"HF_HOME\"] = \"E:/Python Scripts/recsys\"\n",
    "# os.environ['HF_DATASETS_CACHE'] = \"E:/Python Scripts/recsys/data\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = \"E:/Python Scripts/recsys/models\"\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"D:/Python Projects/recommendation_system\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"D:/Python Projects/recommendation_system/recsys/data\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"D:/Python Projects/recommendation_system/recsys/models\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:21:44.951458Z",
     "start_time": "2025-08-21T12:21:44.917173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ],
   "id": "94437de919542462",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Amazon Reviews Dataset\n",
    "This dataset contains user reviews for various products across different domains. We will focus on two domains:\n",
    "- Movies and TV\n",
    "- Video Games\n",
    "\n",
    "The dataset is available on the Hugging Face Hub as `McAuley-Lab/Amazon-Reviews-2023`."
   ],
   "id": "1a40c83e69301d28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:05.456692Z",
     "start_time": "2025-08-21T12:21:50.709045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select 2 categories to highlight cross-domain transfer\n",
    "SOURCE_DOMAIN = \"Movies_and_TV\"\n",
    "TARGET_DOMAIN = \"Video_Games\"\n",
    "DOMAINS = [SOURCE_DOMAIN, TARGET_DOMAIN]\n",
    "\n",
    "MIN_USER_INTERACTIONS = 10\n",
    "MIN_ITEM_INTERACTIONS = 10\n",
    "POSITIVE_THRESHOLD = 4.0  # Ratings >= 4.0 are considered positive\n",
    "\n",
    "# Load the dataset\n",
    "def load_amazon_reviews(domain:str, max_per_domain:int=100000) -> pd.DataFrame:\n",
    "    dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "                           f\"raw_review_{domain}\",\n",
    "                           trust_remote_code=True)\n",
    "    rows = []\n",
    "    for i, r in enumerate(dataset[\"full\"]):\n",
    "        if i >= max_per_domain:\n",
    "            break\n",
    "        rows.append({\n",
    "            \"user\": r[\"user_id\"],\n",
    "            \"item\": r[\"parent_asin\"],\n",
    "            \"rating\": float(r[\"rating\"]),\n",
    "            \"domain\": domain,\n",
    "            \"verified_purchase\": r[\"verified_purchase\"],\n",
    "            \"timestamp\": int(r[\"timestamp\"])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Sample 100k reviews per domain for model development\n",
    "dfs = [load_amazon_reviews(dom, max_per_domain=300000) for dom in DOMAINS]\n",
    "df = pd.concat(dfs, ignore_index=True).sort_values(\"timestamp\").reset_index(drop=True)"
   ],
   "id": "dc23bf27622df5e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:05.491966Z",
     "start_time": "2025-08-21T12:23:05.474906Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "a86cc08256af864e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           user        item  rating         domain  \\\n",
       "0  AHTBKI7WSESAHC6QY55GAQ777MXQ  6304333560     5.0  Movies_and_TV   \n",
       "1  AHTBKI7WSESAHC6QY55GAQ777MXQ  6302737931     4.0  Movies_and_TV   \n",
       "2  AHAYX6YWLK52LPXFSE2QUNMMS44A  0783114222     5.0  Movies_and_TV   \n",
       "3  AG3S4FROO422V5KP7DJCBXVUQLJQ  0800185676     5.0  Movies_and_TV   \n",
       "4  AHVNRIAPM3GVNS3RH3MNIEVSSBNA  6303501281     5.0  Movies_and_TV   \n",
       "\n",
       "   verified_purchase     timestamp  \n",
       "0              False  899940586000  \n",
       "1              False  899941515000  \n",
       "2              False  913069725000  \n",
       "3               True  914267986000  \n",
       "4              False  914297420000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>domain</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHTBKI7WSESAHC6QY55GAQ777MXQ</td>\n",
       "      <td>6304333560</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>899940586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHTBKI7WSESAHC6QY55GAQ777MXQ</td>\n",
       "      <td>6302737931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>899941515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHAYX6YWLK52LPXFSE2QUNMMS44A</td>\n",
       "      <td>0783114222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>913069725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG3S4FROO422V5KP7DJCBXVUQLJQ</td>\n",
       "      <td>0800185676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>True</td>\n",
       "      <td>914267986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHVNRIAPM3GVNS3RH3MNIEVSSBNA</td>\n",
       "      <td>6303501281</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>914297420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess the data (Use ratings as continuous values)\n",
    "- Convert `verified_purchase` to a trust weight (1.0 for verified, 0.8 for unverified)\n",
    "- Filter users and items based on minimum interactions\n",
    "- Encode users and items\n",
    "- Split the dataset into training, validation, and test sets"
   ],
   "id": "1a57172b3e0813cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:05.544635Z",
     "start_time": "2025-08-21T12:23:05.538605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df, min_user_interactions, min_item_interactions):\n",
    "    df[\"trust_weight\"] = df[\"verified_purchase\"].apply(lambda x: 1.0 if x else 0.8)\n",
    "\n",
    "    # Filtering interactions\n",
    "    user_counts = df[\"user\"].value_counts()\n",
    "    item_counts = df[\"item\"].value_counts()\n",
    "    active_users = user_counts[user_counts >= min_user_interactions].index\n",
    "    active_items = item_counts[item_counts >= min_item_interactions].index\n",
    "    df = df[df[\"user\"].isin(active_users) & df[\"item\"].isin(active_items)].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Final data length: {df.shape[0]}\")\n",
    "    print(f\"Unique users: {df['user'].nunique()}\")\n",
    "    print(f\"Unique items: {df['item'].nunique()}\")\n",
    "\n",
    "    # ensure dtypes\n",
    "    df[\"rating\"] = df[\"rating\"].astype(np.float32)\n",
    "    df[\"trust_weight\"] = df[\"trust_weight\"].astype(np.float32)\n",
    "    return df"
   ],
   "id": "34982c3d5f21dffd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.515343Z",
     "start_time": "2025-08-21T12:23:05.556810Z"
    }
   },
   "cell_type": "code",
   "source": "processed_df = preprocess_data(df, MIN_USER_INTERACTIONS, MIN_ITEM_INTERACTIONS)",
   "id": "6a442b8cbff9256a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data length: 100891\n",
      "Unique users: 10159\n",
      "Unique items: 9590\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.538770Z",
     "start_time": "2025-08-21T12:23:06.531410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataEncoder():\n",
    "    def __init__(self):\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.item_encoders = {}  # Store encoders for each domain\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def label_encoder(self, df):\n",
    "        # Encode users (shared across domains)\n",
    "        df[\"user_id\"] = self.user_encoder.fit_transform(df[\"user\"])\n",
    "        print(f\"Encoded {len(self.user_encoder.classes_)} unique users.\")\n",
    "\n",
    "        domains = df[\"domain\"].unique()\n",
    "\n",
    "        # Encode items per domain (items might have same ID in different domains)\n",
    "        df[\"item_id\"] = -1  # Initialize with -1\n",
    "        for domain in domains:\n",
    "            domain_data = df[df[\"domain\"] == domain]\n",
    "            item_encoder = LabelEncoder()\n",
    "            encoded_items = item_encoder.fit_transform(domain_data[\"item\"])\n",
    "            df.loc[df[\"domain\"] == domain, \"item_id\"] = encoded_items\n",
    "            self.item_encoders[domain] = item_encoder\n",
    "\n",
    "            print(f\"Encoded {len(item_encoder.classes_)} unique items in domain '{domain}'.\")\n",
    "\n",
    "        # Convert to integer type\n",
    "        df[\"user_id\"] = df[\"user_id\"].astype(np.int64)\n",
    "        df[\"item_id\"] = df[\"item_id\"].astype(np.int64)\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return df\n",
    "\n",
    "    def transform_new_data(self, df):\n",
    "        # Transform new data using existing encoders. Useful for handling new reviews in production.\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"DataEncoder is not fitted. Call label_encoder() first.\")\n",
    "\n",
    "        # Encode users and items\n",
    "        df[\"user_id\"] = self.user_encoder.transform(df[\"user\"])\n",
    "        df[\"item_id\"] = self.item_encoders[df[\"domain\"]].transform(df[\"item\"])\n",
    "\n",
    "        return df"
   ],
   "id": "6407df1eb08d0650",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.696736Z",
     "start_time": "2025-08-21T12:23:06.546514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = DataEncoder()\n",
    "encoded_df = encoder.label_encoder(processed_df)"
   ],
   "id": "8ce5f1c7e50ee4c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 10159 unique users.\n",
      "Encoded 4239 unique items in domain 'Movies_and_TV'.\n",
      "Encoded 5351 unique items in domain 'Video_Games'.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.718069Z",
     "start_time": "2025-08-21T12:23:06.708278Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_df.head()",
   "id": "b238d471bac0d510",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           user        item  rating         domain  \\\n",
       "0  AFIMCCRTD3PWOJY7BAOJMA5C7I4A  B00003CXC3     5.0  Movies_and_TV   \n",
       "1  AFJE7EQZIEFJJOMZGQVAO4AQBHYA  B00000K2R4     5.0    Video_Games   \n",
       "2  AHC3WRQ2PVG3GVNBNK7ATK7YELLA  B001E91OQA     5.0    Video_Games   \n",
       "3  AHM2XKCUWJ4GZQNGDGNEVEN7FJYQ  6305313687     4.0  Movies_and_TV   \n",
       "4  AHVRJMMQMNEWRCZJZ6T5XHMER2PA  B00000K2R4     5.0    Video_Games   \n",
       "\n",
       "   verified_purchase     timestamp  trust_weight  user_id  item_id  \n",
       "0              False  957887792000           0.8     3782       55  \n",
       "1              False  964125246000           0.8     3842       18  \n",
       "2              False  966276400000           0.8     8338      373  \n",
       "3              False  968303405000           0.8     9090       27  \n",
       "4              False  971974663000           0.8     9860       18  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>domain</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trust_weight</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIMCCRTD3PWOJY7BAOJMA5C7I4A</td>\n",
       "      <td>B00003CXC3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>957887792000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3782</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFJE7EQZIEFJJOMZGQVAO4AQBHYA</td>\n",
       "      <td>B00000K2R4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>964125246000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3842</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHC3WRQ2PVG3GVNBNK7ATK7YELLA</td>\n",
       "      <td>B001E91OQA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>966276400000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8338</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHM2XKCUWJ4GZQNGDGNEVEN7FJYQ</td>\n",
       "      <td>6305313687</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>968303405000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9090</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHVRJMMQMNEWRCZJZ6T5XHMER2PA</td>\n",
       "      <td>B00000K2R4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>971974663000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9860</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.748057Z",
     "start_time": "2025-08-21T12:23:06.743047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mean_rating = encoded_df[\"rating\"].mean()\n",
    "# encoded_df[\"rating\"] = encoded_df[\"rating\"] - mean_rating\n",
    "\n",
    "def create_data_splits(df, train_size=0.8):\n",
    "    train, temp = python_chrono_split(\n",
    "        df, ratio=train_size, filter_by=\"user\",\n",
    "        col_user=\"user_id\", col_item=\"item_id\", col_timestamp=\"timestamp\"\n",
    "    )\n",
    "\n",
    "    val, test = python_stratified_split(\n",
    "        temp, ratio=0.5, filter_by=\"user\",\n",
    "        col_user=\"user_id\", col_item=\"item_id\"\n",
    "    )\n",
    "\n",
    "    print(f\"Train set size: {train.shape[0]}\")\n",
    "    print(f\"Validation set size: {val.shape[0]}\")\n",
    "    print(f\"Test set size: {test.shape[0]}\")\n",
    "    print(f\"Common users in train and val: {len(set(train['user_id']).intersection(set(val['user_id'])))}\")\n",
    "    print(f\"Common users in train and test: {len(set(train['user_id']).intersection(set(test['user_id'])))}\")\n",
    "\n",
    "    return train, val, test"
   ],
   "id": "9e05a880ab9d772a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.871021Z",
     "start_time": "2025-08-21T12:23:06.755579Z"
    }
   },
   "cell_type": "code",
   "source": "train_df, val_df, test_df = create_data_splits(encoded_df)",
   "id": "71bb93fd37c13f90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 80760\n",
      "Validation set size: 8633\n",
      "Test set size: 11498\n",
      "Common users in train and val: 5377\n",
      "Common users in train and test: 9136\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking the interaction between users and items",
   "id": "270724a0827235da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.883017Z",
     "start_time": "2025-08-21T12:23:06.878032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_interaction_matrix(df, n_users=None, n_items=None):\n",
    "    if n_users is None:\n",
    "        n_users = df[\"user_id\"].nunique()\n",
    "    if n_items is None:\n",
    "        n_items = df[\"item_id\"].nunique()\n",
    "\n",
    "    # Create a sparse matrix for interactions\n",
    "    row = df[\"user_id\"].values\n",
    "    col = df[\"item_id\"].values\n",
    "    data = df[\"rating\"].values\n",
    "    interaction_matrix = csr_matrix((data, (row, col)), shape=(n_users, n_items))\n",
    "    density = interaction_matrix.nnz / (interaction_matrix.shape[0] * interaction_matrix.shape[1])\n",
    "\n",
    "    print(f\"Shape: {interaction_matrix.shape} (users x items)\")\n",
    "    print(f\"Non-zero entries: {interaction_matrix.nnz}\")\n",
    "    print(f\"Density: {density:.4f}\")\n",
    "\n",
    "    return interaction_matrix"
   ],
   "id": "6343ccf277802d3e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.933278Z",
     "start_time": "2025-08-21T12:23:06.897058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See interaction matrices for each domain to understand user-item interactions\n",
    "domains = encoded_df[\"domain\"].unique()\n",
    "interaction_matrices = {}\n",
    "\n",
    "for domain in domains:\n",
    "    print(f\"\\n{domain} domain interaction matrix:\")\n",
    "    domain_df = train_df[train_df[\"domain\"] == domain]\n",
    "\n",
    "    n_users = encoded_df[\"user_id\"].max() + 1\n",
    "    n_items = domain_df[\"item_id\"].max() + 1\n",
    "    interaction_matrix = create_interaction_matrix(domain_df, n_users, n_items)\n",
    "    interaction_matrices[domain] = interaction_matrix"
   ],
   "id": "28ed85fba3ad4398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies_and_TV domain interaction matrix:\n",
      "Shape: (10159, 4239) (users x items)\n",
      "Non-zero entries: 41981\n",
      "Density: 0.0010\n",
      "\n",
      "Video_Games domain interaction matrix:\n",
      "Shape: (10159, 5351) (users x items)\n",
      "Non-zero entries: 37629\n",
      "Density: 0.0007\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simple Matrix Factorization Model\n",
    "- Creating dataset class for PyTorch\n",
    "- Implementing a simple matrix factorization model using PyTorch"
   ],
   "id": "a72b6f1531cc4b68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.954710Z",
     "start_time": "2025-08-21T12:23:06.949431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleMFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df[\"item_id\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "        self.weights = torch.tensor(df[\"trust_weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx], self.weights[idx]"
   ],
   "id": "84e599757e1bfe8e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.966756Z",
     "start_time": "2025-08-21T12:23:06.960772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleMatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        # init\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.05)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.05)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        dot_product = (user_embeds * item_embeds).sum(dim=1, keepdim=True)\n",
    "        out = dot_product + self.user_bias(user_ids) + self.item_bias(item_ids) + self.global_bias\n",
    "        return out.squeeze(1)\n",
    "\n",
    "    # def forward(self, user_ids, item_ids):\n",
    "    #     user_embeds = self.user_embedding(user_ids)\n",
    "    #     item_embeds = self.item_embedding(item_ids)\n",
    "    #     dot_product = (user_embeds * item_embeds).sum(dim=1)\n",
    "    #     return dot_product  # No bias terms for simplicity"
   ],
   "id": "f05da9d88669837f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training the Simple Matrix Factorization Model\n",
    "- Using sample-weighted MSE loss\n",
    "- Implementing early stopping with ReduceLROnPlateau scheduler\n",
    "- Evaluating the model on validation set\n",
    "- Predicting ratings for a given user-item pair\n",
    "- Evaluating ranking metrics like Precision@k, Recall@k, MAP@k, NDCG@k"
   ],
   "id": "1e3a97798c90f321"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:06.985003Z",
     "start_time": "2025-08-21T12:23:06.973280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MFModel:\n",
    "    def __init__(self,\n",
    "                 n_embeddings=32,\n",
    "                 n_epochs=10,\n",
    "                 lr=0.001,\n",
    "                 weight_decay=1e-5,\n",
    "                 batch_size=1024,\n",
    "                 device=\"cpu\"):\n",
    "\n",
    "        self.n_embeddings = n_embeddings\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, train_df, val_df, n_users, n_items):\n",
    "        print(f\"\\n Training PyTorch Matrix Factorization Model...\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "        print(f\"   Factors: {self.n_embeddings}, Epochs: {self.n_epochs}, LR: {self.lr}\")\n",
    "\n",
    "        train_loader = DataLoader(SimpleMFDataset(train_df), batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        val_loader   = DataLoader(SimpleMFDataset(val_df),   batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        self.model = SimpleMatrixFactorization(n_users, n_items, self.n_embeddings).to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-5\n",
    "        )\n",
    "\n",
    "        best_val_rmse, best_state = float(\"inf\"), None\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # ---- train ----\n",
    "            self.model.train()\n",
    "            se_sum, denom = 0.0, 0.0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.n_epochs}\")\n",
    "            for users, items, ratings, weights in pbar:\n",
    "                users = users.to(self.device)\n",
    "                items = items.to(self.device)\n",
    "                ratings = ratings.to(self.device)\n",
    "                weights = weights.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.model(users, items)\n",
    "\n",
    "                # sample-weighted MSE on true rating\n",
    "                se = (preds - ratings) ** 2\n",
    "                loss = (weights * se).sum() / (weights.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                se_sum += se.detach().sum().item()\n",
    "                denom += ratings.numel()\n",
    "                pbar.set_postfix({\"Train RMSE\": f\"{math.sqrt(se_sum/denom):.4f}\"})\n",
    "\n",
    "            train_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "\n",
    "            # ---- validate ----\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                se_sum, denom = 0.0, 0.0\n",
    "                for users, items, ratings, _ in val_loader:\n",
    "                    users = users.to(self.device)\n",
    "                    items = items.to(self.device)\n",
    "                    ratings = ratings.to(self.device)\n",
    "                    preds = self.model(users, items)\n",
    "                    se_sum += torch.sum((preds - ratings) ** 2).item()\n",
    "                    denom += ratings.numel()\n",
    "            val_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "            scheduler.step(val_rmse)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} - Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            # track best\n",
    "            if val_rmse < best_val_rmse - 1e-4:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_state = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(self.device) for k, v in best_state.items()})\n",
    "        print(\"  Training complete. Best Val RMSE:\", f\"{best_val_rmse:.4f}\")\n",
    "\n",
    "    def predict_dataframe(self, df):\n",
    "        \"\"\"df must contain columns: user_id, item_id\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        self.model.eval()\n",
    "\n",
    "        users = torch.tensor(df[\"user_id\"].values, dtype=torch.long, device=self.device)\n",
    "        items = torch.tensor(df[\"item_id\"].values, dtype=torch.long, device=self.device)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(df), self.batch_size):\n",
    "                pu = users[i:i+self.batch_size]\n",
    "                pi = items[i:i+self.batch_size]\n",
    "                p = self.model(pu, pi)\n",
    "                preds.append(p.detach().cpu().numpy())\n",
    "        return np.concatenate(preds)"
   ],
   "id": "a64242876a2fc1e1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:23:07.002446Z",
     "start_time": "2025-08-21T12:23:06.992035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dcg_at_k(relevances, k):\n",
    "    \"\"\"relevances: list/array of true gains ordered by the *predicted* rank.\"\"\"\n",
    "    r = np.asarray(relevances)[:k]\n",
    "    if r.size == 0:\n",
    "        return 0.0\n",
    "    discounts = 1.0 / np.log2(np.arange(2, r.size + 2))\n",
    "    return float(np.sum(r * discounts))\n",
    "\n",
    "def ndcg_at_k(predicted_items, true_rel_map, k):\n",
    "    \"\"\"\n",
    "    predicted_items: list of item_ids sorted by predicted score (desc).\n",
    "    true_rel_map   : dict {item_id -> gain}. Items not present => 0 gain.\n",
    "    \"\"\"\n",
    "    # gains at predicted order\n",
    "    gains = [true_rel_map.get(i, 0.0) for i in predicted_items[:k]]\n",
    "    dcg = dcg_at_k(gains, k)\n",
    "\n",
    "    # ideal gains: sort all candidate items by their true gain desc\n",
    "    ideal_gains = sorted(true_rel_map.values(), reverse=True)\n",
    "    idcg = dcg_at_k(ideal_gains, k)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_ranking_metrics(\n",
    "    model,\n",
    "    test_df,\n",
    "    all_data_df,\n",
    "    domain: str,\n",
    "    k=10,\n",
    "    rating_threshold=4.0,\n",
    "    n_neg_samples=100,\n",
    "    rng_seed=42,\n",
    "    graded=False  # <- set True if you want graded gains\n",
    "):\n",
    "    \"\"\"\n",
    "    Domain-aware Precision@k, Recall@k, MAP@k, NDCG@k.\n",
    "    - Binary relevance by default: rating >= threshold -> 1, else 0\n",
    "    - Graded relevance (optional): gain = max(rating - (threshold - 1), 0)\n",
    "      e.g., threshold=4.0 => 4★->1, 5★->2, else 0\n",
    "    \"\"\"\n",
    "    print(f\"\\n  Evaluating Ranking Metrics @k={k} for domain = {domain}\")\n",
    "    rs = np.random.RandomState(rng_seed)\n",
    "\n",
    "    # filter to target domain\n",
    "    test_dom = test_df[test_df[\"domain\"] == domain].copy()\n",
    "    hist_dom = all_data_df[all_data_df[\"domain\"] == domain].copy()\n",
    "\n",
    "    if test_dom.empty:\n",
    "        print(\"No test rows for this domain. Skipping.\")\n",
    "        return {\n",
    "            f'precision_at_{k}': 0.0,\n",
    "            f'recall_at_{k}': 0.0,\n",
    "            f'map_at_{k}': 0.0,\n",
    "            f'ndcg_at_{k}': 0.0\n",
    "        }\n",
    "\n",
    "    # candidate pool in this domain\n",
    "    domain_items = np.unique(hist_dom[\"item_id\"].values)\n",
    "    # seen items per user in this domain\n",
    "    seen_by_user = hist_dom.groupby(\"user_id\")[\"item_id\"].apply(set)\n",
    "\n",
    "    precisions, recalls, aps, ndcgs = [], [], [], []\n",
    "\n",
    "    for user_id, g in tqdm(test_dom.groupby(\"user_id\"), desc=\"Calculating Ranking Metrics\"):\n",
    "        # --- build relevance map for this user's test items ---\n",
    "        if graded:\n",
    "            # graded gains: only >= threshold contribute, and graded by how far above threshold\n",
    "            rel_map = {\n",
    "                iid: max(float(r) - (rating_threshold - 1.0), 0.0)\n",
    "                for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)\n",
    "            }\n",
    "        else:\n",
    "            # binary gains\n",
    "            rel_map = {\n",
    "                iid: 1.0 if (float(r) >= rating_threshold) else 0.0\n",
    "                for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)\n",
    "            }\n",
    "        # positive (nonzero) items\n",
    "        rel_items = {iid for iid, gain in rel_map.items() if gain > 0.0}\n",
    "        if not rel_items:\n",
    "            continue  # skip users with no relevant items in test\n",
    "\n",
    "        seen = seen_by_user.get(user_id, set())\n",
    "        negatives = np.array(list(set(domain_items) - seen))\n",
    "        if negatives.size == 0:\n",
    "            continue\n",
    "\n",
    "        m = min(n_neg_samples, negatives.size)\n",
    "        neg_samples = rs.choice(negatives, size=m, replace=False)\n",
    "\n",
    "        # candidate set = relevant test items + sampled negatives\n",
    "        items_to_rank = np.array(list(rel_map.keys()))\n",
    "        items_to_rank = np.concatenate([items_to_rank, neg_samples])\n",
    "\n",
    "        pred_df = pd.DataFrame({\"user_id\": user_id, \"item_id\": items_to_rank})\n",
    "        pred_df[\"score\"] = model.predict_dataframe(pred_df)\n",
    "        pred_df = pred_df.sort_values(\"score\", ascending=False)\n",
    "        top_k = pred_df[\"item_id\"].values[:k]\n",
    "\n",
    "        # --- Precision@k / Recall@k ---\n",
    "        hit_set = set(top_k).intersection(rel_items)\n",
    "        precisions.append(len(hit_set) / k)\n",
    "        recalls.append(len(hit_set) / len(rel_items))\n",
    "\n",
    "        # --- MAP@k ---\n",
    "        ap, hits = 0.0, 0\n",
    "        for rank, item in enumerate(top_k, start=1):\n",
    "            if item in rel_items:\n",
    "                hits += 1\n",
    "                ap += hits / rank\n",
    "        aps.append(ap / len(rel_items))\n",
    "\n",
    "        # --- NDCG@k ---\n",
    "        ndcgs.append(ndcg_at_k(top_k.tolist(), rel_map, k))\n",
    "\n",
    "    out = {\n",
    "        f\"precision_at_{k}\": float(np.mean(precisions)) if precisions else 0.0,\n",
    "        f\"recall_at_{k}\": float(np.mean(recalls)) if recalls else 0.0,\n",
    "        f\"map_at_{k}\": float(np.mean(aps)) if aps else 0.0,\n",
    "        f\"ndcg_at_{k}\": float(np.mean(ndcgs)) if ndcgs else 0.0,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n--- Ranking Evaluation Results (domain={domain}, k={k}) ---\")\n",
    "    print(f\"   Precision@{k}: {out[f'precision_at_{k}']:.4f}\")\n",
    "    print(f\"   Recall@{k}:    {out[f'recall_at_{k}']:.4f}\")\n",
    "    print(f\"   MAP@{k}:       {out[f'map_at_{k}']:.4f}\")\n",
    "    print(f\"   NDCG@{k}:      {out[f'ndcg_at_{k}']:.4f}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    return out"
   ],
   "id": "105e0ebef5eabf71",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:24:39.088887Z",
     "start_time": "2025-08-21T12:23:43.893386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Training the PyTorch Model ---\n",
    "print(\"\\nTraining PyTorch Matrix Factorization on Movies domain:\")\n",
    "movies_train = train_df[train_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "movies_val = val_df[val_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "movies_test = test_df[test_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "\n",
    "n_total_users = encoded_df[\"user_id\"].max() + 1\n",
    "n_movies_items = encoded_df[encoded_df[\"domain\"] == \"Movies_and_TV\"][\"item_id\"].max() + 1\n",
    "\n",
    "mf_torch_model = MFModel(\n",
    "    n_embeddings=8,\n",
    "    n_epochs=50,\n",
    "    lr=0.05,\n",
    "    weight_decay=5e-3,\n",
    "    batch_size=1024,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "mf_torch_model.train(movies_train, movies_val, n_total_users, n_movies_items)"
   ],
   "id": "83b223c7259932fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training PyTorch Matrix Factorization on Movies domain:\n",
      "\n",
      " Training PyTorch Matrix Factorization Model...\n",
      "   Device: cuda\n",
      "   Factors: 8, Epochs: 50, LR: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 42/42 [00:01<00:00, 29.83it/s, Train RMSE=3.1449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train RMSE: 3.1449, Val RMSE: 2.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 42/42 [00:00<00:00, 43.46it/s, Train RMSE=1.7336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train RMSE: 1.7336, Val RMSE: 1.4117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 42/42 [00:00<00:00, 51.16it/s, Train RMSE=1.2476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train RMSE: 1.2476, Val RMSE: 1.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 42/42 [00:00<00:00, 43.80it/s, Train RMSE=1.1124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train RMSE: 1.1124, Val RMSE: 1.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 42/42 [00:00<00:00, 47.20it/s, Train RMSE=1.0938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train RMSE: 1.0938, Val RMSE: 1.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 42/42 [00:00<00:00, 45.61it/s, Train RMSE=1.0926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train RMSE: 1.0926, Val RMSE: 1.1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 42/42 [00:01<00:00, 39.85it/s, Train RMSE=1.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train RMSE: 1.0921, Val RMSE: 1.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 42/42 [00:01<00:00, 39.92it/s, Train RMSE=1.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train RMSE: 1.0897, Val RMSE: 1.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 42/42 [00:00<00:00, 45.38it/s, Train RMSE=1.0878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train RMSE: 1.0878, Val RMSE: 1.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 42/42 [00:01<00:00, 39.40it/s, Train RMSE=1.0890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train RMSE: 1.0890, Val RMSE: 1.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 42/42 [00:00<00:00, 45.20it/s, Train RMSE=1.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train RMSE: 1.0881, Val RMSE: 1.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 42/42 [00:01<00:00, 39.64it/s, Train RMSE=1.0892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train RMSE: 1.0892, Val RMSE: 1.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 42/42 [00:01<00:00, 39.71it/s, Train RMSE=1.0883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train RMSE: 1.0883, Val RMSE: 1.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 42/42 [00:00<00:00, 45.41it/s, Train RMSE=1.0891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train RMSE: 1.0891, Val RMSE: 1.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 42/42 [00:00<00:00, 44.91it/s, Train RMSE=1.0835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train RMSE: 1.0835, Val RMSE: 1.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 42/42 [00:01<00:00, 39.49it/s, Train RMSE=1.0842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Train RMSE: 1.0842, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 42/42 [00:01<00:00, 39.52it/s, Train RMSE=1.0845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Train RMSE: 1.0845, Val RMSE: 1.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 42/42 [00:00<00:00, 45.69it/s, Train RMSE=1.0808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Train RMSE: 1.0808, Val RMSE: 1.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 42/42 [00:01<00:00, 39.71it/s, Train RMSE=1.0807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Train RMSE: 1.0807, Val RMSE: 1.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 42/42 [00:00<00:00, 46.19it/s, Train RMSE=1.0809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train RMSE: 1.0809, Val RMSE: 1.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 42/42 [00:00<00:00, 46.78it/s, Train RMSE=1.0786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Train RMSE: 1.0786, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 42/42 [00:01<00:00, 40.46it/s, Train RMSE=1.0786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Train RMSE: 1.0786, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 42/42 [00:01<00:00, 40.10it/s, Train RMSE=1.0787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Train RMSE: 1.0787, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 42/42 [00:00<00:00, 45.28it/s, Train RMSE=1.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Train RMSE: 1.0773, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 42/42 [00:01<00:00, 39.62it/s, Train RMSE=1.0774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Train RMSE: 1.0774, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 42/42 [00:00<00:00, 46.77it/s, Train RMSE=1.0774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Train RMSE: 1.0774, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 42/42 [00:01<00:00, 40.09it/s, Train RMSE=1.0766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Train RMSE: 1.0766, Val RMSE: 1.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 42/42 [00:01<00:00, 39.63it/s, Train RMSE=1.0767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Train RMSE: 1.0767, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 42/42 [00:00<00:00, 45.29it/s, Train RMSE=1.0767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Train RMSE: 1.0767, Val RMSE: 1.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 42/42 [00:00<00:00, 45.54it/s, Train RMSE=1.0763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Train RMSE: 1.0763, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 42/42 [00:01<00:00, 39.76it/s, Train RMSE=1.0763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Train RMSE: 1.0763, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 42/42 [00:01<00:00, 39.76it/s, Train RMSE=1.0763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Train RMSE: 1.0763, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 42/42 [00:00<00:00, 45.51it/s, Train RMSE=1.0761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Train RMSE: 1.0761, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 42/42 [00:01<00:00, 38.42it/s, Train RMSE=1.0761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Train RMSE: 1.0761, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 42/42 [00:00<00:00, 50.31it/s, Train RMSE=1.0761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Train RMSE: 1.0761, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 42/42 [00:00<00:00, 45.12it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 42/42 [00:01<00:00, 39.02it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 42/42 [00:01<00:00, 39.46it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 42/42 [00:00<00:00, 45.33it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 42/42 [00:01<00:00, 39.88it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 42/42 [00:00<00:00, 45.23it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 42/42 [00:01<00:00, 39.62it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 42/42 [00:01<00:00, 39.52it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 42/42 [00:00<00:00, 45.67it/s, Train RMSE=1.0760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Train RMSE: 1.0760, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 42/42 [00:00<00:00, 44.43it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 42/42 [00:01<00:00, 37.54it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 42/42 [00:01<00:00, 38.89it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 42/42 [00:00<00:00, 51.33it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 42/42 [00:01<00:00, 39.74it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 42/42 [00:00<00:00, 44.81it/s, Train RMSE=1.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train RMSE: 1.0759, Val RMSE: 1.1740\n",
      "  Training complete. Best Val RMSE: 1.1732\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T10:58:17.093494Z",
     "start_time": "2025-08-21T10:58:15.495741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ranking_results = evaluate_ranking_metrics(\n",
    "    model=mf_torch_model,\n",
    "    test_df=movies_test,\n",
    "    all_data_df=encoded_df,\n",
    "    domain=\"Movies_and_TV\",\n",
    "    k=10,\n",
    "    rating_threshold=POSITIVE_THRESHOLD,  # 4.0\n",
    "    n_neg_samples=100\n",
    ")"
   ],
   "id": "fda6a9f4b6346554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Evaluating Ranking Metrics @k=10 for domain = Movies_and_TV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Ranking Metrics: 100%|██████████| 910/910 [00:01<00:00, 587.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ranking Evaluation Results (domain=Movies_and_TV, k=10) ---\n",
      "   Precision@10: 0.0138\n",
      "   Recall@10:    0.1327\n",
      "   MAP@10:       0.0535\n",
      "   NDCG@10:      0.0724\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment with Implicit Data\n",
    "- Use implicit data instead of explicit ratings\n",
    "- Convert ratings to binary relevance (rating >= 4.0)\n",
    "- Train the model on implicit feedback"
   ],
   "id": "e72c09d5fc070a2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:31.590802Z",
     "start_time": "2025-08-21T14:52:31.428100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_implicit(df, threshold=4.0):\n",
    "    \"\"\"Convert explicit ratings to implicit binary feedback.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"label\"] = (df[\"rating\"] >= threshold).astype(np.float32)  # 1.0 if rating >= threshold, else 0.0\n",
    "    return df\n",
    "\n",
    "implicit_df = make_implicit(encoded_df, 1)\n",
    "implicit_df[\"label\"].value_counts()"
   ],
   "id": "2d2a51956c343733",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    100891\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:33.802534Z",
     "start_time": "2025-08-21T14:52:33.763180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for domain, sub in encoded_df.groupby(\"domain\"):\n",
    "    print(domain, sub)"
   ],
   "id": "f5c57de307340e5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies_and_TV                                 user        item  rating         domain  \\\n",
      "0       AFIMCCRTD3PWOJY7BAOJMA5C7I4A  B00003CXC3     5.0  Movies_and_TV   \n",
      "3       AHM2XKCUWJ4GZQNGDGNEVEN7FJYQ  6305313687     4.0  Movies_and_TV   \n",
      "8       AGXJY52WC5KWDEA3BXTVA5E4YIHQ  B00003CWU3     5.0  Movies_and_TV   \n",
      "11      AHRGTIMQO47C2VLJILIDU53BQKSA  B00005ALS0     4.0  Movies_and_TV   \n",
      "13      AH6C7M7CXHOVGKJ2JXDFFDCWOONA  B00003CX5P     5.0  Movies_and_TV   \n",
      "...                              ...         ...     ...            ...   \n",
      "100855  AGQBF2Z2HGQUIL5BJAVTNGETLH5A  B08XP4KH56     5.0  Movies_and_TV   \n",
      "100858  AFPR3Q7LSH25LTCTO2BWZRDAWGMQ  B0B857V4TH     3.0  Movies_and_TV   \n",
      "100861  AFGLFLHKZQI35Z7UIJWNUCTFSGXQ  B01LW32XQV     5.0  Movies_and_TV   \n",
      "100868  AHZTJHB7BM7ATQG3FD2O53U2VEPQ  B0B18G8R9B     5.0  Movies_and_TV   \n",
      "100879  AEK2SIZXOXZJYYLKNBVBULSU3CKA  B095RHJ52R     1.0  Movies_and_TV   \n",
      "\n",
      "        verified_purchase      timestamp  trust_weight  user_id  item_id  \n",
      "0                   False   957887792000           0.8     3782       55  \n",
      "3                   False   968303405000           0.8     9090       27  \n",
      "8                   False   986429442000           0.8     7498       49  \n",
      "11                   True   990492274000           1.0     9509       75  \n",
      "13                  False   993959175000           0.8     8017       50  \n",
      "...                   ...            ...           ...      ...      ...  \n",
      "100855               True  1678642494851           1.0     6904     4103  \n",
      "100858               True  1678659054172           1.0     4330     4230  \n",
      "100861               True  1678742227231           1.0     3634     3251  \n",
      "100868               True  1678819018034           1.0    10146     4214  \n",
      "100879               True  1679065815122           1.0     1316     4121  \n",
      "\n",
      "[52374 rows x 9 columns]\n",
      "Video_Games                                 user        item  rating       domain  \\\n",
      "1       AFJE7EQZIEFJJOMZGQVAO4AQBHYA  B00000K2R4     5.0  Video_Games   \n",
      "2       AHC3WRQ2PVG3GVNBNK7ATK7YELLA  B001E91OQA     5.0  Video_Games   \n",
      "4       AHVRJMMQMNEWRCZJZ6T5XHMER2PA  B00000K2R4     5.0  Video_Games   \n",
      "5       AHVRJMMQMNEWRCZJZ6T5XHMER2PA  B00004XOWT     5.0  Video_Games   \n",
      "6       AEBMV23TQQKOJBKKF5UUUMBFTXFA  B004HILZV4     5.0  Video_Games   \n",
      "...                              ...         ...     ...          ...   \n",
      "100886  AELQFK4R4NEN3NKHJT4GCYTR2U7Q  B09YCVKMP6     5.0  Video_Games   \n",
      "100887  AELQFK4R4NEN3NKHJT4GCYTR2U7Q  B07HKX4ZV9     5.0  Video_Games   \n",
      "100888  AFHD66FBIKIMNJXWDUUI4QBRY7GQ  B0BJ47N918     5.0  Video_Games   \n",
      "100889  AFHD66FBIKIMNJXWDUUI4QBRY7GQ  B07YYZY2SW     5.0  Video_Games   \n",
      "100890  AFHD66FBIKIMNJXWDUUI4QBRY7GQ  B01FSK99PS     5.0  Video_Games   \n",
      "\n",
      "        verified_purchase      timestamp  trust_weight  user_id  item_id  \n",
      "1                   False   964125246000           0.8     3842       18  \n",
      "2                   False   966276400000           0.8     8338      373  \n",
      "4                   False   971974663000           0.8     9860       18  \n",
      "5                   False   972256169000           0.8     9860       42  \n",
      "6                   False   982086879000           0.8      627     1105  \n",
      "...                   ...            ...           ...      ...      ...  \n",
      "100886               True  1679276897873           1.0     1455     4989  \n",
      "100887               True  1679277004749           1.0     1455     3742  \n",
      "100888               True  1679436702498           1.0     3692     5102  \n",
      "100889               True  1679436840380           1.0     3692     4245  \n",
      "100890               True  1679437038712           1.0     3692     2741  \n",
      "\n",
      "[48517 rows x 9 columns]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:34.881074Z",
     "start_time": "2025-08-21T14:52:34.873128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_implicit_splits(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split interactions per domain with leave-one-out (latest -> val, 2nd latest -> test, rest -> train)\n",
    "    independently for each (domain, user).\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp[\"rank_latest\"] = (\n",
    "        temp.sort_values(\"timestamp\", ascending=False)\n",
    "            .groupby([\"domain\", \"user_id\"])[\"timestamp\"]\n",
    "            .rank(method=\"first\", ascending=False)\n",
    "    )\n",
    "    train = temp[temp[\"rank_latest\"] > 2].drop(columns=\"rank_latest\")\n",
    "    val   = temp[temp[\"rank_latest\"] == 1].drop(columns=\"rank_latest\")\n",
    "    test  = temp[temp[\"rank_latest\"] == 2].drop(columns=\"rank_latest\")\n",
    "\n",
    "    print(f\"Train set size: {train.shape[0]}\")\n",
    "    print(f\"Validation set size: {val.shape[0]}\")\n",
    "    print(f\"Test set size: {test.shape[0]}\")\n",
    "    print(f\"Common users in train and val: {len(set(train['user_id']).intersection(set(val['user_id'])))}\")\n",
    "    print(f\"Common users in train and test: {len(set(train['user_id']).intersection(set(test['user_id'])))}\")\n",
    "    return train.reset_index(drop=True), val.reset_index(drop=True), test.reset_index(drop=True)"
   ],
   "id": "1ec0043be452113b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:35.600216Z",
     "start_time": "2025-08-21T14:52:35.478738Z"
    }
   },
   "cell_type": "code",
   "source": "new_train_df, new_val_df, new_test_df = create_implicit_splits(implicit_df)",
   "id": "a7c0938915ea8973",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 77534\n",
      "Validation set size: 12487\n",
      "Test set size: 10870\n",
      "Common users in train and val: 8935\n",
      "Common users in train and test: 8935\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:36.167405Z",
     "start_time": "2025-08-21T14:52:36.162381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For negatives & candidate pools we must exclude ALL seen items (any rating) in-domain:\n",
    "def seen_and_items_by_domain(df, domain):\n",
    "    dom_all = df[df[\"domain\"] == domain]\n",
    "    domain_items = np.array(sorted(dom_all[\"item_id\"].unique()))\n",
    "    seen_by_user = dom_all.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "    return domain_items, seen_by_user"
   ],
   "id": "83ed8ca90b718580",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:36.945737Z",
     "start_time": "2025-08-21T14:52:36.746773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_domain_items, movies_seen_by_user = seen_and_items_by_domain(implicit_df, SOURCE_DOMAIN)\n",
    "movies_domain_items, movies_seen_by_user"
   ],
   "id": "f60de895484e26cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 4236, 4237, 4238], shape=(4239,)),\n",
       " {0: {102, 611, 1746},\n",
       "  1: {1665, 3150},\n",
       "  2: {1113, 2504, 2593, 3092, 3577},\n",
       "  3: {1081, 1540, 1806, 1827, 2393, 2835, 2950, 3062, 3158, 3179},\n",
       "  4: {195, 222, 823, 1078, 1276, 1319, 1787, 1819, 1912},\n",
       "  5: {986, 2402, 2694, 2717, 3169, 3181},\n",
       "  6: {1334, 1867, 2055, 2345},\n",
       "  7: {1146,\n",
       "   1514,\n",
       "   1709,\n",
       "   2159,\n",
       "   2358,\n",
       "   2688,\n",
       "   2824,\n",
       "   2889,\n",
       "   3178,\n",
       "   3289,\n",
       "   3388,\n",
       "   3393,\n",
       "   3399,\n",
       "   3402,\n",
       "   3418,\n",
       "   3583,\n",
       "   3949},\n",
       "  8: {267, 923, 1003, 1004, 1098, 1577, 1592, 1714, 1879, 2188, 2393, 2764},\n",
       "  9: {2063},\n",
       "  10: {1250, 1622, 2100, 2234, 2345, 2815, 2826, 3172},\n",
       "  11: {393, 468, 590, 632, 924, 1207, 1611, 1920, 2089, 2314, 2671},\n",
       "  13: {1497, 2411, 2729},\n",
       "  15: {2688, 3086, 3473, 3583, 3702, 3749, 3946},\n",
       "  16: {1133,\n",
       "   1449,\n",
       "   1700,\n",
       "   2159,\n",
       "   2287,\n",
       "   2489,\n",
       "   2628,\n",
       "   2685,\n",
       "   2693,\n",
       "   2838,\n",
       "   2888,\n",
       "   3062,\n",
       "   3074,\n",
       "   3136,\n",
       "   3172,\n",
       "   3176,\n",
       "   3203,\n",
       "   3253,\n",
       "   3325},\n",
       "  17: {28,\n",
       "   94,\n",
       "   115,\n",
       "   137,\n",
       "   379,\n",
       "   425,\n",
       "   570,\n",
       "   1231,\n",
       "   1260,\n",
       "   1313,\n",
       "   1377,\n",
       "   1381,\n",
       "   1694,\n",
       "   1697,\n",
       "   1901,\n",
       "   2159,\n",
       "   2177,\n",
       "   2262,\n",
       "   2386,\n",
       "   2436,\n",
       "   2507,\n",
       "   2940,\n",
       "   3014,\n",
       "   3048},\n",
       "  18: {625, 2688},\n",
       "  19: {2418, 2919, 3202, 3382, 3608, 3931, 4111},\n",
       "  20: {42, 153, 177, 339, 444, 527, 805, 3733},\n",
       "  21: {1703, 1989, 2044, 2419, 2564, 2895, 2917, 2975, 2993, 3028},\n",
       "  22: {18, 102, 375, 621, 730, 973, 1185},\n",
       "  24: {1053, 1405, 1514, 1879, 1973, 2159, 2287, 2628},\n",
       "  25: {3397, 3865},\n",
       "  27: {260, 541, 711, 882, 905, 1717, 2157, 2254, 2315},\n",
       "  28: {3506, 4045},\n",
       "  29: {1769, 3716, 3747, 3793},\n",
       "  31: {843, 1172, 1600, 1607, 1821, 2180, 2286, 2386, 3059},\n",
       "  32: {451,\n",
       "   631,\n",
       "   1201,\n",
       "   1209,\n",
       "   1282,\n",
       "   2174,\n",
       "   2289,\n",
       "   2527,\n",
       "   2570,\n",
       "   2611,\n",
       "   2673,\n",
       "   2874,\n",
       "   2973,\n",
       "   2984},\n",
       "  34: {897,\n",
       "   1065,\n",
       "   1423,\n",
       "   1965,\n",
       "   2028,\n",
       "   2487,\n",
       "   2719,\n",
       "   2788,\n",
       "   2863,\n",
       "   3020,\n",
       "   3052,\n",
       "   3363,\n",
       "   3547,\n",
       "   3558,\n",
       "   3615,\n",
       "   3981},\n",
       "  35: {1146, 1902, 2358, 2694, 2919, 3159, 3179},\n",
       "  37: {2106},\n",
       "  38: {129, 349, 2113, 3358},\n",
       "  39: {1136, 1298, 1353, 1369, 1384, 1456, 2983},\n",
       "  40: {3473},\n",
       "  41: {1613,\n",
       "   1638,\n",
       "   1687,\n",
       "   1753,\n",
       "   1831,\n",
       "   2168,\n",
       "   2277,\n",
       "   2624,\n",
       "   2668,\n",
       "   2865,\n",
       "   2900,\n",
       "   3020,\n",
       "   3185,\n",
       "   3201,\n",
       "   3675,\n",
       "   3956},\n",
       "  42: {983, 1283, 1788},\n",
       "  45: {209, 2115},\n",
       "  46: {1612},\n",
       "  47: {1328,\n",
       "   2369,\n",
       "   2688,\n",
       "   2720,\n",
       "   2955,\n",
       "   3058,\n",
       "   3114,\n",
       "   3298,\n",
       "   3418,\n",
       "   3636,\n",
       "   3789,\n",
       "   3922,\n",
       "   3977,\n",
       "   3985,\n",
       "   4001,\n",
       "   4006,\n",
       "   4032,\n",
       "   4113},\n",
       "  49: {714, 1448, 1487, 1528, 1598, 2751, 2893, 3078},\n",
       "  50: {110,\n",
       "   372,\n",
       "   426,\n",
       "   519,\n",
       "   814,\n",
       "   1880,\n",
       "   1948,\n",
       "   2084,\n",
       "   2550,\n",
       "   2693,\n",
       "   3333,\n",
       "   3402,\n",
       "   3633},\n",
       "  53: {595, 3230},\n",
       "  54: {3954, 4215},\n",
       "  58: {768,\n",
       "   1058,\n",
       "   1059,\n",
       "   1091,\n",
       "   1194,\n",
       "   1344,\n",
       "   1923,\n",
       "   2201,\n",
       "   2338,\n",
       "   2347,\n",
       "   2375,\n",
       "   2391,\n",
       "   2642,\n",
       "   2658,\n",
       "   2774,\n",
       "   3018,\n",
       "   3028,\n",
       "   3053,\n",
       "   3156,\n",
       "   3294,\n",
       "   3304,\n",
       "   3393,\n",
       "   3651,\n",
       "   4181},\n",
       "  59: {447, 3290, 3704},\n",
       "  61: {515, 874, 2131, 2896, 2916, 2935, 2963, 3024},\n",
       "  62: {57, 235, 891, 1642, 3714},\n",
       "  63: {11, 125},\n",
       "  64: {389, 1788, 2233},\n",
       "  66: {237, 2197, 2460, 2606},\n",
       "  67: {1069, 1781, 2237, 2545, 3258, 3400, 3525},\n",
       "  68: {2711, 3014},\n",
       "  69: {689},\n",
       "  71: {153, 2707},\n",
       "  72: {652,\n",
       "   855,\n",
       "   1081,\n",
       "   1154,\n",
       "   1475,\n",
       "   1514,\n",
       "   1816,\n",
       "   1827,\n",
       "   1906,\n",
       "   2055,\n",
       "   2089,\n",
       "   2277,\n",
       "   2365,\n",
       "   2519,\n",
       "   2603,\n",
       "   2770,\n",
       "   3067},\n",
       "  73: {1277,\n",
       "   1325,\n",
       "   1616,\n",
       "   1691,\n",
       "   1721,\n",
       "   1729,\n",
       "   1772,\n",
       "   1884,\n",
       "   1907,\n",
       "   1914,\n",
       "   1925,\n",
       "   2001,\n",
       "   2041,\n",
       "   2048,\n",
       "   2062,\n",
       "   2115,\n",
       "   2159,\n",
       "   2312,\n",
       "   2529,\n",
       "   2578,\n",
       "   2583,\n",
       "   2606,\n",
       "   2626,\n",
       "   3168,\n",
       "   3321,\n",
       "   3899},\n",
       "  74: {282,\n",
       "   571,\n",
       "   653,\n",
       "   853,\n",
       "   900,\n",
       "   1085,\n",
       "   1493,\n",
       "   1508,\n",
       "   1570,\n",
       "   1906,\n",
       "   2119,\n",
       "   2159,\n",
       "   2177,\n",
       "   3075,\n",
       "   3545,\n",
       "   3597},\n",
       "  75: {3494},\n",
       "  76: {794, 897, 1847, 2060},\n",
       "  77: {657, 2384, 2688, 4016},\n",
       "  78: {470,\n",
       "   541,\n",
       "   573,\n",
       "   711,\n",
       "   992,\n",
       "   1133,\n",
       "   1361,\n",
       "   1607,\n",
       "   2175,\n",
       "   2305,\n",
       "   2624,\n",
       "   2640,\n",
       "   2950},\n",
       "  80: {477, 852, 1435, 2064, 2635, 2653, 2671, 2702, 3075, 3740},\n",
       "  81: {533, 1327},\n",
       "  83: {1621, 1909, 2203},\n",
       "  84: {362,\n",
       "   363,\n",
       "   760,\n",
       "   762,\n",
       "   771,\n",
       "   895,\n",
       "   1069,\n",
       "   1292,\n",
       "   1344,\n",
       "   1403,\n",
       "   1411,\n",
       "   1565,\n",
       "   1622,\n",
       "   1661,\n",
       "   1737,\n",
       "   1909,\n",
       "   2062,\n",
       "   2097,\n",
       "   2169,\n",
       "   2249,\n",
       "   2251,\n",
       "   2603,\n",
       "   2612,\n",
       "   2925,\n",
       "   2950,\n",
       "   2967,\n",
       "   3061,\n",
       "   3178,\n",
       "   3248,\n",
       "   3261},\n",
       "  85: {395, 541, 720, 1066, 1884, 2032, 2129, 2285, 2474, 2557},\n",
       "  87: {1591, 1684, 1922, 2169, 2234, 2358, 2363, 2549},\n",
       "  88: {551,\n",
       "   770,\n",
       "   784,\n",
       "   877,\n",
       "   987,\n",
       "   1016,\n",
       "   1303,\n",
       "   1480,\n",
       "   1598,\n",
       "   1600,\n",
       "   1702,\n",
       "   2062,\n",
       "   2131,\n",
       "   2142,\n",
       "   2236,\n",
       "   2240,\n",
       "   2284,\n",
       "   2543,\n",
       "   2577,\n",
       "   2771,\n",
       "   3212},\n",
       "  90: {206, 1293, 1295, 1390, 1867, 2566, 2998, 3622},\n",
       "  91: {363, 1906, 2159, 2549, 2950, 4085, 4097},\n",
       "  92: {705,\n",
       "   1537,\n",
       "   2929,\n",
       "   3350,\n",
       "   3352,\n",
       "   3362,\n",
       "   3373,\n",
       "   3410,\n",
       "   3413,\n",
       "   3417,\n",
       "   3433,\n",
       "   3443,\n",
       "   3478,\n",
       "   3534,\n",
       "   3570,\n",
       "   3574,\n",
       "   3578,\n",
       "   3645,\n",
       "   3665,\n",
       "   3681,\n",
       "   3698,\n",
       "   3740},\n",
       "  93: {1528, 2327},\n",
       "  96: {730,\n",
       "   2477,\n",
       "   3013,\n",
       "   3073,\n",
       "   3393,\n",
       "   3532,\n",
       "   3705,\n",
       "   3716,\n",
       "   3747,\n",
       "   3752,\n",
       "   3772,\n",
       "   3812,\n",
       "   3951,\n",
       "   4002,\n",
       "   4059,\n",
       "   4066,\n",
       "   4083,\n",
       "   4101,\n",
       "   4141,\n",
       "   4219,\n",
       "   4237},\n",
       "  97: {2688, 2961, 3263, 3667, 3796},\n",
       "  99: {3243, 3244, 3617},\n",
       "  105: {8, 64, 221, 1544, 2688},\n",
       "  106: {2056,\n",
       "   2157,\n",
       "   2262,\n",
       "   2351,\n",
       "   2358,\n",
       "   2423,\n",
       "   2492,\n",
       "   2646,\n",
       "   2676,\n",
       "   2688,\n",
       "   2721,\n",
       "   2785,\n",
       "   3158},\n",
       "  109: {461, 2168, 2487, 3348, 3743, 4031},\n",
       "  110: {1539,\n",
       "   1541,\n",
       "   2356,\n",
       "   2820,\n",
       "   2950,\n",
       "   2974,\n",
       "   3014,\n",
       "   3058,\n",
       "   3150,\n",
       "   3158,\n",
       "   3171,\n",
       "   3179},\n",
       "  111: {146, 251, 469, 3146, 3436, 3516},\n",
       "  114: {871},\n",
       "  116: {622, 1091, 1698, 1699, 2281, 2358, 2688, 2955, 3065, 3261},\n",
       "  117: {966,\n",
       "   1077,\n",
       "   1242,\n",
       "   1250,\n",
       "   1324,\n",
       "   1597,\n",
       "   1920,\n",
       "   1965,\n",
       "   2358,\n",
       "   2365,\n",
       "   2418,\n",
       "   2558,\n",
       "   3098,\n",
       "   3171},\n",
       "  118: {830, 1009, 1211, 1624, 1654, 1954, 1980},\n",
       "  119: {2689, 3187, 3584},\n",
       "  120: {21},\n",
       "  121: {441, 856, 1105, 2147, 3228, 3581, 3763, 3782, 4113, 4186, 4209, 4232},\n",
       "  122: {558, 1195, 2361, 2629, 3178},\n",
       "  123: {2888, 3185, 3213, 3302, 3361, 3538, 3547, 3600, 3614, 3623, 3660},\n",
       "  125: {2688, 3806, 4202},\n",
       "  126: {923, 1426, 1503, 2006, 2007, 2093, 2240, 2521, 2533, 2646},\n",
       "  128: {3237, 3310, 3504},\n",
       "  129: {114, 955, 1783, 2850, 3603},\n",
       "  130: {1045, 1273, 2321, 2558, 2834, 3031},\n",
       "  131: {591, 1244, 1764, 1805},\n",
       "  133: {2418, 3168, 3312},\n",
       "  134: {1643, 1940},\n",
       "  135: {279, 3064, 3415, 3855, 4012},\n",
       "  138: {299, 442, 537, 3690},\n",
       "  139: {339, 3614},\n",
       "  140: {1229,\n",
       "   1231,\n",
       "   1247,\n",
       "   1305,\n",
       "   1377,\n",
       "   1397,\n",
       "   1503,\n",
       "   1674,\n",
       "   1879,\n",
       "   1886,\n",
       "   1906,\n",
       "   1992,\n",
       "   2043,\n",
       "   2479,\n",
       "   2640,\n",
       "   2816,\n",
       "   2862},\n",
       "  141: {1473, 4143},\n",
       "  142: {1229, 2496, 2628, 2679, 2850, 3014},\n",
       "  143: {839, 1041, 1056, 1505, 1923, 2888, 3261},\n",
       "  144: {74, 839, 843, 1056, 1410, 1822, 1826, 2286, 2960, 4039, 4078, 4085},\n",
       "  146: {651, 853, 2364, 2877, 4037, 4040},\n",
       "  147: {791, 1016, 1017, 1966, 2978, 3182, 3263, 3742},\n",
       "  149: {1252, 1800, 1903, 2138, 2462},\n",
       "  152: {69, 634, 1001, 1581, 2029, 2601},\n",
       "  153: {112, 206, 445, 1853, 2708},\n",
       "  154: {3466, 3501},\n",
       "  155: {128, 187, 335},\n",
       "  156: {3156},\n",
       "  157: {841, 1021, 1077, 1250, 2617, 2693, 2826, 3150, 3159},\n",
       "  158: {64, 1405, 2090, 2753, 3282},\n",
       "  159: {1146, 1444, 2093, 2109, 2266, 2583},\n",
       "  160: {396,\n",
       "   397,\n",
       "   458,\n",
       "   477,\n",
       "   532,\n",
       "   541,\n",
       "   581,\n",
       "   640,\n",
       "   643,\n",
       "   652,\n",
       "   684,\n",
       "   698,\n",
       "   721,\n",
       "   722,\n",
       "   737,\n",
       "   756,\n",
       "   762,\n",
       "   770,\n",
       "   781,\n",
       "   790,\n",
       "   810,\n",
       "   826,\n",
       "   855,\n",
       "   877,\n",
       "   894,\n",
       "   895,\n",
       "   906,\n",
       "   967,\n",
       "   968,\n",
       "   975,\n",
       "   1010,\n",
       "   1034,\n",
       "   1040,\n",
       "   1041,\n",
       "   1046,\n",
       "   1081,\n",
       "   1108,\n",
       "   1113,\n",
       "   1182,\n",
       "   1186,\n",
       "   1301,\n",
       "   1360,\n",
       "   1366,\n",
       "   1475,\n",
       "   1567,\n",
       "   1633,\n",
       "   1661,\n",
       "   1675,\n",
       "   1723,\n",
       "   1735,\n",
       "   1906,\n",
       "   1956,\n",
       "   2062,\n",
       "   2185,\n",
       "   2189,\n",
       "   2332,\n",
       "   2358,\n",
       "   2391,\n",
       "   2453,\n",
       "   2583,\n",
       "   2638,\n",
       "   2640,\n",
       "   2688,\n",
       "   2749,\n",
       "   2866,\n",
       "   2933,\n",
       "   3062,\n",
       "   3105,\n",
       "   3158,\n",
       "   3181,\n",
       "   3185},\n",
       "  161: {524, 1153, 1879, 1990},\n",
       "  162: {1305, 1479, 2374},\n",
       "  164: {3939},\n",
       "  166: {253},\n",
       "  167: {4085, 4113, 4130},\n",
       "  168: {3509, 3749, 3963},\n",
       "  170: {1067},\n",
       "  171: {1622, 1934, 2056, 2164, 2367, 2378, 2636, 2850, 3106, 3152, 3185},\n",
       "  172: {971, 1302, 1735, 2115, 2352, 3175, 3322},\n",
       "  174: {158, 2910},\n",
       "  175: {865, 2688, 2821, 3473, 3702, 3739, 3789},\n",
       "  177: {2933},\n",
       "  178: {1323},\n",
       "  179: {1441, 2072, 2445, 2612, 2691, 2703, 2705, 2996, 3130, 3140},\n",
       "  180: {548, 2877, 3036, 3160, 3461, 3966, 4045},\n",
       "  181: {633,\n",
       "   732,\n",
       "   1017,\n",
       "   1053,\n",
       "   1716,\n",
       "   1982,\n",
       "   2042,\n",
       "   2361,\n",
       "   2414,\n",
       "   2787,\n",
       "   2955,\n",
       "   3156,\n",
       "   3178},\n",
       "  182: {640, 790, 987, 1236, 2355, 2471, 2558},\n",
       "  183: {534, 796, 1762},\n",
       "  186: {29, 48, 148, 557, 1025},\n",
       "  189: {336, 451, 892, 1769, 2695, 2706, 2803, 4052},\n",
       "  191: {281, 2107, 2688, 3302, 3514, 3531, 3581, 3584, 3600},\n",
       "  192: {3715},\n",
       "  194: {1729, 2635, 2662, 2705, 2718, 2845, 2924},\n",
       "  195: {2410},\n",
       "  196: {172, 414, 488, 601, 918, 1139, 1448, 1692, 1844, 1878, 4048},\n",
       "  197: {36, 107, 151, 202, 256, 350, 2200, 4057},\n",
       "  205: {1021, 1978},\n",
       "  206: {604, 1114, 1245},\n",
       "  207: {64, 1123, 1337, 3187},\n",
       "  209: {1411, 2595},\n",
       "  210: {1026, 2804, 3962},\n",
       "  211: {326, 973, 1221},\n",
       "  212: {832, 1036, 1257, 1377, 2121, 2313, 2640, 2940, 3261, 3973, 4078},\n",
       "  213: {1166, 2090},\n",
       "  214: {1155, 1223, 1313, 1514, 1936, 2006, 2055, 2393, 2462, 2915},\n",
       "  215: {1138,\n",
       "   1176,\n",
       "   1498,\n",
       "   1906,\n",
       "   1931,\n",
       "   1973,\n",
       "   2246,\n",
       "   2558,\n",
       "   2782,\n",
       "   2816,\n",
       "   2907,\n",
       "   2950,\n",
       "   3089,\n",
       "   3202,\n",
       "   3388,\n",
       "   3391,\n",
       "   3752,\n",
       "   3872},\n",
       "  217: {802},\n",
       "  218: {2272, 2410},\n",
       "  219: {602, 2688, 3216, 3501},\n",
       "  222: {38,\n",
       "   63,\n",
       "   71,\n",
       "   94,\n",
       "   114,\n",
       "   118,\n",
       "   121,\n",
       "   128,\n",
       "   222,\n",
       "   370,\n",
       "   455,\n",
       "   613,\n",
       "   830,\n",
       "   879,\n",
       "   1160,\n",
       "   1161,\n",
       "   1171,\n",
       "   1473,\n",
       "   1618,\n",
       "   1620,\n",
       "   1744,\n",
       "   2000,\n",
       "   2668,\n",
       "   3243,\n",
       "   3319,\n",
       "   3579},\n",
       "  224: {1183,\n",
       "   1235,\n",
       "   1543,\n",
       "   1633,\n",
       "   1643,\n",
       "   1795,\n",
       "   2094,\n",
       "   2122,\n",
       "   2243,\n",
       "   2248,\n",
       "   2273,\n",
       "   2484,\n",
       "   2486,\n",
       "   2552,\n",
       "   2575,\n",
       "   2624,\n",
       "   2751,\n",
       "   2799,\n",
       "   2805,\n",
       "   2843,\n",
       "   2872,\n",
       "   2893,\n",
       "   3019,\n",
       "   3031,\n",
       "   3251,\n",
       "   3407,\n",
       "   3413,\n",
       "   3448,\n",
       "   3547,\n",
       "   3600,\n",
       "   3633,\n",
       "   3655,\n",
       "   3661,\n",
       "   3665,\n",
       "   3681,\n",
       "   3685,\n",
       "   3726,\n",
       "   3759,\n",
       "   3900,\n",
       "   3944},\n",
       "  225: {355, 373, 760, 854, 1236, 1779, 3584},\n",
       "  227: {1484, 1598, 1600, 1801, 2140, 2221},\n",
       "  228: {328, 441, 1564, 1884, 1953, 2287, 2291},\n",
       "  229: {792},\n",
       "  230: {3720},\n",
       "  231: {708, 731, 1006, 1277, 1734},\n",
       "  232: {102, 624, 680, 1746, 2382},\n",
       "  233: {897, 1504, 2225, 3087, 3139, 3145, 3708},\n",
       "  234: {1340, 1367, 1450, 1454, 2083, 2228, 2292},\n",
       "  235: {555, 1976, 2487, 3700, 3994},\n",
       "  236: {1122},\n",
       "  238: {2353, 2688, 2869, 2937},\n",
       "  239: {220, 236, 846, 3511},\n",
       "  242: {3429, 3885, 3893, 3897},\n",
       "  244: {985, 2868, 3397},\n",
       "  245: {181, 805, 1152, 1355},\n",
       "  247: {652,\n",
       "   895,\n",
       "   916,\n",
       "   1047,\n",
       "   1058,\n",
       "   1059,\n",
       "   1062,\n",
       "   1077,\n",
       "   1182,\n",
       "   1338,\n",
       "   1442,\n",
       "   1622,\n",
       "   2044,\n",
       "   2062,\n",
       "   2160,\n",
       "   2312,\n",
       "   2693,\n",
       "   3264},\n",
       "  248: {2159, 2694, 2969, 3470, 3498},\n",
       "  250: {1058, 1905, 2198, 2592, 3104, 3473, 3747, 4006},\n",
       "  251: {262, 974, 1547, 2144, 2428, 2531, 2960, 3520, 3627, 3721, 3781},\n",
       "  252: {3089, 3159, 3375, 3391, 3397, 3536, 3729, 3838, 3903, 3934},\n",
       "  253: {981, 1166, 2433, 2441, 2628, 3569, 3709, 3810},\n",
       "  254: {4105},\n",
       "  255: {441, 2661, 2774, 4070},\n",
       "  256: {2880, 2919, 4068},\n",
       "  258: {609, 2779, 2936},\n",
       "  259: {58, 670, 829, 1758, 2491, 3465},\n",
       "  261: {819, 1237, 1562, 1563, 2517},\n",
       "  262: {295, 466},\n",
       "  263: {783,\n",
       "   836,\n",
       "   1322,\n",
       "   1476,\n",
       "   1479,\n",
       "   1871,\n",
       "   2314,\n",
       "   2426,\n",
       "   2485,\n",
       "   3082,\n",
       "   3328,\n",
       "   3367,\n",
       "   3444,\n",
       "   3490,\n",
       "   3838,\n",
       "   3859,\n",
       "   3866,\n",
       "   3896,\n",
       "   4088,\n",
       "   4131},\n",
       "  264: {807, 1055, 1133, 1411, 1565, 1821, 2110, 2287, 2435, 2470, 2603, 3171},\n",
       "  265: {855, 968, 1146, 1258, 1543, 1749, 2405, 2423, 2556},\n",
       "  266: {999, 1185, 2693, 3482},\n",
       "  267: {640, 790, 1873, 1985, 2265, 2688, 2897},\n",
       "  268: {343, 1223, 1342, 3348, 3375},\n",
       "  269: {1395, 1774, 1995, 2053, 2110, 2793, 2976, 3404},\n",
       "  270: {1815},\n",
       "  272: {652, 751, 855, 1182, 1324, 1475, 1661, 2062, 2620, 2640, 2964, 3113},\n",
       "  279: {2277, 2574},\n",
       "  281: {1046, 1170, 2159, 2940, 2990, 3075, 3941},\n",
       "  282: {46, 159, 3482},\n",
       "  283: {846},\n",
       "  284: {2983},\n",
       "  286: {3670, 4115},\n",
       "  287: {3830, 4085, 4127},\n",
       "  288: {1031, 1340, 1599, 2009, 2159, 2376, 2378, 2583, 2688, 3059, 3141},\n",
       "  289: {3300},\n",
       "  290: {1346, 2501, 3350, 3796},\n",
       "  292: {1148,\n",
       "   1863,\n",
       "   1954,\n",
       "   2014,\n",
       "   2066,\n",
       "   2067,\n",
       "   2077,\n",
       "   2087,\n",
       "   2196,\n",
       "   2225,\n",
       "   2418,\n",
       "   2607,\n",
       "   3096,\n",
       "   3208},\n",
       "  293: {878,\n",
       "   966,\n",
       "   1051,\n",
       "   1060,\n",
       "   1069,\n",
       "   1093,\n",
       "   1107,\n",
       "   1115,\n",
       "   1145,\n",
       "   1313,\n",
       "   1332,\n",
       "   1384,\n",
       "   1543,\n",
       "   1573,\n",
       "   1622,\n",
       "   1674,\n",
       "   1717,\n",
       "   1781,\n",
       "   1892,\n",
       "   1906,\n",
       "   1907,\n",
       "   1925,\n",
       "   1940,\n",
       "   1979,\n",
       "   2036,\n",
       "   2075,\n",
       "   2094,\n",
       "   2108,\n",
       "   2144,\n",
       "   2152,\n",
       "   2249,\n",
       "   2285,\n",
       "   2318,\n",
       "   2347,\n",
       "   2358,\n",
       "   2423,\n",
       "   2453,\n",
       "   2494,\n",
       "   2579,\n",
       "   2636,\n",
       "   2679,\n",
       "   2799,\n",
       "   2849,\n",
       "   2870,\n",
       "   2895,\n",
       "   2976,\n",
       "   3063,\n",
       "   3214},\n",
       "  295: {1875},\n",
       "  296: {532, 575, 721, 1477, 2065, 2671},\n",
       "  297: {1283, 2886},\n",
       "  299: {1034, 1052, 1177, 1287, 1383, 2691},\n",
       "  300: {577, 1044, 1964, 3880},\n",
       "  301: {799, 1309, 1602, 3197},\n",
       "  304: {652,\n",
       "   855,\n",
       "   1053,\n",
       "   1058,\n",
       "   1059,\n",
       "   1081,\n",
       "   1475,\n",
       "   1543,\n",
       "   1827,\n",
       "   2262,\n",
       "   2287,\n",
       "   2365,\n",
       "   2693,\n",
       "   3115},\n",
       "  305: {1010, 1543, 1909, 1920, 2655, 2688, 3321, 3994},\n",
       "  306: {22, 82, 2870},\n",
       "  307: {769, 2108, 2159, 2281},\n",
       "  308: {1037, 1326, 2358, 2681},\n",
       "  309: {477, 852, 1510, 1598, 1847, 2111},\n",
       "  310: {702, 1018, 2786, 3397, 3459},\n",
       "  311: {812, 1949, 1963},\n",
       "  313: {71, 278, 994, 1076, 2924},\n",
       "  314: {594, 1865, 2348, 2622, 3020},\n",
       "  315: {107, 188, 227},\n",
       "  317: {624, 2357, 2688, 3478, 3604},\n",
       "  318: {625, 785, 1799},\n",
       "  319: {4181, 4192, 4196},\n",
       "  320: {163, 672, 2363, 2640, 2693},\n",
       "  323: {3107, 4194},\n",
       "  324: {496,\n",
       "   629,\n",
       "   1277,\n",
       "   1514,\n",
       "   1531,\n",
       "   2052,\n",
       "   2085,\n",
       "   2159,\n",
       "   2184,\n",
       "   2315,\n",
       "   2351,\n",
       "   2376,\n",
       "   2399,\n",
       "   2583,\n",
       "   2640,\n",
       "   2685,\n",
       "   2834,\n",
       "   2842,\n",
       "   2872,\n",
       "   2949,\n",
       "   2981,\n",
       "   3014,\n",
       "   3068,\n",
       "   3083,\n",
       "   3115,\n",
       "   3153,\n",
       "   3261,\n",
       "   3387,\n",
       "   3440,\n",
       "   3487,\n",
       "   3545,\n",
       "   3874},\n",
       "  326: {88, 2693},\n",
       "  327: {3863, 3992, 4104, 4161, 4190},\n",
       "  328: {233, 1611, 2019, 2233, 2246, 2259, 2343, 2397, 2856, 3241, 3434, 3437},\n",
       "  329: {9},\n",
       "  330: {1284, 2137, 3287, 3351},\n",
       "  331: {8, 102, 165, 190, 503, 1284},\n",
       "  332: {1326,\n",
       "   2307,\n",
       "   2514,\n",
       "   2720,\n",
       "   2989,\n",
       "   3142,\n",
       "   3162,\n",
       "   3291,\n",
       "   3306,\n",
       "   3389,\n",
       "   3405,\n",
       "   3423,\n",
       "   3539},\n",
       "  334: {230, 301, 1757, 3460},\n",
       "  336: {1315, 2947, 3656, 3674},\n",
       "  340: {577, 1477, 2463, 2487, 2851, 3870, 3994},\n",
       "  341: {3089, 3862},\n",
       "  342: {1432,\n",
       "   1512,\n",
       "   1553,\n",
       "   1597,\n",
       "   1609,\n",
       "   1687,\n",
       "   2358,\n",
       "   2386,\n",
       "   2565,\n",
       "   2688,\n",
       "   2778,\n",
       "   2896},\n",
       "  343: {737, 1622, 1957, 2006, 2097, 2386, 2481, 2693, 3062, 3303},\n",
       "  344: {3753},\n",
       "  346: {1314, 1322, 1353, 1508, 1534, 1864, 1940, 2834, 2888},\n",
       "  347: {135, 4216},\n",
       "  348: {1610, 1879, 1905, 1912, 2146, 2270, 2376, 2606},\n",
       "  349: {144,\n",
       "   417,\n",
       "   429,\n",
       "   652,\n",
       "   722,\n",
       "   894,\n",
       "   1186,\n",
       "   1345,\n",
       "   1355,\n",
       "   1359,\n",
       "   1410,\n",
       "   1821,\n",
       "   1867,\n",
       "   2061,\n",
       "   2190,\n",
       "   2493},\n",
       "  351: {309,\n",
       "   1413,\n",
       "   1899,\n",
       "   1900,\n",
       "   1980,\n",
       "   2041,\n",
       "   2045,\n",
       "   2395,\n",
       "   2614,\n",
       "   3182,\n",
       "   3486,\n",
       "   3688,\n",
       "   3751,\n",
       "   3872,\n",
       "   4231},\n",
       "  352: {1257,\n",
       "   1338,\n",
       "   1367,\n",
       "   1850,\n",
       "   1909,\n",
       "   2116,\n",
       "   2133,\n",
       "   2429,\n",
       "   2445,\n",
       "   2458,\n",
       "   2479,\n",
       "   2519,\n",
       "   2666,\n",
       "   2693,\n",
       "   2962,\n",
       "   3065,\n",
       "   3085,\n",
       "   3261,\n",
       "   3279,\n",
       "   3285},\n",
       "  353: {256},\n",
       "  354: {596, 1467, 2445, 2518, 2520, 2678, 3259},\n",
       "  355: {218,\n",
       "   229,\n",
       "   359,\n",
       "   466,\n",
       "   620,\n",
       "   813,\n",
       "   1102,\n",
       "   1199,\n",
       "   1207,\n",
       "   1417,\n",
       "   1546,\n",
       "   1581,\n",
       "   1657,\n",
       "   1696,\n",
       "   1771,\n",
       "   1780,\n",
       "   1804,\n",
       "   2019,\n",
       "   2233},\n",
       "  359: {611},\n",
       "  360: {3, 343},\n",
       "  364: {3, 17, 1196, 1828, 2383},\n",
       "  366: {765, 1111},\n",
       "  367: {2816, 2892, 3189},\n",
       "  368: {679, 1318, 3751, 3813, 3830, 3843, 3857, 3867, 3885, 3902},\n",
       "  370: {714, 3759},\n",
       "  372: {280, 1138, 3263, 3427, 3653, 3834, 3835},\n",
       "  373: {22, 243, 902, 979, 1417, 2756, 3494},\n",
       "  376: {57, 438, 545, 817, 849, 851, 889, 909, 982, 1166, 1435, 1877, 2104},\n",
       "  377: {193, 354, 490, 1727, 2739, 3244},\n",
       "  378: {3627, 4050, 4131, 4228},\n",
       "  380: {1299, 1385, 2494},\n",
       "  381: {1204},\n",
       "  382: {2359, 2693, 2797, 2803, 2815, 3035, 3203},\n",
       "  385: {131,\n",
       "   133,\n",
       "   1245,\n",
       "   1321,\n",
       "   1568,\n",
       "   2174,\n",
       "   2217,\n",
       "   2289,\n",
       "   2527,\n",
       "   2570,\n",
       "   2621,\n",
       "   2708,\n",
       "   2795,\n",
       "   2928,\n",
       "   2969,\n",
       "   2983,\n",
       "   3040,\n",
       "   3460,\n",
       "   3511},\n",
       "  387: {1464, 1481},\n",
       "  388: {2330, 2461, 2520, 3313, 3335, 3533, 3561, 3601},\n",
       "  389: {266, 1871, 3339, 3575},\n",
       "  390: {522, 1428, 2886},\n",
       "  392: {316,\n",
       "   324,\n",
       "   363,\n",
       "   435,\n",
       "   572,\n",
       "   1119,\n",
       "   1330,\n",
       "   1433,\n",
       "   1590,\n",
       "   2276,\n",
       "   2353,\n",
       "   2821,\n",
       "   2877,\n",
       "   2989,\n",
       "   3069,\n",
       "   3213,\n",
       "   3405,\n",
       "   3477,\n",
       "   3499,\n",
       "   3556,\n",
       "   3582,\n",
       "   3696,\n",
       "   3702,\n",
       "   3734,\n",
       "   3736,\n",
       "   3744,\n",
       "   3776,\n",
       "   3794,\n",
       "   3806,\n",
       "   3823,\n",
       "   3835,\n",
       "   3839,\n",
       "   3850,\n",
       "   3904,\n",
       "   3919,\n",
       "   3922,\n",
       "   3934,\n",
       "   3952,\n",
       "   3953,\n",
       "   3962,\n",
       "   3963,\n",
       "   3970,\n",
       "   3978,\n",
       "   3998,\n",
       "   4001,\n",
       "   4003,\n",
       "   4016,\n",
       "   4017,\n",
       "   4023,\n",
       "   4040,\n",
       "   4046,\n",
       "   4047,\n",
       "   4052,\n",
       "   4061,\n",
       "   4063,\n",
       "   4064,\n",
       "   4071,\n",
       "   4073,\n",
       "   4075,\n",
       "   4078,\n",
       "   4087,\n",
       "   4090,\n",
       "   4094,\n",
       "   4097,\n",
       "   4102,\n",
       "   4105,\n",
       "   4113,\n",
       "   4115,\n",
       "   4116,\n",
       "   4121,\n",
       "   4123,\n",
       "   4129,\n",
       "   4130,\n",
       "   4131,\n",
       "   4143,\n",
       "   4145,\n",
       "   4153,\n",
       "   4154,\n",
       "   4157,\n",
       "   4158,\n",
       "   4166,\n",
       "   4169,\n",
       "   4174,\n",
       "   4176,\n",
       "   4181,\n",
       "   4186,\n",
       "   4194,\n",
       "   4197,\n",
       "   4198,\n",
       "   4204,\n",
       "   4206,\n",
       "   4209,\n",
       "   4211,\n",
       "   4212,\n",
       "   4213,\n",
       "   4214,\n",
       "   4221,\n",
       "   4229,\n",
       "   4231,\n",
       "   4232},\n",
       "  394: {27, 162},\n",
       "  395: {3299, 4108, 4175, 4202},\n",
       "  399: {1037, 1622, 1847, 2031, 2251, 2322, 2866},\n",
       "  400: {253, 776},\n",
       "  401: {1038, 1133, 1242, 1514, 1699, 1906, 2693, 2950},\n",
       "  402: {3,\n",
       "   211,\n",
       "   229,\n",
       "   274,\n",
       "   279,\n",
       "   299,\n",
       "   303,\n",
       "   306,\n",
       "   313,\n",
       "   354,\n",
       "   355,\n",
       "   412,\n",
       "   448,\n",
       "   515,\n",
       "   528,\n",
       "   545,\n",
       "   651,\n",
       "   662,\n",
       "   703,\n",
       "   724,\n",
       "   725,\n",
       "   726,\n",
       "   730,\n",
       "   753,\n",
       "   788,\n",
       "   796,\n",
       "   853,\n",
       "   865,\n",
       "   876,\n",
       "   891,\n",
       "   895,\n",
       "   959,\n",
       "   971,\n",
       "   979,\n",
       "   1012,\n",
       "   1085,\n",
       "   1103,\n",
       "   1117,\n",
       "   1129,\n",
       "   1151,\n",
       "   1345,\n",
       "   1388,\n",
       "   1418,\n",
       "   1496,\n",
       "   1513,\n",
       "   1518,\n",
       "   1558,\n",
       "   1574,\n",
       "   1581,\n",
       "   1695,\n",
       "   1900,\n",
       "   1935,\n",
       "   1970,\n",
       "   2038,\n",
       "   2089,\n",
       "   2151,\n",
       "   2384,\n",
       "   2392,\n",
       "   2477,\n",
       "   2592,\n",
       "   2603,\n",
       "   2733,\n",
       "   2776,\n",
       "   2950,\n",
       "   2970,\n",
       "   3103,\n",
       "   3209,\n",
       "   3250,\n",
       "   3513,\n",
       "   3878},\n",
       "  406: {650, 1682},\n",
       "  409: {1190, 1327},\n",
       "  411: {1862, 2545, 3397, 3834, 4032},\n",
       "  413: {1089,\n",
       "   1115,\n",
       "   1386,\n",
       "   1390,\n",
       "   1886,\n",
       "   1898,\n",
       "   2103,\n",
       "   2115,\n",
       "   2116,\n",
       "   2128,\n",
       "   2228,\n",
       "   2262,\n",
       "   2436,\n",
       "   2507,\n",
       "   2580,\n",
       "   2671,\n",
       "   3214,\n",
       "   3547},\n",
       "  415: {1558, 2187},\n",
       "  416: {78, 606, 833, 2076, 3295},\n",
       "  417: {2361, 3020, 3156, 3182},\n",
       "  420: {891},\n",
       "  421: {1954, 1985, 4173},\n",
       "  424: {2877, 3613},\n",
       "  425: {1847, 2514},\n",
       "  426: {3397, 4011},\n",
       "  427: {2614, 3304, 3746},\n",
       "  428: {734, 1067, 1537, 2577, 3112, 3321, 3380, 3624, 3760, 3914},\n",
       "  429: {277,\n",
       "   3032,\n",
       "   3291,\n",
       "   4098,\n",
       "   4124,\n",
       "   4131,\n",
       "   4135,\n",
       "   4157,\n",
       "   4162,\n",
       "   4166,\n",
       "   4181,\n",
       "   4189,\n",
       "   4207,\n",
       "   4211,\n",
       "   4228},\n",
       "  430: {115, 137, 155, 840, 1658, 2466, 2623, 2669, 3245},\n",
       "  431: {616},\n",
       "  432: {265,\n",
       "   456,\n",
       "   541,\n",
       "   587,\n",
       "   905,\n",
       "   988,\n",
       "   1031,\n",
       "   1039,\n",
       "   1214,\n",
       "   1978,\n",
       "   2098,\n",
       "   2159,\n",
       "   2359,\n",
       "   2574,\n",
       "   2605,\n",
       "   3725},\n",
       "  433: {1334,\n",
       "   1536,\n",
       "   1574,\n",
       "   1797,\n",
       "   1929,\n",
       "   1930,\n",
       "   1946,\n",
       "   2097,\n",
       "   2140,\n",
       "   2230,\n",
       "   2480,\n",
       "   2481,\n",
       "   2882,\n",
       "   2933,\n",
       "   4229},\n",
       "  434: {3612, 3806},\n",
       "  435: {1432, 1906, 2950, 3253},\n",
       "  437: {1095, 1558, 2183, 2184, 2187, 2636, 2688, 2711, 2795, 4228},\n",
       "  439: {55},\n",
       "  440: {4031, 4066, 4131, 4181},\n",
       "  441: {28, 187, 402, 765, 911, 915, 1084, 1213, 1246, 1404, 1435},\n",
       "  442: {519, 3358},\n",
       "  443: {1503,\n",
       "   1985,\n",
       "   2122,\n",
       "   2786,\n",
       "   2980,\n",
       "   3069,\n",
       "   3082,\n",
       "   3153,\n",
       "   3261,\n",
       "   3397,\n",
       "   3604,\n",
       "   3934,\n",
       "   4054,\n",
       "   4065,\n",
       "   4096,\n",
       "   4109,\n",
       "   4195},\n",
       "  444: {4,\n",
       "   46,\n",
       "   172,\n",
       "   319,\n",
       "   337,\n",
       "   433,\n",
       "   766,\n",
       "   898,\n",
       "   918,\n",
       "   1443,\n",
       "   1445,\n",
       "   1612,\n",
       "   1664,\n",
       "   1697},\n",
       "  446: {380,\n",
       "   1722,\n",
       "   1724,\n",
       "   1755,\n",
       "   1900,\n",
       "   1977,\n",
       "   2197,\n",
       "   2207,\n",
       "   2425,\n",
       "   2745,\n",
       "   2792,\n",
       "   3150,\n",
       "   3397,\n",
       "   3428,\n",
       "   3446,\n",
       "   3504,\n",
       "   3747,\n",
       "   3755,\n",
       "   3901,\n",
       "   3905,\n",
       "   4014,\n",
       "   4064,\n",
       "   4099,\n",
       "   4113},\n",
       "  447: {701},\n",
       "  448: {652,\n",
       "   1010,\n",
       "   1514,\n",
       "   1567,\n",
       "   1597,\n",
       "   1669,\n",
       "   1821,\n",
       "   1902,\n",
       "   1906,\n",
       "   1936,\n",
       "   1977,\n",
       "   2013,\n",
       "   2159,\n",
       "   2453,\n",
       "   2583,\n",
       "   2644,\n",
       "   2778,\n",
       "   2816,\n",
       "   3014,\n",
       "   3157,\n",
       "   3171,\n",
       "   3179,\n",
       "   3214},\n",
       "  449: {2214, 3397, 4120, 4126},\n",
       "  450: {1133,\n",
       "   1166,\n",
       "   2549,\n",
       "   3014,\n",
       "   3414,\n",
       "   3486,\n",
       "   3614,\n",
       "   3789,\n",
       "   3890,\n",
       "   3962,\n",
       "   4157,\n",
       "   4158},\n",
       "  452: {28, 352, 443, 541, 737, 1537, 1777, 1985, 2093, 2395, 2594, 2671},\n",
       "  454: {1290, 1296, 1963},\n",
       "  456: {1480, 3426, 4009, 4093},\n",
       "  459: {1564, 3209, 3998, 4204},\n",
       "  460: {1636, 1812},\n",
       "  461: {1128, 2007, 2287, 2612, 2662},\n",
       "  462: {707, 2108, 3023, 3103},\n",
       "  463: {1053, 2065, 2638},\n",
       "  464: {662, 3115},\n",
       "  465: {902, 1185},\n",
       "  467: {255, 1509},\n",
       "  469: {2029, 3822},\n",
       "  471: {59, 2926, 3161, 3229, 3355, 3384},\n",
       "  472: {2983},\n",
       "  473: {1410, 1822, 1935, 2287, 2627, 2694, 2703, 3136, 3158, 3325},\n",
       "  474: {127, 2174, 2217, 2510, 2546, 3109, 3161, 3345, 3642},\n",
       "  476: {832, 3356},\n",
       "  478: {428,\n",
       "   911,\n",
       "   1152,\n",
       "   1157,\n",
       "   1210,\n",
       "   1213,\n",
       "   1315,\n",
       "   2217,\n",
       "   2289,\n",
       "   2344,\n",
       "   2401,\n",
       "   2589,\n",
       "   3875},\n",
       "  479: {830, 2489, 3243, 4005, 4020},\n",
       "  480: {1237, 1675, 2325, 2347, 2560, 3150, 3335, 3401, 3415, 3473},\n",
       "  481: {215, 983, 1374, 1759, 1853, 2033},\n",
       "  483: {1286, 1674, 2054, 2509, 2561, 2742, 2775, 2782, 2818, 3048, 3181},\n",
       "  485: {45, 700, 1189, 1206, 1657},\n",
       "  486: {72,\n",
       "   163,\n",
       "   235,\n",
       "   254,\n",
       "   939,\n",
       "   1329,\n",
       "   1528,\n",
       "   1566,\n",
       "   1877,\n",
       "   2119,\n",
       "   2127,\n",
       "   2174,\n",
       "   2262,\n",
       "   2317,\n",
       "   2399,\n",
       "   2586,\n",
       "   2685,\n",
       "   2688,\n",
       "   2825,\n",
       "   3039,\n",
       "   3181,\n",
       "   3197,\n",
       "   3387,\n",
       "   3488,\n",
       "   3496,\n",
       "   3665,\n",
       "   4006,\n",
       "   4025,\n",
       "   4206},\n",
       "  488: {1027, 1028, 1440, 1969, 2480, 2689, 2979, 3417, 3495, 3584, 4085},\n",
       "  491: {1041, 1567, 1590, 1934, 2549, 2583, 3010, 3013, 3178, 3311},\n",
       "  492: {623,\n",
       "   981,\n",
       "   999,\n",
       "   1367,\n",
       "   1419,\n",
       "   1441,\n",
       "   1514,\n",
       "   1568,\n",
       "   1684,\n",
       "   1804,\n",
       "   2549,\n",
       "   2815,\n",
       "   2936,\n",
       "   3079,\n",
       "   3145,\n",
       "   3150,\n",
       "   3159,\n",
       "   3175,\n",
       "   3402,\n",
       "   3443,\n",
       "   3519,\n",
       "   3564,\n",
       "   3707},\n",
       "  493: {775},\n",
       "  495: {321, 652, 889, 1016, 1261, 1558, 2183, 2688, 3178},\n",
       "  496: {454, 2688, 3169, 3228, 4117},\n",
       "  497: {861, 3773},\n",
       "  498: {52, 347, 1203, 1427, 1461, 1467, 1727, 1734, 1786, 1787, 3994},\n",
       "  500: {557, 3880, 3914},\n",
       "  503: {753, 770, 781, 1555, 2741, 2933},\n",
       "  504: {2877, 3858, 4105, 4151, 4158, 4181, 4196},\n",
       "  505: {459, 3177},\n",
       "  506: {603, 1714, 2262, 2688, 2775, 3583, 3798},\n",
       "  511: {26, 884, 973, 2126, 2154, 2733, 3960},\n",
       "  512: {1581, 2097},\n",
       "  514: {2558, 2581, 2600, 3131, 3137, 3153, 3346},\n",
       "  516: {63, 1217, 3473, 3650},\n",
       "  519: {21, 247, 301, 2217, 2297},\n",
       "  524: {714,\n",
       "   1515,\n",
       "   1798,\n",
       "   2315,\n",
       "   2418,\n",
       "   2643,\n",
       "   2806,\n",
       "   2846,\n",
       "   3650,\n",
       "   3703,\n",
       "   3760,\n",
       "   3818,\n",
       "   3969,\n",
       "   4149,\n",
       "   4173,\n",
       "   4201,\n",
       "   4224},\n",
       "  525: {64, 227, 1382},\n",
       "  526: {1168, 1757},\n",
       "  527: {2433},\n",
       "  531: {1306, 1308, 1598, 1651, 1839, 1867, 2114, 2233},\n",
       "  532: {279, 937, 1332, 2825, 3373, 3394, 3697},\n",
       "  535: {1906, 2404, 2442, 2858, 3181, 3402},\n",
       "  536: {1286, 2832, 2890, 2944, 3116, 3186, 3208},\n",
       "  537: {799,\n",
       "   991,\n",
       "   1560,\n",
       "   1906,\n",
       "   2077,\n",
       "   2423,\n",
       "   2516,\n",
       "   2678,\n",
       "   2688,\n",
       "   2784,\n",
       "   2869,\n",
       "   2905,\n",
       "   3162,\n",
       "   3266,\n",
       "   3953},\n",
       "  538: {1012, 1514, 2169, 2287, 2358, 2622, 2688, 2817, 3812},\n",
       "  539: {2916, 2987, 3622, 3688},\n",
       "  540: {53, 2211, 2246},\n",
       "  541: {528,\n",
       "   565,\n",
       "   797,\n",
       "   942,\n",
       "   973,\n",
       "   1478,\n",
       "   1593,\n",
       "   1728,\n",
       "   1915,\n",
       "   1954,\n",
       "   2208,\n",
       "   2348,\n",
       "   2408,\n",
       "   2776,\n",
       "   2897,\n",
       "   2938,\n",
       "   2966,\n",
       "   3165,\n",
       "   3320,\n",
       "   3338,\n",
       "   3464,\n",
       "   3630},\n",
       "  542: {499,\n",
       "   597,\n",
       "   713,\n",
       "   877,\n",
       "   1176,\n",
       "   1236,\n",
       "   1264,\n",
       "   1299,\n",
       "   1385,\n",
       "   1414,\n",
       "   1585,\n",
       "   2157,\n",
       "   2182,\n",
       "   2347,\n",
       "   2445,\n",
       "   2563,\n",
       "   2872,\n",
       "   3152,\n",
       "   3291,\n",
       "   3498,\n",
       "   3681},\n",
       "  543: {257,\n",
       "   265,\n",
       "   622,\n",
       "   968,\n",
       "   976,\n",
       "   1010,\n",
       "   1031,\n",
       "   1592,\n",
       "   1722,\n",
       "   2188,\n",
       "   2287,\n",
       "   2447,\n",
       "   2603,\n",
       "   2914,\n",
       "   3062,\n",
       "   3466,\n",
       "   3615},\n",
       "  544: {143,\n",
       "   539,\n",
       "   983,\n",
       "   1744,\n",
       "   1828,\n",
       "   2886,\n",
       "   2969,\n",
       "   3078,\n",
       "   3145,\n",
       "   3237,\n",
       "   3245,\n",
       "   3279,\n",
       "   3364,\n",
       "   3397,\n",
       "   3447,\n",
       "   3511,\n",
       "   3786,\n",
       "   3790,\n",
       "   3968,\n",
       "   4092},\n",
       "  547: {197, 528, 766, 1787, 2127},\n",
       "  548: {1423},\n",
       "  549: {2011, 2038, 2529, 2651, 3178},\n",
       "  550: {474, 3350, 3680, 3698},\n",
       "  551: {99, 314, 700, 912, 1166},\n",
       "  553: {640},\n",
       "  554: {2237, 3587},\n",
       "  555: {504, 589, 682, 2496, 2706, 2832, 2940, 3083, 3095},\n",
       "  557: {407},\n",
       "  558: {928, 929, 1894, 3293, 3907, 4002, 4003, 4181},\n",
       "  559: {37, 217},\n",
       "  561: {2062, 2100, 2888, 2915, 3367, 3570},\n",
       "  563: {640, 1411, 1598, 2287, 3185},\n",
       "  565: {762, 770, 894, 1543, 2102, 2249, 2486, 2549, 2889, 3325},\n",
       "  566: {743, 1081, 1404, 2641, 3291, 3420, 3443, 3446, 3452},\n",
       "  567: {2610, 3024, 3037, 3160, 3358, 3683},\n",
       "  571: {2531, 2901, 2919, 3473, 3749, 3890},\n",
       "  573: {2136, 2411, 3005},\n",
       "  577: {189},\n",
       "  579: {1023, 2699},\n",
       "  580: {871, 2257, 2262},\n",
       "  581: {406},\n",
       "  584: {2159},\n",
       "  586: {1034,\n",
       "   1040,\n",
       "   1041,\n",
       "   1052,\n",
       "   1058,\n",
       "   1177,\n",
       "   1244,\n",
       "   1398,\n",
       "   1555,\n",
       "   1985,\n",
       "   2159,\n",
       "   2357,\n",
       "   2358,\n",
       "   2449,\n",
       "   2531,\n",
       "   2646,\n",
       "   2688,\n",
       "   2787,\n",
       "   2816,\n",
       "   2922,\n",
       "   2995,\n",
       "   3159,\n",
       "   3216,\n",
       "   3881},\n",
       "  588: {653, 2414, 2425, 2586, 3651, 3655, 3860, 3992, 4068, 4113, 4121},\n",
       "  592: {3742, 3813, 3872, 4156},\n",
       "  593: {672, 682, 3389, 3496, 3542, 3749, 3946, 4002, 4012},\n",
       "  594: {3182},\n",
       "  595: {273},\n",
       "  596: {3738, 3953, 4030, 4127, 4133, 4160},\n",
       "  600: {862, 910, 1154, 1241, 1490, 1658, 2074, 2298, 2679, 2711, 3245, 3291},\n",
       "  601: {349,\n",
       "   383,\n",
       "   517,\n",
       "   777,\n",
       "   818,\n",
       "   944,\n",
       "   1354,\n",
       "   1420,\n",
       "   1681,\n",
       "   1702,\n",
       "   1853,\n",
       "   1943,\n",
       "   2073,\n",
       "   2350,\n",
       "   2528,\n",
       "   2633,\n",
       "   2707,\n",
       "   2721,\n",
       "   3550,\n",
       "   3724,\n",
       "   3740},\n",
       "  602: {2663, 3521},\n",
       "  603: {2194},\n",
       "  604: {96, 2602},\n",
       "  605: {893, 925, 1020, 1146, 1388, 1486, 1626, 2206, 2551, 2829, 3175, 3273},\n",
       "  607: {655, 1048, 1049, 1108, 1514, 1622, 1643},\n",
       "  608: {698, 728, 760, 825, 1020, 1148, 1387, 1470, 1833, 2249, 2476, 2549},\n",
       "  609: {441, 2331, 3397, 3756, 3832, 3856, 3998, 4086, 4141},\n",
       "  610: {729, 1543, 1859, 1907, 1920, 2358, 2688, 3159},\n",
       "  612: {625, 757},\n",
       "  613: {1139, 1277, 2028, 2366, 2448, 2455, 2896, 3389},\n",
       "  614: {855, 944, 1153, 1207, 1221, 1463, 1541, 1827, 2211, 2525, 2976},\n",
       "  615: {1055, 1133, 1607, 2421, 2688, 2950, 3285, 3813, 3979},\n",
       "  616: {1188},\n",
       "  617: {1475, 1848, 2695},\n",
       "  618: {1528, 1568},\n",
       "  620: {3400, 3426, 3455, 3464, 3528, 3576, 3971},\n",
       "  622: {962, 2746, 2764, 2765, 2904},\n",
       "  623: {1042, 1909, 2167, 2262, 2545, 2625, 2705, 2803, 3827},\n",
       "  624: {1423, 3859, 4020, 4029},\n",
       "  625: {896,\n",
       "   1054,\n",
       "   1075,\n",
       "   1441,\n",
       "   1566,\n",
       "   1903,\n",
       "   1977,\n",
       "   2159,\n",
       "   2254,\n",
       "   2357,\n",
       "   2358,\n",
       "   2378,\n",
       "   2475,\n",
       "   2516,\n",
       "   2688,\n",
       "   2703,\n",
       "   2815,\n",
       "   2823,\n",
       "   2962,\n",
       "   3059,\n",
       "   3322,\n",
       "   3854},\n",
       "  626: {1356, 1662, 1729, 1862, 1876, 1919, 2420, 2583, 2707},\n",
       "  628: {2689, 3181, 3399, 3747, 3861},\n",
       "  629: {76,\n",
       "   158,\n",
       "   263,\n",
       "   426,\n",
       "   434,\n",
       "   594,\n",
       "   847,\n",
       "   950,\n",
       "   953,\n",
       "   1188,\n",
       "   1211,\n",
       "   1283,\n",
       "   1623,\n",
       "   1674,\n",
       "   1805,\n",
       "   1823,\n",
       "   1842,\n",
       "   1853,\n",
       "   1878,\n",
       "   2018,\n",
       "   2019,\n",
       "   2023,\n",
       "   2090,\n",
       "   2172,\n",
       "   2211,\n",
       "   2220,\n",
       "   2259,\n",
       "   2290,\n",
       "   2397,\n",
       "   2454,\n",
       "   2526,\n",
       "   2569,\n",
       "   2587,\n",
       "   2886},\n",
       "  630: {1472, 2327, 2401},\n",
       "  631: {980,\n",
       "   1017,\n",
       "   1042,\n",
       "   1558,\n",
       "   1980,\n",
       "   2092,\n",
       "   2185,\n",
       "   2664,\n",
       "   2786,\n",
       "   2849,\n",
       "   2981,\n",
       "   2982,\n",
       "   3124,\n",
       "   3743,\n",
       "   3788,\n",
       "   4001,\n",
       "   4210},\n",
       "  632: {1112, 2902, 2920, 3063, 3150},\n",
       "  633: {7,\n",
       "   163,\n",
       "   235,\n",
       "   456,\n",
       "   554,\n",
       "   681,\n",
       "   1109,\n",
       "   1280,\n",
       "   1316,\n",
       "   1322,\n",
       "   1648,\n",
       "   1762,\n",
       "   1796,\n",
       "   1839,\n",
       "   2116,\n",
       "   2600},\n",
       "  634: {280, 1151, 2123},\n",
       "  636: {1163, 1350, 3700},\n",
       "  637: {1280, 1461, 1616, 3234},\n",
       "  638: {403, 844, 1277, 3808, 3914, 3931, 4015},\n",
       "  639: {370, 542, 1294, 1624, 1666, 3692},\n",
       "  640: {2042, 2277, 3415, 3572, 3581, 3702},\n",
       "  645: {3397, 3459, 3865, 4085},\n",
       "  647: {270, 717, 880, 1327, 1773, 2379, 2383, 2546, 2733, 2988, 3265, 3609},\n",
       "  648: {561, 562, 1192, 1547, 2155},\n",
       "  649: {668},\n",
       "  651: {1396, 1568, 2688},\n",
       "  653: {498, 506, 507, 612, 782},\n",
       "  654: {1004, 2160, 2164, 2361, 2420, 2548, 2630, 2693, 3010, 3178},\n",
       "  655: {321, 400, 405, 938, 950},\n",
       "  656: {1089,\n",
       "   1135,\n",
       "   1314,\n",
       "   1493,\n",
       "   1742,\n",
       "   1947,\n",
       "   2405,\n",
       "   2458,\n",
       "   2484,\n",
       "   2549,\n",
       "   2718,\n",
       "   2933,\n",
       "   2974,\n",
       "   3259,\n",
       "   3630,\n",
       "   3796,\n",
       "   3801,\n",
       "   3914,\n",
       "   3947,\n",
       "   3979,\n",
       "   3985},\n",
       "  657: {50, 57},\n",
       "  659: {751, 1396, 1644, 1774, 1906, 2028, 2270, 2277, 2395, 2405, 2431, 3559},\n",
       "  660: {1017, 2185, 2187, 2393, 2688},\n",
       "  662: {144, 190},\n",
       "  663: {434, 1690, 2258, 2295, 3024, 3078, 3087, 3111, 3139, 3242, 3768, 3804},\n",
       "  664: {1044, 1435, 1784, 2171, 2348, 2880, 3968, 4152},\n",
       "  665: {652, 1003, 1371, 1827, 1886, 2033, 2054},\n",
       "  666: {746, 1360, 1379, 1821, 2202, 2888, 2926},\n",
       "  667: {0, 1568},\n",
       "  668: {66, 2177, 3283},\n",
       "  669: {270, 488, 2122},\n",
       "  671: {71, 481, 973, 1159, 2712, 3146, 3243},\n",
       "  673: {57, 2528, 2536, 3558, 3559},\n",
       "  675: {1424, 1534, 1992, 2294, 2950},\n",
       "  676: {640, 1633, 1920, 2101, 2451, 2459, 2805, 2888, 3311},\n",
       "  677: {4173, 4209, 4214, 4222, 4238},\n",
       "  679: {942, 1970, 1974, 2045, 2074, 2304, 2311, 2315, 2452, 2497, 2535, 3776},\n",
       "  682: {3589, 3946, 4093, 4127, 4136},\n",
       "  683: {944, 1692, 2018, 2145, 2218, 2358, 2736, 2886, 3460},\n",
       "  685: {1251, 2263, 3282},\n",
       "  686: {2249, 2928, 2950, 2976, 3005, 3062, 3117, 3171},\n",
       "  687: {447, 2794, 3220, 3251, 3331, 3473, 3736},\n",
       "  689: {1784, 2792, 3039, 3132, 3218, 3685, 4084},\n",
       "  690: {2732, 2749},\n",
       "  691: {2569, 3276},\n",
       "  692: {1681, 2019},\n",
       "  693: {2242, 2349},\n",
       "  695: {1080,\n",
       "   2358,\n",
       "   2445,\n",
       "   2662,\n",
       "   2671,\n",
       "   2688,\n",
       "   2778,\n",
       "   2834,\n",
       "   2889,\n",
       "   3159,\n",
       "   3169,\n",
       "   3261,\n",
       "   3313,\n",
       "   3479},\n",
       "  696: {1263, 1335, 2230},\n",
       "  698: {602, 792, 1303, 1753, 1968, 3742},\n",
       "  700: {59, 227, 319, 542, 1469},\n",
       "  701: {340},\n",
       "  703: {955, 4202},\n",
       "  705: {364, 1331, 3222, 3707},\n",
       "  706: {1594, 2321, 2336},\n",
       "  707: {2731, 3033},\n",
       "  708: {101, 851, 3226},\n",
       "  709: {105, 228},\n",
       "  710: {1691, 2349, 2598, 2715, 4054, 4088, 4113},\n",
       "  711: {284, 2155},\n",
       "  712: {1259, 1676},\n",
       "  713: {214, 227},\n",
       "  714: {640, 790, 2065, 2111, 2165, 2583, 2596, 2599, 3497},\n",
       "  715: {303, 681, 2573, 2671, 3062},\n",
       "  717: {1119,\n",
       "   1354,\n",
       "   1601,\n",
       "   1705,\n",
       "   1756,\n",
       "   2199,\n",
       "   2253,\n",
       "   2384,\n",
       "   2411,\n",
       "   2530,\n",
       "   2688,\n",
       "   2805,\n",
       "   3253,\n",
       "   3292,\n",
       "   3515,\n",
       "   3531,\n",
       "   3569,\n",
       "   3583,\n",
       "   3640,\n",
       "   3651,\n",
       "   3710,\n",
       "   3747,\n",
       "   3780,\n",
       "   3812,\n",
       "   3838,\n",
       "   3860,\n",
       "   3861,\n",
       "   3886,\n",
       "   3904,\n",
       "   3920,\n",
       "   3955,\n",
       "   4034,\n",
       "   4155},\n",
       "  718: {3374},\n",
       "  719: {652,\n",
       "   855,\n",
       "   1538,\n",
       "   1542,\n",
       "   2364,\n",
       "   2453,\n",
       "   2624,\n",
       "   2819,\n",
       "   3009,\n",
       "   3120,\n",
       "   3171,\n",
       "   3302,\n",
       "   3614,\n",
       "   4153},\n",
       "  720: {231, 1247, 1597, 2755, 2888, 3048, 3133, 3317, 3368},\n",
       "  721: {504, 572, 622, 679, 769, 894, 932, 1012, 1475, 2202, 2754},\n",
       "  722: {1928,\n",
       "   2066,\n",
       "   2077,\n",
       "   2260,\n",
       "   2318,\n",
       "   2323,\n",
       "   2348,\n",
       "   2373,\n",
       "   2396,\n",
       "   2415,\n",
       "   2487,\n",
       "   2794,\n",
       "   2971,\n",
       "   3228},\n",
       "  723: {842, 895, 1109, 1357, 1661, 2602},\n",
       "  724: {1066, 1486},\n",
       "  725: {346, 1441, 1923, 2802, 3291, 3393, 3399, 3438},\n",
       "  726: {1108, 2370, 2492, 2688, 2794, 3901, 4068, 4184},\n",
       "  727: {979, 1327, 1733},\n",
       "  729: {2228, 2741, 2915, 3364, 3397, 3422, 3777},\n",
       "  730: {227, 272, 351, 418, 433, 1374},\n",
       "  731: {1167},\n",
       "  732: {477, 740, 1139, 2108, 2159},\n",
       "  733: {408, 1475, 2671, 2689, 2866},\n",
       "  734: {754, 2495, 2814, 3650, 4094},\n",
       "  735: {582, 1181, 1205, 1753, 1877, 2182, 2314, 2347, 2395, 4108},\n",
       "  736: {1957},\n",
       "  737: {96, 434, 464, 487, 489, 760, 1632, 1653},\n",
       "  739: {1922, 2309, 2381, 2810, 3000, 3477},\n",
       "  740: {1669, 2286, 4019},\n",
       "  741: {624,\n",
       "   1854,\n",
       "   2126,\n",
       "   2258,\n",
       "   2289,\n",
       "   2327,\n",
       "   2344,\n",
       "   2388,\n",
       "   3838,\n",
       "   3878,\n",
       "   3955,\n",
       "   4088,\n",
       "   4133},\n",
       "  743: {197, 295, 1110, 1643},\n",
       "  744: {4097},\n",
       "  747: {3211, 3394, 3741},\n",
       "  751: {974, 1249, 3573, 4127},\n",
       "  752: {12, 819, 1342, 1483, 1985, 2115, 2882, 3314},\n",
       "  753: {1356, 1577, 1669, 2060, 2097, 2314, 2602, 2688, 2749, 2859, 3103},\n",
       "  754: {2177, 2646, 3181, 3187},\n",
       "  755: {1718},\n",
       "  756: {511},\n",
       "  757: {2129, 2362, 2688, 2821, 2829, 3473, 4153},\n",
       "  759: {2583, 3065, 3085},\n",
       "  760: {1133, 1870, 1906, 2159, 2160, 2357, 2549, 3382},\n",
       "  761: {449, 1176, 1384, 1395, 1415, 1542, 1752, 1966, 1979, 2200, 2907},\n",
       "  764: {1214, 1411},\n",
       "  766: {2408, 2711, 3261, 4214},\n",
       "  767: {3952, 4019, 4028, 4113, 4117, 4143, 4153, 4202, 4228},\n",
       "  768: {10, 158, 173, 229, 306, 1612, 2154},\n",
       "  769: {313,\n",
       "   1022,\n",
       "   1023,\n",
       "   1097,\n",
       "   2249,\n",
       "   3091,\n",
       "   3175,\n",
       "   3264,\n",
       "   3315,\n",
       "   3397,\n",
       "   3419,\n",
       "   3427,\n",
       "   3484,\n",
       "   3485,\n",
       "   3504,\n",
       "   3537,\n",
       "   3744,\n",
       "   3762,\n",
       "   3763,\n",
       "   3844,\n",
       "   3971,\n",
       "   4030,\n",
       "   4094,\n",
       "   4128,\n",
       "   4192},\n",
       "  770: {778},\n",
       "  771: {1104, 1411, 1470, 1866, 2238, 2412, 2505, 2888, 3005, 3218},\n",
       "  773: {250, 634, 890},\n",
       "  774: {2719},\n",
       "  775: {630, 775, 1146, 2723, 3187},\n",
       "  778: {29, 553, 1245, 1297, 1710, 2222, 2591},\n",
       "  779: {504, 1055, 1613, 1643, 1667, 2089, 2094, 2688, 3214},\n",
       "  780: {701, 708, 1373},\n",
       "  781: {855, 937, 1634, 1684, 1779, 1896, 2159, 2357, 2449, 2486, 2549},\n",
       "  782: {807, 1969, 3103, 4088},\n",
       "  783: {1230,\n",
       "   1286,\n",
       "   2115,\n",
       "   2165,\n",
       "   2254,\n",
       "   2277,\n",
       "   2278,\n",
       "   2423,\n",
       "   2646,\n",
       "   2671,\n",
       "   2956,\n",
       "   3261,\n",
       "   3267},\n",
       "  784: {321, 1968, 1985, 2644, 3613, 3953, 4017},\n",
       "  785: {108, 811},\n",
       "  786: {792,\n",
       "   1016,\n",
       "   1256,\n",
       "   1348,\n",
       "   1644,\n",
       "   1806,\n",
       "   1932,\n",
       "   1949,\n",
       "   1985,\n",
       "   2253,\n",
       "   2358,\n",
       "   2423,\n",
       "   2871,\n",
       "   2951},\n",
       "  787: {1031, 1179, 1543, 1628, 1891, 1920, 2266, 2740, 3916},\n",
       "  789: {92, 3129},\n",
       "  790: {608,\n",
       "   3743,\n",
       "   3757,\n",
       "   3759,\n",
       "   3778,\n",
       "   3824,\n",
       "   3825,\n",
       "   3828,\n",
       "   3837,\n",
       "   3857,\n",
       "   3867,\n",
       "   3872,\n",
       "   3894,\n",
       "   3923},\n",
       "  791: {166},\n",
       "  796: {626, 2425, 2514, 2689, 3336, 3396, 3515},\n",
       "  797: {167, 1202, 1445, 1578, 2445, 2465, 2536, 2572},\n",
       "  798: {600, 1288, 1289, 1313, 1425, 1441, 1609, 1679, 1932, 2011, 2334, 2558},\n",
       "  799: {97, 223, 619, 1734, 2050, 2154},\n",
       "  803: {52, 328, 348, 1174, 1611, 2712, 2739, 3081},\n",
       "  806: {1906, 2358, 2688, 2775, 2817, 2821, 2848, 2934, 2950, 3009, 3187},\n",
       "  809: {1277, 1593, 1949, 2457, 3681, 3746, 3760},\n",
       "  811: {1902},\n",
       "  812: {24, 150, 152, 167, 346, 700, 1531, 2032, 2344, 2933},\n",
       "  813: {405, 4065, 4151, 4202},\n",
       "  814: {470, 793, 1141, 1567, 1902, 1906, 1907},\n",
       "  815: {535,\n",
       "   964,\n",
       "   1014,\n",
       "   1858,\n",
       "   1968,\n",
       "   2214,\n",
       "   2339,\n",
       "   2590,\n",
       "   2628,\n",
       "   2905,\n",
       "   3607,\n",
       "   3704,\n",
       "   3708,\n",
       "   3709,\n",
       "   3743,\n",
       "   3757,\n",
       "   3759,\n",
       "   3760,\n",
       "   3778,\n",
       "   3779,\n",
       "   3792,\n",
       "   3859,\n",
       "   3900,\n",
       "   3975,\n",
       "   4224},\n",
       "  817: {2607, 3068, 3626, 3726, 3771, 3921},\n",
       "  822: {445, 952, 4143},\n",
       "  824: {718,\n",
       "   1858,\n",
       "   3092,\n",
       "   3261,\n",
       "   3331,\n",
       "   3361,\n",
       "   3391,\n",
       "   3453,\n",
       "   3484,\n",
       "   3496,\n",
       "   3505,\n",
       "   3629,\n",
       "   3712,\n",
       "   3736,\n",
       "   3745,\n",
       "   3761},\n",
       "  825: {266,\n",
       "   516,\n",
       "   521,\n",
       "   546,\n",
       "   547,\n",
       "   580,\n",
       "   748,\n",
       "   989,\n",
       "   2656,\n",
       "   2971,\n",
       "   3166,\n",
       "   3382,\n",
       "   3410,\n",
       "   3448,\n",
       "   3507,\n",
       "   3560,\n",
       "   3652,\n",
       "   3695,\n",
       "   3720,\n",
       "   3837},\n",
       "  826: {23,\n",
       "   75,\n",
       "   246,\n",
       "   494,\n",
       "   511,\n",
       "   644,\n",
       "   788,\n",
       "   831,\n",
       "   947,\n",
       "   962,\n",
       "   979,\n",
       "   998,\n",
       "   1103,\n",
       "   1117,\n",
       "   1203,\n",
       "   1248,\n",
       "   1327,\n",
       "   1658,\n",
       "   1672,\n",
       "   1696,\n",
       "   1708,\n",
       "   1773,\n",
       "   1785,\n",
       "   1809,\n",
       "   1861,\n",
       "   2071,\n",
       "   2154,\n",
       "   2217,\n",
       "   2219,\n",
       "   2222,\n",
       "   2546,\n",
       "   2712,\n",
       "   2744,\n",
       "   2954,\n",
       "   3521,\n",
       "   3592,\n",
       "   3617},\n",
       "  827: {651, 853, 1068, 1410},\n",
       "  828: {17, 3559},\n",
       "  829: {2143, 3629},\n",
       "  832: {822},\n",
       "  836: {1130, 2490},\n",
       "  837: {104, 106, 130, 189, 317, 340, 3442, 3721},\n",
       "  839: {785, 1246},\n",
       "  841: {409, 3159},\n",
       "  842: {490, 2739},\n",
       "  843: {1599},\n",
       "  847: {1685, 1759},\n",
       "  848: {1170, 4101},\n",
       "  851: {1906, 2352, 2360, 2815, 2933, 3059, 3156, 3395, 3584},\n",
       "  852: {710,\n",
       "   1839,\n",
       "   1914,\n",
       "   1917,\n",
       "   1925,\n",
       "   1940,\n",
       "   1971,\n",
       "   2012,\n",
       "   2013,\n",
       "   2032,\n",
       "   2108,\n",
       "   2494,\n",
       "   2603,\n",
       "   3249},\n",
       "  853: {1955, 2112, 2252, 2958, 2995, 3153},\n",
       "  855: {21, 1547},\n",
       "  856: {20, 801, 1245, 1487},\n",
       "  857: {779},\n",
       "  859: {190, 272, 829, 1249, 1421, 1818},\n",
       "  860: {2725, 2737, 3105, 3214},\n",
       "  861: {1385},\n",
       "  863: {2880},\n",
       "  864: {1091,\n",
       "   1194,\n",
       "   1288,\n",
       "   1295,\n",
       "   1398,\n",
       "   1457,\n",
       "   1918,\n",
       "   1985,\n",
       "   2144,\n",
       "   2206,\n",
       "   2263,\n",
       "   2803,\n",
       "   2915,\n",
       "   3100,\n",
       "   3681,\n",
       "   4112},\n",
       "  865: {157, 290, 1237, 1502, 3592, 3775},\n",
       "  866: {1690},\n",
       "  868: {2645, 3065},\n",
       "  869: {407,\n",
       "   549,\n",
       "   1124,\n",
       "   1275,\n",
       "   1369,\n",
       "   1427,\n",
       "   1589,\n",
       "   2921,\n",
       "   3172,\n",
       "   3251,\n",
       "   3363,\n",
       "   3364,\n",
       "   3379,\n",
       "   3712,\n",
       "   3758,\n",
       "   3794,\n",
       "   3869,\n",
       "   3942,\n",
       "   3955,\n",
       "   3958,\n",
       "   4068,\n",
       "   4085},\n",
       "  870: {724, 1009, 3016, 3365, 3397, 3518, 3672, 3699, 3749, 3835, 3862, 3903},\n",
       "  871: {481, 2094, 3192},\n",
       "  872: {3783, 3842},\n",
       "  876: {478, 1397, 4236},\n",
       "  878: {405, 1307, 1454, 1643, 1674, 2094},\n",
       "  882: {1047, 1108, 2358},\n",
       "  883: {436, 1133, 1254, 1410, 1822, 2159, 2480, 2815, 3224},\n",
       "  885: {248, 700, 1208, 3036},\n",
       "  887: {709, 2983, 3797, 3819, 3981},\n",
       "  888: {855, 1543, 1879, 1920, 2357, 2420, 2976, 3291, 3444},\n",
       "  889: {349, 898, 1156, 1211, 2010, 2239, 2247, 2290, 2297, 2689, 3144, 3171},\n",
       "  891: {3110, 3423, 3494},\n",
       "  894: {2983, 4031, 4076},\n",
       "  895: {702, 1501, 2240, 3336, 3781},\n",
       "  896: {177,\n",
       "   352,\n",
       "   551,\n",
       "   1015,\n",
       "   1132,\n",
       "   2025,\n",
       "   2047,\n",
       "   2156,\n",
       "   2160,\n",
       "   2202,\n",
       "   2264,\n",
       "   2302,\n",
       "   2413,\n",
       "   2558,\n",
       "   2688,\n",
       "   2721,\n",
       "   2865,\n",
       "   2890,\n",
       "   2934,\n",
       "   2937,\n",
       "   3064,\n",
       "   3169,\n",
       "   3273,\n",
       "   3395,\n",
       "   3499,\n",
       "   3569},\n",
       "  897: {652, 683, 895, 1827, 1921, 1985, 2062, 2240, 2787, 2950, 3171},\n",
       "  898: {1090,\n",
       "   1902,\n",
       "   1906,\n",
       "   1992,\n",
       "   2112,\n",
       "   2475,\n",
       "   2558,\n",
       "   2640,\n",
       "   2834,\n",
       "   2907,\n",
       "   2990,\n",
       "   3008,\n",
       "   3074,\n",
       "   3158,\n",
       "   3448,\n",
       "   3476,\n",
       "   4081},\n",
       "  900: {4202, 4210},\n",
       "  901: {1214, 1906, 2089, 2230, 2694, 2805, 2821, 3185, 3789},\n",
       "  902: {3319},\n",
       "  903: {368, 1110, 1208},\n",
       "  905: {39, 3190},\n",
       "  907: {1894, 1932, 2548, 2688, 2949, 3060, 3172, 3178, 3325},\n",
       "  909: {286,\n",
       "   524,\n",
       "   1003,\n",
       "   1906,\n",
       "   2160,\n",
       "   2549,\n",
       "   2583,\n",
       "   2688,\n",
       "   2888,\n",
       "   2950,\n",
       "   3172,\n",
       "   3175,\n",
       "   3179,\n",
       "   3325},\n",
       "  910: {360,\n",
       "   363,\n",
       "   524,\n",
       "   541,\n",
       "   789,\n",
       "   1091,\n",
       "   1133,\n",
       "   1411,\n",
       "   1543,\n",
       "   1565,\n",
       "   1800,\n",
       "   1821,\n",
       "   1920,\n",
       "   2549,\n",
       "   2688,\n",
       "   3171},\n",
       "  912: {65, 2886},\n",
       "  913: {1906, 1907, 2662, 2951, 3178},\n",
       "  914: {759,\n",
       "   1031,\n",
       "   1039,\n",
       "   1204,\n",
       "   1207,\n",
       "   1314,\n",
       "   1788,\n",
       "   1911,\n",
       "   2049,\n",
       "   2172,\n",
       "   2565,\n",
       "   3024,\n",
       "   3037,\n",
       "   3049,\n",
       "   3145,\n",
       "   3154,\n",
       "   3638},\n",
       "  915: {2981, 3295, 3304, 3658, 3908},\n",
       "  916: {3298, 3391, 3952, 3971},\n",
       "  917: {987, 1071, 1073, 1971, 2012, 2013, 2287, 2915, 3369, 4018},\n",
       "  918: {458, 640, 790},\n",
       "  919: {429, 1341, 1740, 2216, 2969, 2983, 3094, 3191, 4151},\n",
       "  924: {973},\n",
       "  925: {229, 567, 1528, 1877, 2327},\n",
       "  927: {1752, 2459, 2698, 4104, 4167, 4228},\n",
       "  928: {720, 735, 1031, 1384, 1600, 2097, 2358, 2640, 4186},\n",
       "  929: {23, 361, 483, 568},\n",
       "  930: {3448, 3562, 4118},\n",
       "  931: {281, 2685, 3149, 3636, 3853},\n",
       "  932: {1495, 2159, 2254, 2355, 3125},\n",
       "  933: {788, 1565},\n",
       "  934: {1683, 3139, 3160, 3242},\n",
       "  935: {1014, 1015},\n",
       "  936: {46, 2383, 4165},\n",
       "  937: {1238},\n",
       "  939: {816, 1016, 1454, 1609, 1906, 2302, 2950},\n",
       "  940: {1137, 2572, 2801, 2968, 2973, 3079, 3146, 3580, 3611},\n",
       "  941: {2885},\n",
       "  942: {251,\n",
       "   723,\n",
       "   1140,\n",
       "   1209,\n",
       "   1282,\n",
       "   1381,\n",
       "   1394,\n",
       "   1780,\n",
       "   1797,\n",
       "   1802,\n",
       "   1878,\n",
       "   1911,\n",
       "   2022},\n",
       "  944: {822, 1426, 2220},\n",
       "  945: {2688, 3040, 3247, 3647},\n",
       "  948: {1555, 2293, 2671, 2717, 2996},\n",
       "  950: {1042, 1857, 2069},\n",
       "  951: {1452},\n",
       "  952: {2913, 3600, 3681, 3699},\n",
       "  953: {1205, 1829},\n",
       "  954: {4050},\n",
       "  956: {33, 1084, 2403, 2481},\n",
       "  958: {1017},\n",
       "  959: {168, 306, 328, 665, 972, 3568},\n",
       "  960: {1017},\n",
       "  961: {1569, 1998, 2482},\n",
       "  962: {1745, 3181},\n",
       "  964: {1208, 1635, 1763, 2377, 2646, 2679, 3067, 3192, 3223},\n",
       "  966: {192, 775, 955},\n",
       "  967: {811, 2418, 2950, 3221, 3473, 3680, 4001},\n",
       "  968: {50, 3771},\n",
       "  971: {43, 121, 1297},\n",
       "  972: {2219, 3108, 3291, 3341, 3833},\n",
       "  974: {83, 1157},\n",
       "  975: {16, 108, 131, 242, 255, 393, 780, 1078, 1444, 2668},\n",
       "  976: {3911},\n",
       "  977: {363,\n",
       "   573,\n",
       "   769,\n",
       "   870,\n",
       "   924,\n",
       "   925,\n",
       "   987,\n",
       "   1183,\n",
       "   1236,\n",
       "   1302,\n",
       "   1580,\n",
       "   1622,\n",
       "   1633,\n",
       "   1769,\n",
       "   1794,\n",
       "   1906,\n",
       "   1924,\n",
       "   2036,\n",
       "   2054,\n",
       "   2152,\n",
       "   2171,\n",
       "   2249,\n",
       "   2417,\n",
       "   2671},\n",
       "  979: {652, 2688, 3175, 3687},\n",
       "  980: {169,\n",
       "   2646,\n",
       "   3181,\n",
       "   3519,\n",
       "   3522,\n",
       "   3638,\n",
       "   3908,\n",
       "   4007,\n",
       "   4010,\n",
       "   4101,\n",
       "   4111,\n",
       "   4113,\n",
       "   4148,\n",
       "   4181},\n",
       "  985: {589, 1383, 1700, 1701, 1891, 2358, 2594, 2666, 3158},\n",
       "  986: {991,\n",
       "   2307,\n",
       "   2688,\n",
       "   3120,\n",
       "   3171,\n",
       "   3499,\n",
       "   3501,\n",
       "   3526,\n",
       "   3589,\n",
       "   3868,\n",
       "   3878,\n",
       "   3879,\n",
       "   3904,\n",
       "   3928,\n",
       "   3980,\n",
       "   4121,\n",
       "   4143},\n",
       "  987: {1010, 1922, 1936, 2249, 2392, 3007, 3392, 3630},\n",
       "  988: {1037, 1059, 1614, 1622, 2169, 2255, 2312, 2352, 2420, 2888, 3106},\n",
       "  989: {344,\n",
       "   761,\n",
       "   1010,\n",
       "   1205,\n",
       "   1741,\n",
       "   1902,\n",
       "   1906,\n",
       "   2251,\n",
       "   2549,\n",
       "   2636,\n",
       "   2638,\n",
       "   2640,\n",
       "   2688,\n",
       "   2700,\n",
       "   2950,\n",
       "   3172,\n",
       "   3179,\n",
       "   3310},\n",
       "  990: {971, 1315, 2583, 2730, 2847, 3098, 3498, 3806},\n",
       "  991: {487, 755},\n",
       "  993: {2370, 2688, 3081, 3316},\n",
       "  995: {1529, 2018},\n",
       "  998: {290, 974, 1939, 2131, 2267, 2396, 3126},\n",
       "  1001: {775, 1560, 2707, 2983, 3287, 3460, 3788},\n",
       "  1002: {2731, 2853, 2863, 2872, 2892, 2916, 2935, 2945, 2971, 3067},\n",
       "  1003: {2243, 2751, 3318},\n",
       "  1004: {2492, 2906, 3186, 4152, 4165, 4167, 4199},\n",
       "  1005: {1133, 1146, 1264, 1380, 1481, 2144, 2324, 2358},\n",
       "  1007: {464},\n",
       "  1008: {516, 521, 547, 576, 580, 2806, 3726},\n",
       "  1009: {3349, 3397, 3501, 3903, 3928},\n",
       "  1010: {4, 233, 1877, 2124, 2191, 2327, 2582, 3351, 3434, 3592},\n",
       "  1011: {4174, 4181},\n",
       "  1013: {84,\n",
       "   118,\n",
       "   219,\n",
       "   249,\n",
       "   375,\n",
       "   391,\n",
       "   606,\n",
       "   620,\n",
       "   660,\n",
       "   823,\n",
       "   830,\n",
       "   890,\n",
       "   1532,\n",
       "   2397,\n",
       "   2490,\n",
       "   2505,\n",
       "   2582,\n",
       "   3147},\n",
       "  1015: {1568},\n",
       "  1017: {4032, 4075, 4176, 4181, 4232},\n",
       "  1018: {2254, 2549, 4202},\n",
       "  1021: {360,\n",
       "   771,\n",
       "   1015,\n",
       "   1046,\n",
       "   1047,\n",
       "   1182,\n",
       "   1345,\n",
       "   1699,\n",
       "   2040,\n",
       "   2062,\n",
       "   2085,\n",
       "   2170,\n",
       "   2349,\n",
       "   2392,\n",
       "   2583,\n",
       "   2693,\n",
       "   2750,\n",
       "   2827,\n",
       "   2976,\n",
       "   3317},\n",
       "  1022: {85, 109, 409, 839, 2864},\n",
       "  1023: {781, 929, 3955},\n",
       "  1025: {128, 652, 1435, 2228, 2656},\n",
       "  1026: {752, 987, 1643},\n",
       "  1027: {1334, 1929, 1930, 2140, 2549, 2752},\n",
       "  1028: {3234},\n",
       "  1029: {4, 267, 926, 1377},\n",
       "  1030: {2423, 2445, 2928, 2983},\n",
       "  1031: {2176, 2214, 2273, 2494, 2559},\n",
       "  1032: {3397, 3427, 3477, 3747, 3756, 3836},\n",
       "  1033: {1338},\n",
       "  1034: {937,\n",
       "   969,\n",
       "   1016,\n",
       "   1051,\n",
       "   1055,\n",
       "   1133,\n",
       "   1229,\n",
       "   1242,\n",
       "   1401,\n",
       "   1411,\n",
       "   1514,\n",
       "   1579,\n",
       "   1673,\n",
       "   1684,\n",
       "   1906,\n",
       "   1920,\n",
       "   2044,\n",
       "   2277,\n",
       "   2287,\n",
       "   2455,\n",
       "   2516,\n",
       "   2603,\n",
       "   2645,\n",
       "   2693,\n",
       "   2755,\n",
       "   2787,\n",
       "   2816,\n",
       "   2940,\n",
       "   2955,\n",
       "   3062,\n",
       "   3159,\n",
       "   3171,\n",
       "   3272,\n",
       "   3306},\n",
       "  1037: {4, 72, 319, 358, 1652, 2525},\n",
       "  1039: {379,\n",
       "   674,\n",
       "   796,\n",
       "   991,\n",
       "   1216,\n",
       "   1222,\n",
       "   1287,\n",
       "   1456,\n",
       "   1479,\n",
       "   1700,\n",
       "   1701,\n",
       "   1801,\n",
       "   1959,\n",
       "   1960,\n",
       "   2203,\n",
       "   2221,\n",
       "   2464,\n",
       "   2495,\n",
       "   2658,\n",
       "   2702,\n",
       "   2797,\n",
       "   2813,\n",
       "   2871,\n",
       "   2940,\n",
       "   3065,\n",
       "   3124,\n",
       "   3273,\n",
       "   3946,\n",
       "   3983,\n",
       "   4015},\n",
       "  1040: {286,\n",
       "   362,\n",
       "   1012,\n",
       "   1085,\n",
       "   1242,\n",
       "   1559,\n",
       "   1603,\n",
       "   1957,\n",
       "   2602,\n",
       "   2769,\n",
       "   3249,\n",
       "   3397,\n",
       "   3588,\n",
       "   3687,\n",
       "   3710,\n",
       "   4013,\n",
       "   4032,\n",
       "   4053,\n",
       "   4078,\n",
       "   4097,\n",
       "   4113,\n",
       "   4119,\n",
       "   4126,\n",
       "   4141,\n",
       "   4160,\n",
       "   4187},\n",
       "  1041: {275, 805, 3080, 3413, 3452, 3462},\n",
       "  1043: {995, 2583, 2934},\n",
       "  1044: {260, 352, 696, 781, 1013, 2021, 2062, 2620},\n",
       "  1045: {129,\n",
       "   142,\n",
       "   146,\n",
       "   590,\n",
       "   607,\n",
       "   614,\n",
       "   638,\n",
       "   800,\n",
       "   818,\n",
       "   957,\n",
       "   1118,\n",
       "   1197,\n",
       "   1283,\n",
       "   1404,\n",
       "   1602,\n",
       "   1844,\n",
       "   2023,\n",
       "   2708,\n",
       "   3101,\n",
       "   3431,\n",
       "   3443,\n",
       "   3683,\n",
       "   3721},\n",
       "  1046: {736, 2858, 3479, 3897, 4054},\n",
       "  1047: {294,\n",
       "   534,\n",
       "   802,\n",
       "   1418,\n",
       "   1746,\n",
       "   2029,\n",
       "   2035,\n",
       "   2381,\n",
       "   2382,\n",
       "   2601,\n",
       "   2739,\n",
       "   2855,\n",
       "   3238},\n",
       "  1048: {108,\n",
       "   533,\n",
       "   718,\n",
       "   748,\n",
       "   1025,\n",
       "   1329,\n",
       "   2178,\n",
       "   2443,\n",
       "   2787,\n",
       "   2861,\n",
       "   3261,\n",
       "   3364,\n",
       "   3439,\n",
       "   3985},\n",
       "  1049: {2277, 2445, 2516, 2640, 3128, 3206, 3265},\n",
       "  1050: {2064},\n",
       "  1052: {2195, 2319, 2391, 2392, 2476, 2550, 2584},\n",
       "  1053: {99,\n",
       "   101,\n",
       "   302,\n",
       "   387,\n",
       "   439,\n",
       "   443,\n",
       "   555,\n",
       "   611,\n",
       "   700,\n",
       "   802,\n",
       "   813,\n",
       "   1894,\n",
       "   2950,\n",
       "   3396,\n",
       "   3647,\n",
       "   3890,\n",
       "   3904,\n",
       "   4031,\n",
       "   4105},\n",
       "  1055: {2722, 2809},\n",
       "  1056: {585, 1318, 1400, 1435, 1480, 1784, 1811, 2959, 4151},\n",
       "  1057: {1977,\n",
       "   2361,\n",
       "   2416,\n",
       "   2476,\n",
       "   2515,\n",
       "   2553,\n",
       "   2627,\n",
       "   2743,\n",
       "   2787,\n",
       "   2790,\n",
       "   2795,\n",
       "   2799,\n",
       "   2805,\n",
       "   2833,\n",
       "   2871,\n",
       "   2878,\n",
       "   2925,\n",
       "   2933,\n",
       "   2956,\n",
       "   2990,\n",
       "   3005,\n",
       "   3034,\n",
       "   3065,\n",
       "   3129,\n",
       "   3153,\n",
       "   3159,\n",
       "   3186,\n",
       "   3205,\n",
       "   3277,\n",
       "   3285,\n",
       "   3288,\n",
       "   3298,\n",
       "   3307,\n",
       "   3311,\n",
       "   3318,\n",
       "   3346,\n",
       "   3382,\n",
       "   3389,\n",
       "   3471,\n",
       "   3561,\n",
       "   3601,\n",
       "   3625,\n",
       "   4118},\n",
       "  1060: {671, 1017, 1077, 1081, 1151, 2365, 2752, 3252},\n",
       "  1062: {4069},\n",
       "  1063: {2418},\n",
       "  1065: {1058, 1059, 1070, 1104, 2012, 2183, 2393, 2420, 3171},\n",
       "  1066: {2688, 3581, 3854, 3953, 4085, 4169},\n",
       "  1067: {1531, 2410, 3430},\n",
       "  1069: {227},\n",
       "  1070: {1152, 1395},\n",
       "  1071: {705, 3828, 3872, 3909, 3980, 4007, 4010},\n",
       "  1073: {424,\n",
       "   699,\n",
       "   1055,\n",
       "   1133,\n",
       "   1236,\n",
       "   1616,\n",
       "   1617,\n",
       "   1997,\n",
       "   2149,\n",
       "   2475,\n",
       "   2540,\n",
       "   2620,\n",
       "   3171,\n",
       "   3237,\n",
       "   3326},\n",
       "  1074: {1017, 2182, 2786, 2922, 3013, 3167, 3304, 3463, 3896, 3920},\n",
       "  1078: {1894,\n",
       "   1896,\n",
       "   1949,\n",
       "   2158,\n",
       "   2161,\n",
       "   2433,\n",
       "   2814,\n",
       "   2826,\n",
       "   2835,\n",
       "   3014,\n",
       "   3291,\n",
       "   3953},\n",
       "  1079: {900, 2002, 2064, 2522, 2541},\n",
       "  1080: {1016,\n",
       "   1377,\n",
       "   1906,\n",
       "   2380,\n",
       "   2646,\n",
       "   2748,\n",
       "   3412,\n",
       "   3448,\n",
       "   3450,\n",
       "   3464,\n",
       "   3487,\n",
       "   3535,\n",
       "   3558,\n",
       "   3657,\n",
       "   3828,\n",
       "   3965,\n",
       "   3986,\n",
       "   4040,\n",
       "   4113,\n",
       "   4161,\n",
       "   4202},\n",
       "  1081: {73, 182, 348, 2465, 3243, 3512},\n",
       "  1083: {2006, 2056, 2277, 2583, 2587, 3097},\n",
       "  1084: {1558, 1936, 2549, 2815, 2820, 3171, 3172, 3175},\n",
       "  1086: {268, 470, 789, 895, 1010, 1051, 1182, 1573, 1643, 1951, 2108},\n",
       "  1087: {405, 974, 2172},\n",
       "  1088: {1055, 1133, 1146, 2054, 2287, 2361, 2691, 3833, 3867},\n",
       "  1089: {3181},\n",
       "  1090: {1188, 2877, 3342, 3676, 4070},\n",
       "  1091: {5, 99, 165, 226, 320, 579, 840, 868, 1787, 2035},\n",
       "  1093: {1162, 3880, 3983},\n",
       "  1094: {652,\n",
       "   771,\n",
       "   819,\n",
       "   854,\n",
       "   1097,\n",
       "   1143,\n",
       "   1343,\n",
       "   1439,\n",
       "   1547,\n",
       "   1628,\n",
       "   2183,\n",
       "   2184,\n",
       "   2202},\n",
       "  1096: {3642, 3831, 3979},\n",
       "  1098: {194, 223, 389, 466, 998, 1708, 1748, 1890, 2801, 3079, 3146, 4209},\n",
       "  1100: {1303, 2583, 3420},\n",
       "  1101: {652, 1238, 1740, 1826, 2688, 2785},\n",
       "  1102: {652, 820, 1622, 1795, 2072, 2365, 2377, 3121, 3341},\n",
       "  1103: {431, 873, 1055, 1133, 1411, 1821, 2043, 2197, 2287, 2602, 2915, 3252},\n",
       "  1104: {1525, 1534, 1590, 1606, 1622, 2038, 2312, 2897, 3014},\n",
       "  1106: {138, 610, 3226},\n",
       "  1109: {570, 1899, 1908, 2200, 2508, 2688, 3277, 3495, 3780},\n",
       "  1110: {87, 351},\n",
       "  1111: {1017,\n",
       "   1068,\n",
       "   1922,\n",
       "   2160,\n",
       "   2262,\n",
       "   2353,\n",
       "   2393,\n",
       "   2688,\n",
       "   2814,\n",
       "   2822,\n",
       "   2888,\n",
       "   3009,\n",
       "   3272},\n",
       "  1117: {113, 973, 2247, 2623},\n",
       "  1118: {699,\n",
       "   1055,\n",
       "   1133,\n",
       "   1379,\n",
       "   1411,\n",
       "   1691,\n",
       "   1700,\n",
       "   1821,\n",
       "   2287,\n",
       "   2411,\n",
       "   2445,\n",
       "   2558,\n",
       "   2729,\n",
       "   2897,\n",
       "   2915},\n",
       "  1119: {28,\n",
       "   630,\n",
       "   640,\n",
       "   739,\n",
       "   842,\n",
       "   987,\n",
       "   1012,\n",
       "   1161,\n",
       "   1236,\n",
       "   1368,\n",
       "   1618,\n",
       "   2189,\n",
       "   2211,\n",
       "   2258,\n",
       "   2685,\n",
       "   2744},\n",
       "  1120: {1555,\n",
       "   1976,\n",
       "   2270,\n",
       "   2476,\n",
       "   2494,\n",
       "   2740,\n",
       "   3321,\n",
       "   3338,\n",
       "   3472,\n",
       "   3583,\n",
       "   3650,\n",
       "   3697,\n",
       "   3739,\n",
       "   3776},\n",
       "  1125: {836, 1782, 2411, 2729, 3005, 3114},\n",
       "  1126: {2194, 2298},\n",
       "  1127: {2797, 2816},\n",
       "  1130: {703, 3397, 3706, 3736},\n",
       "  1131: {2377, 3264},\n",
       "  1133: {4113},\n",
       "  1134: {1376, 1809},\n",
       "  1135: {802, 1189},\n",
       "  1136: {1604, 1906, 2693, 2706, 2900, 2905, 2950, 3185, 3187},\n",
       "  1138: {518,\n",
       "   596,\n",
       "   639,\n",
       "   675,\n",
       "   684,\n",
       "   741,\n",
       "   746,\n",
       "   754,\n",
       "   770,\n",
       "   834,\n",
       "   875,\n",
       "   910,\n",
       "   932,\n",
       "   936,\n",
       "   969,\n",
       "   980,\n",
       "   1095,\n",
       "   1120,\n",
       "   1330,\n",
       "   1340,\n",
       "   1367,\n",
       "   1379,\n",
       "   1412,\n",
       "   1660,\n",
       "   1689,\n",
       "   1736,\n",
       "   1737,\n",
       "   1808,\n",
       "   1810,\n",
       "   1879,\n",
       "   1906,\n",
       "   1927,\n",
       "   2003,\n",
       "   2089,\n",
       "   2119,\n",
       "   2251,\n",
       "   2264,\n",
       "   2330,\n",
       "   2413,\n",
       "   2624,\n",
       "   2629,\n",
       "   2640,\n",
       "   2671,\n",
       "   2678,\n",
       "   2688,\n",
       "   2703,\n",
       "   2716,\n",
       "   2720,\n",
       "   2768,\n",
       "   2802,\n",
       "   2815,\n",
       "   2821,\n",
       "   2830,\n",
       "   2840,\n",
       "   2881,\n",
       "   2937,\n",
       "   2950,\n",
       "   2963,\n",
       "   3025,\n",
       "   3027,\n",
       "   3058,\n",
       "   3065,\n",
       "   3069,\n",
       "   3077,\n",
       "   3092,\n",
       "   3100,\n",
       "   3102,\n",
       "   3104,\n",
       "   3105,\n",
       "   3118,\n",
       "   3120,\n",
       "   3133,\n",
       "   3148,\n",
       "   3150,\n",
       "   3171,\n",
       "   3199,\n",
       "   3203,\n",
       "   3205,\n",
       "   3213,\n",
       "   3220,\n",
       "   3227,\n",
       "   3260,\n",
       "   3263,\n",
       "   3266,\n",
       "   3279,\n",
       "   3293,\n",
       "   3315,\n",
       "   3364,\n",
       "   3418,\n",
       "   3453,\n",
       "   3459,\n",
       "   3505,\n",
       "   3552},\n",
       "  1139: {1280, 1296, 1358, 1435, 1452, 1479, 1677, 2653, 2760, 2763},\n",
       "  1141: {1171},\n",
       "  1142: {3187, 3393, 4113, 4121},\n",
       "  1143: {3040, 3160, 3355, 3443, 3578, 3595, 3644, 3695, 3769},\n",
       "  1144: {1012, 1016, 1577, 1849, 1934, 3187},\n",
       "  1145: {674, 790, 1133, 1584, 1906},\n",
       "  1146: {38, 85, 86, 204, 754, 2415, 2875},\n",
       "  1149: {1303, 1811, 1902, 3284, 4223},\n",
       "  1150: {227, 391, 481, 1754, 1819},\n",
       "  1154: {359, 2205, 3247},\n",
       "  1155: {637, 3185, 3541},\n",
       "  1156: {1282, 1686, 2174, 2510, 2984, 3109},\n",
       "  1158: {2790, 3168, 3271, 3321, 3337, 3360},\n",
       "  1159: {652,\n",
       "   1242,\n",
       "   1345,\n",
       "   1514,\n",
       "   1574,\n",
       "   1581,\n",
       "   1843,\n",
       "   2151,\n",
       "   2154,\n",
       "   2303,\n",
       "   2358,\n",
       "   2418,\n",
       "   2630,\n",
       "   2640,\n",
       "   2787,\n",
       "   2945,\n",
       "   2971,\n",
       "   3098,\n",
       "   3171,\n",
       "   3359,\n",
       "   3382,\n",
       "   3393,\n",
       "   3397,\n",
       "   3491,\n",
       "   4019,\n",
       "   4143,\n",
       "   4186},\n",
       "  1160: {3189},\n",
       "  1161: {392, 423, 494, 627, 841, 998, 1560, 1708, 2348, 3192, 3228},\n",
       "  1162: {1449, 1894, 2116, 2705, 3129, 3175, 3178, 3315},\n",
       "  1163: {572,\n",
       "   1292,\n",
       "   1460,\n",
       "   1902,\n",
       "   2358,\n",
       "   2549,\n",
       "   2583,\n",
       "   2962,\n",
       "   3048,\n",
       "   3119,\n",
       "   3171,\n",
       "   3175,\n",
       "   3322},\n",
       "  1164: {2672},\n",
       "  1165: {481,\n",
       "   488,\n",
       "   633,\n",
       "   755,\n",
       "   847,\n",
       "   999,\n",
       "   1582,\n",
       "   1728,\n",
       "   2419,\n",
       "   2554,\n",
       "   2642,\n",
       "   2680,\n",
       "   2698,\n",
       "   2761,\n",
       "   2779,\n",
       "   2801,\n",
       "   2857,\n",
       "   2863,\n",
       "   2885,\n",
       "   2886,\n",
       "   2900,\n",
       "   2920,\n",
       "   2959,\n",
       "   2967,\n",
       "   2971,\n",
       "   3014},\n",
       "  1166: {498, 582},\n",
       "  1167: {1886, 2011, 2146},\n",
       "  1169: {1047, 1452, 2358, 2751, 3158, 3603},\n",
       "  1171: {498, 800, 2969},\n",
       "  1172: {238,\n",
       "   434,\n",
       "   766,\n",
       "   804,\n",
       "   1139,\n",
       "   1300,\n",
       "   1369,\n",
       "   1546,\n",
       "   1788,\n",
       "   2051,\n",
       "   2172,\n",
       "   2298,\n",
       "   2585,\n",
       "   2772,\n",
       "   2981,\n",
       "   3670},\n",
       "  1174: {812, 1132, 1290, 1370, 3807},\n",
       "  1175: {136, 660, 669, 811, 907, 3192, 3353},\n",
       "  1177: {356, 796, 1356, 1410, 1415, 1464, 1479, 1776, 2032},\n",
       "  1178: {17, 105, 215, 420},\n",
       "  1179: {1159, 1619, 3353, 3468},\n",
       "  1180: {1528, 1877, 2327},\n",
       "  1181: {2387},\n",
       "  1182: {793, 2136, 3212, 3511, 3543, 3546, 3564, 3680},\n",
       "  1183: {2684},\n",
       "  1184: {58, 506, 1823, 4162},\n",
       "  1187: {1559, 1637, 2069, 2136, 2200, 2847, 3136, 3175},\n",
       "  1188: {33,\n",
       "   80,\n",
       "   104,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   124,\n",
       "   179,\n",
       "   187,\n",
       "   224,\n",
       "   225,\n",
       "   231,\n",
       "   234,\n",
       "   350,\n",
       "   376,\n",
       "   463,\n",
       "   527,\n",
       "   530,\n",
       "   533,\n",
       "   734,\n",
       "   739,\n",
       "   903,\n",
       "   909,\n",
       "   1114,\n",
       "   1131,\n",
       "   1160,\n",
       "   1161,\n",
       "   1192,\n",
       "   1241,\n",
       "   1394,\n",
       "   1473,\n",
       "   1941,\n",
       "   2071,\n",
       "   2222,\n",
       "   3072,\n",
       "   3307},\n",
       "  1189: {785, 989},\n",
       "  1192: {350, 1906, 2411, 2678, 2787, 2933, 3479},\n",
       "  1194: {1496},\n",
       "  1195: {26, 402, 660, 839, 848, 2499, 3045, 3430},\n",
       "  1197: {1733, 2151, 2693},\n",
       "  1198: {2281, 2705, 3048, 3156},\n",
       "  1199: {2671, 2694, 3171, 3537, 3702},\n",
       "  1200: {855,\n",
       "   1275,\n",
       "   1289,\n",
       "   1474,\n",
       "   1514,\n",
       "   1516,\n",
       "   2079,\n",
       "   2120,\n",
       "   2159,\n",
       "   2179,\n",
       "   2206,\n",
       "   2323,\n",
       "   2345,\n",
       "   2364,\n",
       "   2370,\n",
       "   2408,\n",
       "   2665,\n",
       "   2816},\n",
       "  1201: {855, 1182, 1661, 1906, 2365, 2951, 3171, 3267},\n",
       "  1202: {1274, 1870, 2165, 2243, 2933},\n",
       "  1206: {3918, 4113, 4143},\n",
       "  1207: {3, 34, 641, 839, 2317, 3032, 3041, 3244, 3353, 3817},\n",
       "  1209: {640, 1040, 1041, 1222, 2359, 3010, 3270},\n",
       "  1210: {2589, 2842, 3023},\n",
       "  1211: {1078},\n",
       "  1213: {3397, 3488, 3693, 3747, 3946, 3971, 3991},\n",
       "  1214: {897},\n",
       "  1215: {302, 1988, 3000},\n",
       "  1217: {2740,\n",
       "   3336,\n",
       "   3397,\n",
       "   3873,\n",
       "   4019,\n",
       "   4026,\n",
       "   4027,\n",
       "   4038,\n",
       "   4051,\n",
       "   4093,\n",
       "   4104,\n",
       "   4105,\n",
       "   4127,\n",
       "   4134,\n",
       "   4198,\n",
       "   4210,\n",
       "   4221,\n",
       "   4225},\n",
       "  1219: {452, 1980, 2497, 2971, 3562, 3663},\n",
       "  1220: {1066,\n",
       "   1156,\n",
       "   1199,\n",
       "   1268,\n",
       "   1298,\n",
       "   1526,\n",
       "   1557,\n",
       "   1570,\n",
       "   1572,\n",
       "   1615,\n",
       "   1715,\n",
       "   1880,\n",
       "   1959,\n",
       "   1974,\n",
       "   1986,\n",
       "   2059,\n",
       "   2108,\n",
       "   2200,\n",
       "   2238,\n",
       "   2276,\n",
       "   2357,\n",
       "   2412,\n",
       "   2426,\n",
       "   2477,\n",
       "   2496,\n",
       "   2568,\n",
       "   2661,\n",
       "   2727,\n",
       "   2728,\n",
       "   2826,\n",
       "   2834,\n",
       "   2871,\n",
       "   2878,\n",
       "   2896,\n",
       "   2976,\n",
       "   3029,\n",
       "   3030,\n",
       "   3169,\n",
       "   3249,\n",
       "   3267,\n",
       "   3282,\n",
       "   3290,\n",
       "   3291,\n",
       "   3341,\n",
       "   3375,\n",
       "   3381,\n",
       "   3386,\n",
       "   3394,\n",
       "   3400,\n",
       "   3469,\n",
       "   3479,\n",
       "   3490,\n",
       "   3495,\n",
       "   3498,\n",
       "   3503,\n",
       "   3509,\n",
       "   3546,\n",
       "   3575,\n",
       "   3676,\n",
       "   3815,\n",
       "   3827,\n",
       "   3868,\n",
       "   3966,\n",
       "   4056,\n",
       "   4058,\n",
       "   4070,\n",
       "   4076,\n",
       "   4105,\n",
       "   4131,\n",
       "   4143,\n",
       "   4176,\n",
       "   4202},\n",
       "  1225: {74, 982},\n",
       "  1226: {3027},\n",
       "  1227: {1238},\n",
       "  1228: {1988, 2033},\n",
       "  1229: {260,\n",
       "   337,\n",
       "   385,\n",
       "   435,\n",
       "   470,\n",
       "   921,\n",
       "   1021,\n",
       "   1053,\n",
       "   1081,\n",
       "   1242,\n",
       "   1361,\n",
       "   1384,\n",
       "   1567,\n",
       "   1572,\n",
       "   1659,\n",
       "   1684,\n",
       "   1688,\n",
       "   1715,\n",
       "   1869,\n",
       "   1940,\n",
       "   1986,\n",
       "   2005,\n",
       "   2075,\n",
       "   2108,\n",
       "   2167,\n",
       "   2202,\n",
       "   2231,\n",
       "   2245,\n",
       "   2250,\n",
       "   2271,\n",
       "   2314,\n",
       "   2364,\n",
       "   2376,\n",
       "   2400,\n",
       "   2404,\n",
       "   2430,\n",
       "   2438,\n",
       "   2445,\n",
       "   2452,\n",
       "   2514,\n",
       "   2515,\n",
       "   2599,\n",
       "   2606,\n",
       "   2614,\n",
       "   2640,\n",
       "   2657,\n",
       "   2670,\n",
       "   2680,\n",
       "   2688,\n",
       "   2713,\n",
       "   2727,\n",
       "   2821,\n",
       "   2833,\n",
       "   2878,\n",
       "   2919,\n",
       "   2923,\n",
       "   2926,\n",
       "   2944,\n",
       "   2972,\n",
       "   3029,\n",
       "   3115,\n",
       "   3125,\n",
       "   3152,\n",
       "   3171,\n",
       "   3181,\n",
       "   3228,\n",
       "   3253,\n",
       "   3346,\n",
       "   3393,\n",
       "   3418,\n",
       "   3423,\n",
       "   3429,\n",
       "   3432,\n",
       "   3441,\n",
       "   3450,\n",
       "   3465,\n",
       "   3473,\n",
       "   3490,\n",
       "   3497,\n",
       "   3508,\n",
       "   3514,\n",
       "   3525,\n",
       "   3531,\n",
       "   3545,\n",
       "   3572,\n",
       "   3623,\n",
       "   3627,\n",
       "   3631,\n",
       "   3654,\n",
       "   3676,\n",
       "   3677,\n",
       "   3684,\n",
       "   3693,\n",
       "   3702,\n",
       "   3716,\n",
       "   3719,\n",
       "   3749,\n",
       "   3755,\n",
       "   3764,\n",
       "   3789,\n",
       "   3790,\n",
       "   3791,\n",
       "   3820,\n",
       "   3842,\n",
       "   3852,\n",
       "   3890,\n",
       "   3904,\n",
       "   3970,\n",
       "   3978,\n",
       "   3986,\n",
       "   4024,\n",
       "   4072,\n",
       "   4113},\n",
       "  1230: {407,\n",
       "   812,\n",
       "   836,\n",
       "   921,\n",
       "   1876,\n",
       "   1948,\n",
       "   2469,\n",
       "   3061,\n",
       "   3315,\n",
       "   3450,\n",
       "   3536,\n",
       "   3581,\n",
       "   3587,\n",
       "   3600,\n",
       "   3704,\n",
       "   3872,\n",
       "   3904,\n",
       "   3955,\n",
       "   3985,\n",
       "   3989,\n",
       "   4075,\n",
       "   4085,\n",
       "   4114,\n",
       "   4200},\n",
       "  1231: {806, 1098, 1627},\n",
       "  1232: {559, 1133, 1335, 1336, 2159, 2315, 3171, 4156},\n",
       "  1233: {1164, 2287, 3051},\n",
       "  1235: {1622, 1823, 2452, 2976, 4033},\n",
       "  1237: {283, 651, 1052, 1442, 1558, 1661, 2249, 2693, 2861, 3178, 3311},\n",
       "  1239: {1821, 1900, 1949, 2603, 3208, 3249, 3261, 3388},\n",
       "  1240: {1881, 3397, 3548, 3989, 4000, 4067, 4075, 4080},\n",
       "  1241: {594, 3786},\n",
       "  1242: {987,\n",
       "   1139,\n",
       "   1158,\n",
       "   1383,\n",
       "   1613,\n",
       "   1646,\n",
       "   1788,\n",
       "   1813,\n",
       "   1934,\n",
       "   2358,\n",
       "   2891,\n",
       "   3106},\n",
       "  1243: {396,\n",
       "   870,\n",
       "   1274,\n",
       "   1325,\n",
       "   1498,\n",
       "   1512,\n",
       "   1565,\n",
       "   1567,\n",
       "   1667,\n",
       "   1763,\n",
       "   1800,\n",
       "   1902,\n",
       "   1906,\n",
       "   1942,\n",
       "   2157,\n",
       "   2262,\n",
       "   2318,\n",
       "   2603,\n",
       "   2628,\n",
       "   2676,\n",
       "   2686,\n",
       "   2786,\n",
       "   2937,\n",
       "   3013,\n",
       "   3171,\n",
       "   3473,\n",
       "   3823},\n",
       "  1244: {1668, 2461},\n",
       "  1245: {71, 122, 317, 584, 898, 1711, 2235, 2505, 2973},\n",
       "  1246: {210, 227, 304, 414, 1830, 1904, 2835, 3704},\n",
       "  1247: {900,\n",
       "   2244,\n",
       "   3140,\n",
       "   3209,\n",
       "   3397,\n",
       "   3414,\n",
       "   3420,\n",
       "   3426,\n",
       "   3446,\n",
       "   3556,\n",
       "   3620,\n",
       "   3636,\n",
       "   3677,\n",
       "   3693,\n",
       "   3766,\n",
       "   3848,\n",
       "   3860,\n",
       "   3985,\n",
       "   4048,\n",
       "   4052},\n",
       "  1248: {1031, 3575, 3769},\n",
       "  1252: {229, 1329},\n",
       "  1254: {2164, 2313, 2346, 2561, 2758},\n",
       "  1255: {288, 562},\n",
       "  1257: {1927, 2688, 2825, 3089, 3395, 3537, 3584, 3599, 3761, 3952, 4228},\n",
       "  1259: {2941, 3089, 3171, 4076, 4153},\n",
       "  1260: {193, 1225, 1375, 1491, 1657, 1983, 3397, 3565},\n",
       "  1263: {164},\n",
       "  1264: {842, 1111, 2758},\n",
       "  1266: {3260, 3627, 3797, 3802, 3848},\n",
       "  1267: {1707, 1906, 2357, 2358, 2693, 2888, 2950, 3159, 3171, 3317},\n",
       "  1268: {54, 2688, 3907, 4131},\n",
       "  1269: {335, 537},\n",
       "  1270: {112, 529, 1715, 1770, 1950},\n",
       "  1271: {1323, 1586, 2189},\n",
       "  1273: {236, 258, 1278, 2090},\n",
       "  1276: {2602},\n",
       "  1278: {1903, 1909, 2358, 2549, 2688, 2887, 2951, 3009, 3311},\n",
       "  1280: {3264,\n",
       "   3320,\n",
       "   3376,\n",
       "   3400,\n",
       "   3413,\n",
       "   3452,\n",
       "   3514,\n",
       "   3548,\n",
       "   3558,\n",
       "   3590,\n",
       "   3591,\n",
       "   3626,\n",
       "   3688,\n",
       "   3796,\n",
       "   3926},\n",
       "  1281: {573,\n",
       "   1732,\n",
       "   1909,\n",
       "   2060,\n",
       "   2171,\n",
       "   2190,\n",
       "   2584,\n",
       "   2595,\n",
       "   2688,\n",
       "   3106,\n",
       "   3169,\n",
       "   3702,\n",
       "   3949,\n",
       "   4017,\n",
       "   4218},\n",
       "  1282: {1865, 2688, 3082, 3676, 3886, 4070},\n",
       "  1283: {349, 2183, 2185, 2693},\n",
       "  1285: {1093, 1187, 3916, 4132, 4169},\n",
       "  1286: {2762,\n",
       "   3124,\n",
       "   3135,\n",
       "   3166,\n",
       "   3266,\n",
       "   3574,\n",
       "   3577,\n",
       "   3597,\n",
       "   3685,\n",
       "   3742,\n",
       "   3778,\n",
       "   3932,\n",
       "   4085,\n",
       "   4180},\n",
       "  1287: {443, 2683},\n",
       "  1290: {446,\n",
       "   614,\n",
       "   1020,\n",
       "   1093,\n",
       "   1548,\n",
       "   2318,\n",
       "   2542,\n",
       "   2739,\n",
       "   3056,\n",
       "   3453,\n",
       "   3745,\n",
       "   4085,\n",
       "   4131},\n",
       "  1291: {14, 592, 2140, 2980},\n",
       "  1292: {1553, 2225},\n",
       "  1296: {365},\n",
       "  1298: {2886},\n",
       "  1299: {407, 1093, 3752, 4069, 4105, 4108, 4181},\n",
       "  1300: {1874, 2120, 2224, 2746, 4135},\n",
       "  1301: {1043, 1796, 2413, 2784, 2955, 3654, 3714, 3759, 3797, 3934},\n",
       "  1302: {683,\n",
       "   987,\n",
       "   1326,\n",
       "   1567,\n",
       "   2097,\n",
       "   2160,\n",
       "   2636,\n",
       "   2688,\n",
       "   2990,\n",
       "   3256,\n",
       "   3264,\n",
       "   3292,\n",
       "   3339,\n",
       "   3393,\n",
       "   3402,\n",
       "   3477,\n",
       "   3515,\n",
       "   3531,\n",
       "   3606},\n",
       "  1303: {804},\n",
       "  1304: {2157, 2348, 2530, 3382},\n",
       "  1305: {1485, 1791, 2115, 2406, 3084},\n",
       "  1306: {1193},\n",
       "  1307: {111, 414},\n",
       "  1310: {293, 314, 405, 637, 1435, 1984, 2886, 3065},\n",
       "  1311: {28, 61, 79},\n",
       "  1312: {1077,\n",
       "   1641,\n",
       "   1643,\n",
       "   2094,\n",
       "   2160,\n",
       "   2183,\n",
       "   2185,\n",
       "   2287,\n",
       "   2358,\n",
       "   2393,\n",
       "   3175,\n",
       "   3207},\n",
       "  1313: {512, 1733, 1983, 2483, 3232, 3355},\n",
       "  1314: {50, 107, 191, 201, 221, 451, 548, 981},\n",
       "  1315: {2955, 3115, 3315, 3500, 3539, 3582, 3864, 3881, 4004, 4114},\n",
       "  1316: {3329, 3397, 3690, 4121},\n",
       "  1317: {722, 1338, 1560, 1765, 2094},\n",
       "  1318: {973, 2673},\n",
       "  1319: {361, 387, 1026, 2162},\n",
       "  1321: {1144,\n",
       "   1643,\n",
       "   2144,\n",
       "   2300,\n",
       "   2307,\n",
       "   2353,\n",
       "   2368,\n",
       "   2411,\n",
       "   3132,\n",
       "   3220,\n",
       "   3292,\n",
       "   3361,\n",
       "   3582,\n",
       "   3675,\n",
       "   3684,\n",
       "   3702,\n",
       "   3739,\n",
       "   3747,\n",
       "   3949},\n",
       "  1322: {18},\n",
       "  1323: {1748, 3822},\n",
       "  1324: {1151, 3584, 4194},\n",
       "  1327: {640,\n",
       "   790,\n",
       "   1077,\n",
       "   1177,\n",
       "   1334,\n",
       "   1411,\n",
       "   1643,\n",
       "   1664,\n",
       "   1698,\n",
       "   2094,\n",
       "   2163,\n",
       "   2164,\n",
       "   2549,\n",
       "   2688,\n",
       "   2705,\n",
       "   3010,\n",
       "   3156,\n",
       "   3926},\n",
       "  1328: {363,\n",
       "   587,\n",
       "   761,\n",
       "   900,\n",
       "   909,\n",
       "   914,\n",
       "   1205,\n",
       "   1214,\n",
       "   1251,\n",
       "   1314,\n",
       "   1528,\n",
       "   1585,\n",
       "   1643,\n",
       "   1655,\n",
       "   1691,\n",
       "   1710,\n",
       "   1720,\n",
       "   1870,\n",
       "   1987,\n",
       "   2019,\n",
       "   2094,\n",
       "   2127,\n",
       "   2315,\n",
       "   2528,\n",
       "   2646,\n",
       "   2682,\n",
       "   2707,\n",
       "   2940,\n",
       "   3072,\n",
       "   3111,\n",
       "   3228,\n",
       "   3341,\n",
       "   3346,\n",
       "   3467,\n",
       "   3626,\n",
       "   3685,\n",
       "   4007},\n",
       "  1330: {2357, 2364, 4113, 4143},\n",
       "  1333: {2688, 3296, 3391, 3419, 3702},\n",
       "  1334: {366, 2749, 3397, 4172},\n",
       "  1338: {861, 1280, 1318, 1963, 2616, 3084, 3099, 3354},\n",
       "  1339: {3185, 3395},\n",
       "  1340: {333,\n",
       "   937,\n",
       "   1016,\n",
       "   1133,\n",
       "   1166,\n",
       "   1267,\n",
       "   1410,\n",
       "   1530,\n",
       "   1534,\n",
       "   1556,\n",
       "   1576,\n",
       "   1886,\n",
       "   1892,\n",
       "   1956,\n",
       "   2152,\n",
       "   2332,\n",
       "   2352,\n",
       "   2693,\n",
       "   2879,\n",
       "   3098,\n",
       "   3156,\n",
       "   3169,\n",
       "   3213},\n",
       "  1341: {392, 1534, 1556},\n",
       "  1342: {4, 2143},\n",
       "  1343: {667, 1329},\n",
       "  1344: {329,\n",
       "   369,\n",
       "   383,\n",
       "   415,\n",
       "   540,\n",
       "   700,\n",
       "   1181,\n",
       "   1207,\n",
       "   2361,\n",
       "   3188,\n",
       "   3194,\n",
       "   3580,\n",
       "   3747,\n",
       "   4010},\n",
       "  1346: {94, 2071, 2419, 3173, 3395, 3738, 3867, 3930, 3951, 3985, 4088},\n",
       "  1347: {2693, 2794, 2890, 2940},\n",
       "  1348: {126, 2709, 3483},\n",
       "  1351: {46, 613, 667, 1198, 1804},\n",
       "  1353: {4, 164, 190, 251, 1243},\n",
       "  1354: {2042, 2165, 2178, 2358, 2624, 2953, 2957},\n",
       "  1357: {18, 119, 3425},\n",
       "  1360: {919, 1794},\n",
       "  1361: {2688, 2823, 3183, 4024, 4047, 4101, 4110, 4143, 4190},\n",
       "  1362: {1573, 1898, 2036, 2274, 2438, 2487, 2583, 2711, 2852},\n",
       "  1363: {733, 1025, 2418, 2696, 3156, 3275, 3465, 3981, 4144},\n",
       "  1364: {2080, 2554, 3799, 3937},\n",
       "  1365: {2385,\n",
       "   2390,\n",
       "   2518,\n",
       "   2688,\n",
       "   3149,\n",
       "   3174,\n",
       "   3308,\n",
       "   3427,\n",
       "   3514,\n",
       "   3535,\n",
       "   3555,\n",
       "   3607,\n",
       "   3626,\n",
       "   4196},\n",
       "  1366: {175, 1589},\n",
       "  1367: {1608, 3495},\n",
       "  1368: {1254, 2055, 2926, 3459, 3729, 3736, 3749, 3761, 4077},\n",
       "  1371: {201, 525, 986, 2528},\n",
       "  1372: {1568, 3761, 4085, 4117},\n",
       "  1373: {2421},\n",
       "  1375: {1743, 1888, 2304, 2373, 2563, 2606, 2661, 3473, 3591},\n",
       "  1377: {382, 504, 2036, 2688, 3586, 3702, 3715, 3907},\n",
       "  1380: {751, 2059, 2181, 2365, 2951},\n",
       "  1381: {1249, 1430},\n",
       "  1382: {652,\n",
       "   762,\n",
       "   763,\n",
       "   826,\n",
       "   1475,\n",
       "   1565,\n",
       "   1627,\n",
       "   1643,\n",
       "   1761,\n",
       "   2094,\n",
       "   2332,\n",
       "   2357,\n",
       "   2365,\n",
       "   2475,\n",
       "   2549,\n",
       "   2624,\n",
       "   2685},\n",
       "  1383: {1803, 2100, 2549},\n",
       "  1384: {1871, 2167, 2373, 2726, 2742},\n",
       "  1385: {1010, 1069, 1493, 2159, 2187, 2188, 2691, 3224, 3378, 3626, 3924},\n",
       "  1387: {79, 189, 1435},\n",
       "  1388: {356, 988, 2964},\n",
       "  1391: {125, 1241, 1524, 3193, 3295, 3369, 3464, 3906, 3910, 3940, 3965},\n",
       "  1392: {496, 1063, 1756, 2023, 2241, 2575, 2603, 3061, 3257, 3559, 3790},\n",
       "  1395: {62, 66, 69, 255, 443, 3474},\n",
       "  1396: {2085, 2086, 2641, 3389},\n",
       "  1397: {821, 2173},\n",
       "  1398: {4149, 4173},\n",
       "  1400: {1709, 3981, 3994},\n",
       "  1401: {889, 2103},\n",
       "  1403: {825, 1127, 3397, 3662, 3830, 3989},\n",
       "  1405: {878, 2162, 3294, 3362, 3473, 3514, 3823, 4032},\n",
       "  1410: {1430, 1687, 2249},\n",
       "  1412: {1777, 2348, 2886, 3223, 3613, 3788},\n",
       "  1415: {1747, 2388, 3925},\n",
       "  1416: {486, 1097, 1373, 1760, 2021, 2213, 3325},\n",
       "  1418: {482, 1874, 2568, 2688, 3429, 3669, 3681, 3920},\n",
       "  1421: {3289, 4169, 4181, 4196},\n",
       "  1422: {1104, 2698, 3075, 3313, 4214},\n",
       "  1425: {2011, 2159},\n",
       "  1426: {1133,\n",
       "   1301,\n",
       "   1391,\n",
       "   1409,\n",
       "   1411,\n",
       "   1450,\n",
       "   2116,\n",
       "   2180,\n",
       "   2352,\n",
       "   2705,\n",
       "   3171,\n",
       "   3413},\n",
       "  1427: {1227,\n",
       "   1559,\n",
       "   2678,\n",
       "   2721,\n",
       "   2774,\n",
       "   2837,\n",
       "   3027,\n",
       "   3151,\n",
       "   3253,\n",
       "   3435,\n",
       "   4073,\n",
       "   4074,\n",
       "   4097,\n",
       "   4108,\n",
       "   4127,\n",
       "   4187},\n",
       "  1429: {189, 1975, 2469, 2590, 2870, 3146},\n",
       "  1430: {3504, 3702, 3850, 4031, 4093, 4123},\n",
       "  1431: {954, 4195},\n",
       "  1432: {713, 1286, 1400, 2016, 2254, 2678, 2861, 3140},\n",
       "  1433: {156, 316, 522, 597, 999, 1185, 1276, 1494, 1528, 1582},\n",
       "  1434: {2628, 2689},\n",
       "  1438: {1091, 1092, 1615, 1899, 2554, 2655, 2685, 3082, 3157, 3479},\n",
       "  1439: {506,\n",
       "   1176,\n",
       "   1384,\n",
       "   1615,\n",
       "   1703,\n",
       "   1796,\n",
       "   1925,\n",
       "   1941,\n",
       "   2129,\n",
       "   2314,\n",
       "   2328,\n",
       "   2433,\n",
       "   2495,\n",
       "   2515,\n",
       "   2563,\n",
       "   2670,\n",
       "   2761,\n",
       "   2803,\n",
       "   2893,\n",
       "   2921,\n",
       "   3051,\n",
       "   3153,\n",
       "   3367,\n",
       "   3393,\n",
       "   3397,\n",
       "   3406,\n",
       "   3417,\n",
       "   3449,\n",
       "   3455,\n",
       "   3461,\n",
       "   3464,\n",
       "   3471,\n",
       "   3492,\n",
       "   3493,\n",
       "   3546,\n",
       "   3549,\n",
       "   3562,\n",
       "   3586,\n",
       "   3587,\n",
       "   3600,\n",
       "   3609,\n",
       "   3622,\n",
       "   3623,\n",
       "   3644,\n",
       "   3665,\n",
       "   3670,\n",
       "   3770,\n",
       "   3821,\n",
       "   3872,\n",
       "   4143},\n",
       "  1440: {28, 92, 225, 2127},\n",
       "  1441: {3331, 3397, 4076, 4194, 4198, 4219},\n",
       "  1442: {24, 738, 823, 1462},\n",
       "  1444: {15,\n",
       "   25,\n",
       "   36,\n",
       "   107,\n",
       "   151,\n",
       "   202,\n",
       "   227,\n",
       "   232,\n",
       "   868,\n",
       "   1394,\n",
       "   2020,\n",
       "   2050,\n",
       "   2071,\n",
       "   2219,\n",
       "   2510,\n",
       "   2517},\n",
       "  1445: {679,\n",
       "   964,\n",
       "   1593,\n",
       "   1793,\n",
       "   1942,\n",
       "   2329,\n",
       "   2418,\n",
       "   2482,\n",
       "   2786,\n",
       "   3254,\n",
       "   3362,\n",
       "   3377,\n",
       "   3412,\n",
       "   3416,\n",
       "   3433,\n",
       "   3448,\n",
       "   3489,\n",
       "   3493,\n",
       "   3500,\n",
       "   3534,\n",
       "   3539,\n",
       "   3623,\n",
       "   3626,\n",
       "   3645,\n",
       "   3665,\n",
       "   3678,\n",
       "   3799,\n",
       "   3849,\n",
       "   3982,\n",
       "   4070},\n",
       "  1446: {1927, 2158, 2321, 2359, 3586, 4113, 4144},\n",
       "  1448: {95, 2910},\n",
       "  1449: {630, 2447},\n",
       "  1450: {1055, 2361},\n",
       "  1451: {29, 347, 438, 475, 1670, 1961, 2710, 2886},\n",
       "  1454: {1516, 1530, 1534, 1594, 2970},\n",
       "  1458: {862,\n",
       "   1349,\n",
       "   1457,\n",
       "   2227,\n",
       "   2277,\n",
       "   2278,\n",
       "   2291,\n",
       "   2322,\n",
       "   2558,\n",
       "   2679,\n",
       "   2758,\n",
       "   2819,\n",
       "   2933,\n",
       "   3171},\n",
       "  1459: {1503, 2200, 2308, 2384, 2474, 2538, 2559, 2625, 2626, 2751},\n",
       "  1460: {3356, 4113},\n",
       "  1461: {3462, 3600, 3737, 3751, 3944, 3997},\n",
       "  1463: {1906,\n",
       "   2353,\n",
       "   2688,\n",
       "   2950,\n",
       "   2955,\n",
       "   3156,\n",
       "   3396,\n",
       "   3423,\n",
       "   3491,\n",
       "   3495,\n",
       "   3539,\n",
       "   3631,\n",
       "   3651,\n",
       "   3659,\n",
       "   3739,\n",
       "   4143},\n",
       "  1464: {325, 716, 1435, 1506, 1844},\n",
       "  1465: {995, 1277, 1524, 1831, 1838, 1870, 2011, 2441, 2842, 3948},\n",
       "  1466: {1497, 2128, 2533, 3062},\n",
       "  1467: {263, 1225, 1277, 2268, 2727, 3001, 3134, 3168, 3220},\n",
       "  1468: {2955, 2956, 3322, 3388, 3391, 3502, 3885, 4097, 4161},\n",
       "  1469: {1006, 1164, 1190},\n",
       "  1470: {3473},\n",
       "  1472: {1276},\n",
       "  1474: {1384, 2093, 2955, 2978, 3304, 3409},\n",
       "  1475: {893,\n",
       "   1025,\n",
       "   1146,\n",
       "   1684,\n",
       "   1906,\n",
       "   1907,\n",
       "   2240,\n",
       "   2281,\n",
       "   2593,\n",
       "   2682,\n",
       "   3083,\n",
       "   3150},\n",
       "  1476: {283, 1344, 1438, 1675, 2202, 2352, 2583, 3048, 3115},\n",
       "  ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:37.748243Z",
     "start_time": "2025-08-21T14:52:37.742911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositiveImplicitDataset(Dataset):\n",
    "    def __init__(self, df_pos: pd.DataFrame):\n",
    "        self.user_ids = torch.tensor(df_pos[\"user_id\"].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df_pos[\"item_id\"].values, dtype=torch.long)\n",
    "        self.weights  = torch.tensor(df_pos[\"trust_weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.weights[idx]"
   ],
   "id": "44446a0bcd7265fc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:40.220032Z",
     "start_time": "2025-08-21T14:52:40.200023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImplicitBCETrainer:\n",
    "    def __init__(self, model, domain_items, seen_by_user,\n",
    "                 n_epochs=20, lr=1e-3, weight_decay=1e-5, batch_size=1024,\n",
    "                 n_neg=5, pos_weight_scale=1, neg_weight=1,\n",
    "                 max_grad_norm=5.0, patience=3, device=\"cpu\"):\n",
    "\n",
    "        self.model = model.to(device)\n",
    "        self.domain_items = np.array(domain_items)\n",
    "        self.seen_by_user = seen_by_user\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.n_neg = n_neg\n",
    "        self.pos_weight_scale = pos_weight_scale\n",
    "        self.neg_weight = neg_weight\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-5\n",
    "        )\n",
    "\n",
    "    def _sample_negatives(self, users_np: np.ndarray) -> np.ndarray:\n",
    "        neg_items = []\n",
    "        for u in users_np:\n",
    "            seen = self.seen_by_user.get(int(u), set())\n",
    "            pool = self.domain_items[~np.isin(self.domain_items, list(seen))]\n",
    "            if len(pool) == 0:\n",
    "                pool = self.domain_items\n",
    "            replace = len(pool) < self.n_neg\n",
    "            neg_items.append(np.random.choice(pool, size=self.n_neg, replace=replace))\n",
    "        return np.array(neg_items)\n",
    "\n",
    "    def train(self, train_df_pos: pd.DataFrame, val_df_pos: pd.DataFrame):\n",
    "        train_loader = DataLoader(PositiveImplicitDataset(train_df_pos), batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(PositiveImplicitDataset(val_df_pos),   batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        best_val, best_state, bad = float(\"inf\"), None, 0\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # ---- train ----\n",
    "            self.model.train()\n",
    "            loss_acc, denom = 0.0, 0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.n_epochs}\")\n",
    "            for u_pos, i_pos, w_pos in pbar:\n",
    "                u_pos = u_pos.to(self.device)\n",
    "                i_pos = i_pos.to(self.device)\n",
    "                w_pos = w_pos.to(self.device)\n",
    "\n",
    "                neg_mat = self._sample_negatives(u_pos.cpu().numpy())  # [B, n_neg]\n",
    "                u_neg = torch.tensor(u_pos.cpu().numpy().repeat(self.n_neg), dtype=torch.long, device=self.device)\n",
    "                i_neg = torch.tensor(neg_mat.reshape(-1), dtype=torch.long, device=self.device)\n",
    "\n",
    "                users  = torch.cat([u_pos, u_neg], dim=0)\n",
    "                items  = torch.cat([i_pos, i_neg], dim=0)\n",
    "                labels = torch.cat([torch.ones_like(u_pos, dtype=torch.float32),\n",
    "                                    torch.zeros_like(u_neg, dtype=torch.float32)], dim=0)\n",
    "                w_neg  = torch.full_like(u_neg, fill_value=self.neg_weight, dtype=torch.float32)\n",
    "                weights = torch.cat([w_pos * self.pos_weight_scale, w_neg], dim=0).to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                logits = self.model(users, items)\n",
    "                loss_vec = self.loss_fn(logits, labels)\n",
    "                loss = (weights * loss_vec).sum() / (weights.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "                if self.max_grad_norm: nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                loss_acc += loss.item() * labels.size(0)\n",
    "                denom += labels.size(0)\n",
    "                pbar.set_postfix({\"Train loss\": f\"{loss.item():.4f}\"})\n",
    "            train_loss = loss_acc / max(1, denom)\n",
    "\n",
    "            # ---- validate ----\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                loss_acc, denom = 0.0, 0\n",
    "                for u_pos, i_pos, w_pos in val_loader:\n",
    "                    u_pos = u_pos.to(DEVICE)\n",
    "                    i_pos = i_pos.to(self.device)\n",
    "                    w_pos = w_pos.to(self.device)\n",
    "\n",
    "                    neg_mat = self._sample_negatives(u_pos.cpu().numpy())\n",
    "                    u_neg = torch.tensor(u_pos.cpu().numpy().repeat(self.n_neg), dtype=torch.long, device=self.device)\n",
    "                    i_neg = torch.tensor(neg_mat.reshape(-1), dtype=torch.long, device=self.device)\n",
    "\n",
    "                    users  = torch.cat([u_pos, u_neg], dim=0)\n",
    "                    items  = torch.cat([i_pos, i_neg], dim=0)\n",
    "                    labels = torch.cat([torch.ones_like(u_pos, dtype=torch.float32),\n",
    "                                        torch.zeros_like(u_neg, dtype=torch.float32)], dim=0)\n",
    "                    w_neg  = torch.full_like(u_neg, fill_value=self.neg_weight, dtype=torch.float32)\n",
    "                    weights = torch.cat([w_pos * self.pos_weight_scale, w_neg], dim=0).to(self.device)\n",
    "\n",
    "                    logits = self.model(users, items)\n",
    "                    loss_vec = self.loss_fn(logits, labels)\n",
    "                    loss = (weights * loss_vec).sum() / (weights.sum() + 1e-8)\n",
    "\n",
    "                    loss_acc += loss.item() * labels.size(0)\n",
    "                    denom += labels.size(0)\n",
    "            val_loss = loss_acc / max(1, denom)\n",
    "            self.scheduler.step(val_loss)\n",
    "            print(f\"Epoch {epoch+1}: Train loss={train_loss:.4f} | Val loss={val_loss:.4f}\")\n",
    "            # print(f\"Epoch {epoch+1}: train_BCE={train_loss:.4f} | val_BCE={val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val - 1e-4:\n",
    "                best_val, best_state, bad = val_loss, {k: v.detach().cpu() for k, v in self.model.state_dict().items()}, 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}. Best val loss={best_val:.4f}\")\n",
    "                    break\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(self.device) for k, v in best_state.items()})\n",
    "\n",
    "    # same API your evaluator expects\n",
    "    def predict_dataframe(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        self.model.eval()\n",
    "        users = torch.tensor(df[\"user_id\"].values, dtype=torch.long, device=self.device)\n",
    "        items = torch.tensor(df[\"item_id\"].values, dtype=torch.long, device=self.device)\n",
    "        out = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(df), 100_000):\n",
    "                pu = users[i:i+100_000]; pi = items[i:i+100_000]\n",
    "                out.append(self.model(pu, pi).detach().cpu().numpy())\n",
    "        return np.concatenate(out)"
   ],
   "id": "c8f8dcc125d6ef86",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:52:40.828984Z",
     "start_time": "2025-08-21T14:52:40.820465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items,\n",
    "                 factors_gmf=32, factors_mlp=32,\n",
    "                 mlp_layers=(128,64,32), dropout=0.2, use_bias=True):\n",
    "        super().__init__()\n",
    "        # GMF\n",
    "        self.gmf_user = nn.Embedding(n_users, factors_gmf)\n",
    "        self.gmf_item = nn.Embedding(n_items, factors_gmf)\n",
    "        # MLP\n",
    "        self.mlp_user = nn.Embedding(n_users, factors_mlp)\n",
    "        self.mlp_item = nn.Embedding(n_items, factors_mlp)\n",
    "        in_dim = factors_mlp * 2\n",
    "        layers = []\n",
    "        for h in mlp_layers:\n",
    "            layers += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            in_dim = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        # Combine & predict logits\n",
    "        pred_in = factors_gmf + (mlp_layers[-1] if mlp_layers else factors_mlp * 2)\n",
    "        self.pred = nn.Linear(pred_in, 1)\n",
    "\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.user_bias = nn.Embedding(n_users, 1)\n",
    "            self.item_bias = nn.Embedding(n_items, 1)\n",
    "        else:\n",
    "            self.user_bias = None\n",
    "            self.item_bias = None\n",
    "\n",
    "        # init\n",
    "        for emb in [self.gmf_user, self.gmf_item, self.mlp_user, self.mlp_item]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.pred.weight); nn.init.zeros_(self.pred.bias)\n",
    "        if self.use_bias:\n",
    "            nn.init.zeros_(self.user_bias.weight); nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        gmf = self.gmf_user(users) * self.gmf_item(items)\n",
    "        mlp_in = torch.cat([self.mlp_user(users), self.mlp_item(items)], dim=1)\n",
    "        mlp_out = self.mlp(mlp_in)\n",
    "        x = torch.cat([gmf, mlp_out], dim=1)\n",
    "        y = self.pred(x).squeeze(1)\n",
    "        if self.use_bias:\n",
    "            y = y + self.user_bias(users).squeeze(1) + self.item_bias(items).squeeze(1)\n",
    "        return y"
   ],
   "id": "8fe3a5e6893692b3",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:56:32.473699Z",
     "start_time": "2025-08-21T14:55:05.359906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_new_train = new_train_df[new_train_df[\"domain\"] == SOURCE_DOMAIN]\n",
    "movies_new_val   = new_val_df[new_val_df[\"domain\"] == SOURCE_DOMAIN]\n",
    "movies_new_test  = new_test_df[new_test_df[\"domain\"] == SOURCE_DOMAIN]\n",
    "\n",
    "# Shapes from your implicit prep:\n",
    "n_users_total  = implicit_df[\"user_id\"].max() + 1\n",
    "n_movies_items = implicit_df[implicit_df[\"domain\"] == SOURCE_DOMAIN][\"item_id\"].max() + 1\n",
    "\n",
    "# Build MF model and trainer\n",
    "# mf_imp = SimpleMatrixFactorization(n_users_total, n_movies_items, embedding_dim=8)\n",
    "mf_imp = NeuMF(\n",
    "    n_users=n_users_total,\n",
    "    n_items=n_movies_items,\n",
    "    factors_gmf=8,\n",
    "    factors_mlp=8,\n",
    "    mlp_layers=(64, 32),\n",
    "    dropout=0.2,\n",
    "    use_bias=True\n",
    ")\n",
    "\n",
    "mf_trainer = ImplicitBCETrainer(\n",
    "    model=mf_imp,\n",
    "    domain_items=movies_domain_items,\n",
    "    seen_by_user=movies_seen_by_user,\n",
    "    n_epochs=100, lr=0.005, weight_decay=5e-3, batch_size=1024,\n",
    "    n_neg=5, # negatives per positive (training)\n",
    "    pos_weight_scale=1, # multiplier on positives’ trust_weight for BCE\n",
    "    neg_weight=1, # multiplier on positives’ trust_weight for BCE\n",
    "    max_grad_norm=5.0, patience=10, device=DEVICE\n",
    ")\n",
    "\n",
    "mf_trainer.train(movies_new_train, movies_new_val)"
   ],
   "id": "c1dbd6838cbfe503",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 39/39 [00:06<00:00,  5.80it/s, Train loss=0.4427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.4813 | Val loss=0.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 39/39 [00:06<00:00,  5.71it/s, Train loss=0.4398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss=0.4417 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 39/39 [00:06<00:00,  5.74it/s, Train loss=0.4408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss=0.4420 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, Train loss=0.4433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss=0.4417 | Val loss=0.4415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 39/39 [00:06<00:00,  5.68it/s, Train loss=0.4410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss=0.4415 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 39/39 [00:06<00:00,  5.80it/s, Train loss=0.4425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train loss=0.4415 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 39/39 [00:06<00:00,  5.81it/s, Train loss=0.4433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train loss=0.4415 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 39/39 [00:06<00:00,  5.73it/s, Train loss=0.4430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train loss=0.4416 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 39/39 [00:06<00:00,  5.98it/s, Train loss=0.4421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train loss=0.4414 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 39/39 [00:06<00:00,  5.60it/s, Train loss=0.4417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train loss=0.4413 | Val loss=0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 39/39 [00:06<00:00,  5.80it/s, Train loss=0.4418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train loss=0.4415 | Val loss=0.4414\n",
      "Early stopping at epoch 11. Best val loss=0.4404\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:58:08.419272Z",
     "start_time": "2025-08-21T14:58:08.406302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dcg_at_k(relevances, k):\n",
    "    r = np.asarray(relevances)[:k]\n",
    "    if r.size == 0: return 0.0\n",
    "    discounts = 1.0 / np.log2(np.arange(2, r.size + 2))\n",
    "    return float(np.sum(r * discounts))\n",
    "\n",
    "def ndcg_at_k(predicted_items, true_rel_map, k):\n",
    "    gains = [true_rel_map.get(i, 0.0) for i in predicted_items[:k]]\n",
    "    dcg = dcg_at_k(gains, k)\n",
    "    ideal_gains = sorted(true_rel_map.values(), reverse=True)\n",
    "    idcg = dcg_at_k(ideal_gains, k)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def precompute_negatives(all_df: pd.DataFrame, test_df: pd.DataFrame, domain: str, n_neg=100, seed=42):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    dom_all = all_df[all_df[\"domain\"] == domain]\n",
    "    dom_items = set(dom_all[\"item_id\"].unique())\n",
    "    seen_by_user = dom_all.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "    negs = {}\n",
    "    for uid, _ in test_df[test_df[\"domain\"] == domain].groupby(\"user_id\"):\n",
    "        seen = seen_by_user.get(uid, set())\n",
    "        pool = np.array(list(dom_items - seen))\n",
    "        if len(pool) == 0: continue\n",
    "        m = min(n_neg, len(pool))\n",
    "        negs[int(uid)] = rs.choice(pool, size=m, replace=False)\n",
    "    return negs\n",
    "\n",
    "def evaluate_ranking_metrics(\n",
    "    model, test_df, all_data_df, domain: str,\n",
    "    k=10, rating_threshold=4.0, neg_samples=100,\n",
    "    precomputed_negatives=None, graded=False\n",
    "):\n",
    "    print(f\"\\n📊 Evaluating @k={k} for domain={domain}\")\n",
    "    test_dom = test_df[test_df[\"domain\"] == domain].copy()\n",
    "    hist_dom = all_data_df[all_data_df[\"domain\"] == domain].copy()\n",
    "    if test_dom.empty:\n",
    "        print(\"No test rows for domain.\")\n",
    "        return {f\"precision_at_{k}\":0.0, f\"recall_at_{k}\":0.0, f\"map_at_{k}\":0.0, f\"ndcg_at_{k}\":0.0}\n",
    "\n",
    "    # relevance map per user (binary by default)\n",
    "    precisions, recalls, aps, ndcgs = [], [], [], []\n",
    "\n",
    "    # fallback for negatives if not provided\n",
    "    if precomputed_negatives is None:\n",
    "        precomputed_negatives = precompute_negatives(all_data_df, test_df, domain, n_neg=neg_samples, seed=SEED)\n",
    "\n",
    "    for user_id, g in tqdm(test_dom.groupby(\"user_id\"), desc=\"Ranking\"):\n",
    "        if graded:\n",
    "            rel_map = {iid: max(float(r) - (rating_threshold - 1.0), 0.0)\n",
    "                       for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)}\n",
    "        else:\n",
    "            rel_map = {iid: 1.0 if float(r) >= rating_threshold else 0.0\n",
    "                       for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)}\n",
    "        rel_items = {iid for iid, gain in rel_map.items() if gain > 0}\n",
    "        if not rel_items:  # no relevant test items\n",
    "            continue\n",
    "\n",
    "        # candidates: relevant test items + fixed negatives\n",
    "        negs = precomputed_negatives.get(int(user_id), None)\n",
    "        if negs is None or len(negs) == 0:\n",
    "            # skip user if no negatives available (rare)\n",
    "            continue\n",
    "\n",
    "        items_to_rank = np.concatenate([np.array(list(rel_map.keys()), dtype=np.int64), negs.astype(np.int64)])\n",
    "        pred_df = pd.DataFrame({\"user_id\": int(user_id), \"item_id\": items_to_rank})\n",
    "        pred_df[\"score\"] = model.predict_dataframe(pred_df)\n",
    "        pred_df = pred_df.sort_values(\"score\", ascending=False)\n",
    "        top_k = pred_df[\"item_id\"].values[:k]\n",
    "\n",
    "        hits = set(top_k).intersection(rel_items)\n",
    "        precisions.append(len(hits) / k)\n",
    "        recalls.append(len(hits) / len(rel_items))\n",
    "\n",
    "        # MAP@k\n",
    "        ap, got = 0.0, 0\n",
    "        for rank, it in enumerate(top_k, start=1):\n",
    "            if it in rel_items:\n",
    "                got += 1\n",
    "                ap += got / rank\n",
    "        aps.append(ap / len(rel_items))\n",
    "\n",
    "        # NDCG@k\n",
    "        ndcgs.append(ndcg_at_k(top_k.tolist(), rel_map, k))\n",
    "\n",
    "    out = {\n",
    "        f\"precision_at_{k}\": float(np.mean(precisions)) if precisions else 0.0,\n",
    "        f\"recall_at_{k}\":    float(np.mean(recalls))    if recalls    else 0.0,\n",
    "        f\"map_at_{k}\":       float(np.mean(aps))        if aps        else 0.0,\n",
    "        f\"ndcg_at_{k}\":      float(np.mean(ndcgs))      if ndcgs      else 0.0,\n",
    "    }\n",
    "    print(f\"Precision@{k}: {out[f'precision_at_{k}']:.4f} | \"\n",
    "          f\"Recall@{k}: {out[f'recall_at_{k}']:.4f} | \"\n",
    "          f\"MAP@{k}: {out[f'map_at_{k}']:.4f} | \"\n",
    "          f\"NDCG@{k}: {out[f'ndcg_at_{k}']:.4f}\")\n",
    "    return out"
   ],
   "id": "a8ed2d597efade26",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:58:22.442291Z",
     "start_time": "2025-08-21T14:58:09.143015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_fixed_negs = precompute_negatives(implicit_df, movies_test, SOURCE_DOMAIN, n_neg=100, seed=SEED)\n",
    "_ = evaluate_ranking_metrics(\n",
    "    model=mf_trainer,\n",
    "    test_df=movies_new_test,\n",
    "    all_data_df=implicit_df,\n",
    "    domain=SOURCE_DOMAIN,\n",
    "    k=10,\n",
    "    rating_threshold=4.0,\n",
    "    neg_samples=100,\n",
    "    precomputed_negatives=movies_fixed_negs,\n",
    "    graded=False\n",
    ")"
   ],
   "id": "ca5bd41be11ebee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating @k=10 for domain=Movies_and_TV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6106/6106 [00:10<00:00, 592.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0252 | Recall@10: 0.2519 | MAP@10: 0.1185 | NDCG@10: 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1365c2e2967b996d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1399d882cbd3530c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1290ca226eb772de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:00:06.397171Z",
     "start_time": "2025-08-21T09:00:06.384152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items: int,\n",
    "        factors_gmf: int = 32,\n",
    "        factors_mlp: int = 32,\n",
    "        mlp_layers=(128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        use_bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # GMF embeddings\n",
    "        self.gmf_user = nn.Embedding(n_users, factors_gmf)\n",
    "        self.gmf_item = nn.Embedding(n_items, factors_gmf)\n",
    "        # MLP embeddings\n",
    "        self.mlp_user = nn.Embedding(n_users, factors_mlp)\n",
    "        self.mlp_item = nn.Embedding(n_items, factors_mlp)\n",
    "\n",
    "        # MLP tower\n",
    "        in_dim = factors_mlp * 2\n",
    "        mlp = []\n",
    "        for h in mlp_layers:\n",
    "            mlp += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            in_dim = h\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "\n",
    "        # Prediction layer over [GMF ⊕ MLP]\n",
    "        pred_in = factors_gmf + (mlp_layers[-1] if len(mlp_layers) > 0 else factors_mlp * 2)\n",
    "        self.pred = nn.Linear(pred_in, 1)\n",
    "\n",
    "        # Optional biases + global mean (helpful for ratings)\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.user_bias = nn.Embedding(n_users, 1)\n",
    "            self.item_bias = nn.Embedding(n_items, 1)\n",
    "        else:\n",
    "            self.user_bias = None\n",
    "            self.item_bias = None\n",
    "        self.global_mean = nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "        # init\n",
    "        for emb in [self.gmf_user, self.gmf_item, self.mlp_user, self.mlp_item]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.pred.weight); nn.init.zeros_(self.pred.bias)\n",
    "        if self.use_bias:\n",
    "            nn.init.zeros_(self.user_bias.weight); nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        gmf = self.gmf_user(users) * self.gmf_item(items)  # elementwise product\n",
    "        mlp_in = torch.cat([self.mlp_user(users), self.mlp_item(items)], dim=1)\n",
    "        mlp_out = self.mlp(mlp_in)\n",
    "        x = torch.cat([gmf, mlp_out], dim=1)\n",
    "        y = self.pred(x).squeeze(1)\n",
    "        if self.use_bias:\n",
    "            y = y + self.user_bias(users).squeeze(1) + self.item_bias(items).squeeze(1) + self.global_mean\n",
    "        return y"
   ],
   "id": "4cb6e3c4ebae7a93",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:00:07.966756Z",
     "start_time": "2025-08-21T09:00:07.944122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class PyTorchNeuMFModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        factors_gmf=32,\n",
    "        factors_mlp=32,\n",
    "        mlp_layers=(128, 64, 32),\n",
    "        dropout=0.2,\n",
    "        use_bias=True,\n",
    "        n_epochs=30,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        batch_size=1024,\n",
    "        max_grad_norm=5.0,\n",
    "        patience=4,  # for ReduceLROnPlateau-driven convergence\n",
    "    ):\n",
    "        self.factors_gmf = factors_gmf\n",
    "        self.factors_mlp = factors_mlp\n",
    "        self.mlp_layers = mlp_layers\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.patience = patience\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, train_df, val_df, n_users, n_items):\n",
    "        print(\"\\n🚀 Training NeuMF (ratings regression with sample-weighted MSE)\")\n",
    "        print(f\"   Device: {DEVICE} | GMF:{self.factors_gmf} | MLP:{self.factors_mlp} \"\n",
    "              f\"| Layers:{self.mlp_layers} | Dropout:{self.dropout}\")\n",
    "\n",
    "        train_loader = DataLoader(SimpleMFDataset(train_df), batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(SimpleMFDataset(val_df),   batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.model = NeuMF(\n",
    "            n_users, n_items,\n",
    "            factors_gmf=self.factors_gmf,\n",
    "            factors_mlp=self.factors_mlp,\n",
    "            mlp_layers=self.mlp_layers,\n",
    "            dropout=self.dropout,\n",
    "            use_bias=self.use_bias\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # set global mean from train ratings\n",
    "        self.model.global_mean.data.fill_(float(train_df[\"rating\"].mean()))\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-5\n",
    "        )\n",
    "\n",
    "        best_val_rmse = float(\"inf\")\n",
    "        best_state = None\n",
    "        bad_epochs = 0\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # -------- train --------\n",
    "            self.model.train()\n",
    "            se_sum, denom = 0.0, 0.0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.n_epochs}\")\n",
    "            for users, items, ratings, weights in pbar:\n",
    "                users = users.to(DEVICE); items = items.to(DEVICE)\n",
    "                ratings = ratings.to(DEVICE); weights = weights.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.model(users, items)\n",
    "\n",
    "                se = (preds - ratings) ** 2\n",
    "                loss = (weights * se).sum() / (weights.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "\n",
    "                if self.max_grad_norm is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                se_sum += se.detach().sum().item()\n",
    "                denom += ratings.numel()\n",
    "                pbar.set_postfix({\"Train RMSE\": f\"{math.sqrt(se_sum/denom):.4f}\"})\n",
    "\n",
    "            train_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "\n",
    "            # -------- validate --------\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                se_sum, denom = 0.0, 0.0\n",
    "                for users, items, ratings, _ in val_loader:\n",
    "                    users = users.to(DEVICE); items = items.to(DEVICE); ratings = ratings.to(DEVICE)\n",
    "                    preds = self.model(users, items)\n",
    "                    se_sum += torch.sum((preds - ratings) ** 2).item()\n",
    "                    denom += ratings.numel()\n",
    "            val_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "            scheduler.step(val_rmse)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} - Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            # early-stop restore\n",
    "            if val_rmse < best_val_rmse - 1e-4:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_state = {k: v.detach().cpu() for k, v in self.model.state_dict().items()}\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                bad_epochs += 1\n",
    "                if bad_epochs >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}. Best Val RMSE: {best_val_rmse:.4f}\")\n",
    "                    break\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
    "        print(\"✅ Training complete! Best Val RMSE:\", f\"{best_val_rmse:.4f}\")\n",
    "\n",
    "    def predict_dataframe(self, df):\n",
    "        \"\"\"df must have user_id, item_id\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        self.model.eval()\n",
    "\n",
    "        users = torch.tensor(df[\"user_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "        items = torch.tensor(df[\"item_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(df), self.batch_size):\n",
    "                pu = users[i:i+self.batch_size]\n",
    "                pi = items[i:i+self.batch_size]\n",
    "                p = self.model(pu, pi)\n",
    "                preds.append(p.detach().cpu().numpy())\n",
    "        return np.concatenate(preds)"
   ],
   "id": "60811f9afd64ab3",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:04:07.186476Z",
     "start_time": "2025-08-21T09:04:05.901300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nTraining NeuMF on Movies domain:\")\n",
    "movies_train = train_df[train_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "movies_val   = val_df[val_df[\"domain\"]   == \"Movies_and_TV\"]\n",
    "movies_test  = test_df[test_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "\n",
    "n_total_users  = encoded_df[\"user_id\"].max() + 1\n",
    "n_movies_items = encoded_df[encoded_df[\"domain\"] == \"Movies_and_TV\"][\"item_id\"].max() + 1\n",
    "\n",
    "neumf_model = PyTorchNeuMFModel(\n",
    "    factors_gmf=16, factors_mlp=16,\n",
    "    mlp_layers=(64, 32),\n",
    "    dropout=0.3,\n",
    "    use_bias=True,\n",
    "    n_epochs=50,\n",
    "    lr=5e-3,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=1024,\n",
    "    max_grad_norm=5.0,\n",
    "    patience=5\n",
    ")\n",
    "neumf_model.train(movies_train, movies_val, n_total_users, n_movies_items)"
   ],
   "id": "9d8d0a695243131f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NeuMF on Movies domain:\n",
      "\n",
      "🚀 Training NeuMF (ratings regression with sample-weighted MSE)\n",
      "   Device: cuda | GMF:16 | MLP:16 | Layers:(64, 32) | Dropout:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 6/6 [00:00<00:00, 31.90it/s, Train RMSE=1.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train RMSE: 1.0685 | Val RMSE: 1.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 6/6 [00:00<00:00, 35.33it/s, Train RMSE=1.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train RMSE: 1.0167 | Val RMSE: 1.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 6/6 [00:00<00:00, 36.43it/s, Train RMSE=0.8932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train RMSE: 0.8932 | Val RMSE: 1.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 6/6 [00:00<00:00, 38.96it/s, Train RMSE=0.7898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train RMSE: 0.7898 | Val RMSE: 1.0990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 6/6 [00:00<00:00, 37.70it/s, Train RMSE=0.7241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train RMSE: 0.7241 | Val RMSE: 1.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 6/6 [00:00<00:00, 41.46it/s, Train RMSE=0.6882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train RMSE: 0.6882 | Val RMSE: 1.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 6/6 [00:00<00:00, 35.50it/s, Train RMSE=0.6685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train RMSE: 0.6685 | Val RMSE: 1.0710\n",
      "Early stopping at epoch 7. Best Val RMSE: 1.0479\n",
      "✅ Training complete! Best Val RMSE: 1.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:04:11.151189Z",
     "start_time": "2025-08-21T09:04:08.529237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate with your domain-aware metrics (same protocol)\n",
    "neumf_results = evaluate_ranking_metrics(\n",
    "    model=neumf_model,\n",
    "    test_df=movies_test,\n",
    "    all_data_df=encoded_df,\n",
    "    domain=\"Movies_and_TV\",\n",
    "    k=10,\n",
    "    rating_threshold=POSITIVE_THRESHOLD,  # 4.0\n",
    "    n_neg_samples=100,\n",
    "    rng_seed=42,\n",
    "    graded=False\n",
    ")\n",
    "print(neumf_results)"
   ],
   "id": "f927d8212745c042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating Ranking Metrics @k=10 for domain = Movies_and_TV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Ranking Metrics: 100%|██████████| 910/910 [00:02<00:00, 397.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ranking Evaluation Results (domain=Movies_and_TV, k=10) ---\n",
      "   Precision@10: 0.0130\n",
      "   Recall@10:    0.1246\n",
      "   MAP@10:       0.0432\n",
      "   NDCG@10:      0.0627\n",
      "-----------------------------------------\n",
      "{'precision_at_10': 0.013025780189959296, 'recall_at_10': 0.1246042514699231, 'map_at_10': 0.0432475070534772, 'ndcg_at_10': 0.06274462438909985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a8adde6ab794769"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
