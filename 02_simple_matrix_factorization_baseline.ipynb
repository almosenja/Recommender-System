{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T08:02:40.423499Z",
     "start_time": "2025-08-21T08:02:35.392672Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recommenders.datasets.python_splitters import python_chrono_split, python_stratified_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"E:/Python Scripts/recsys\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"E:/Python Scripts/recsys/data\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"E:/Python Scripts/recsys/models\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python Scripts\\recsys\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:02:40.481390Z",
     "start_time": "2025-08-21T08:02:40.433330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ],
   "id": "94437de919542462",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:15.406059Z",
     "start_time": "2025-08-21T08:57:52.585736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select 2 categories to highlight cross-domain transfer\n",
    "SOURCE_DOMAIN = \"Movies_and_TV\"\n",
    "TARGET_DOMAIN = \"Video_Games\"\n",
    "DOMAINS = [SOURCE_DOMAIN, TARGET_DOMAIN]\n",
    "\n",
    "MIN_USER_INTERACTIONS = 10\n",
    "MIN_ITEM_INTERACTIONS = 10\n",
    "POSITIVE_THRESHOLD = 4.0  # Ratings >= 4.0 are considered positive\n",
    "\n",
    "# Load the dataset\n",
    "def load_amazon_reviews(domain:str, max_per_domain:int=100000) -> pd.DataFrame:\n",
    "    dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "                           f\"raw_review_{domain}\",\n",
    "                           trust_remote_code=True)\n",
    "    rows = []\n",
    "    for i, r in enumerate(dataset[\"full\"]):\n",
    "        if i >= max_per_domain:\n",
    "            break\n",
    "        rows.append({\n",
    "            \"user\": r[\"user_id\"],\n",
    "            \"item\": r[\"parent_asin\"],\n",
    "            \"rating\": float(r[\"rating\"]),\n",
    "            \"domain\": domain,\n",
    "            \"verified_purchase\": r[\"verified_purchase\"],\n",
    "            \"timestamp\": int(r[\"timestamp\"])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "dfs = [load_amazon_reviews(dom, max_per_domain=100000) for dom in DOMAINS]\n",
    "df = pd.concat(dfs, ignore_index=True).sort_values(\"timestamp\").reset_index(drop=True)"
   ],
   "id": "dc23bf27622df5e4",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:15.430425Z",
     "start_time": "2025-08-21T08:58:15.421396Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "a86cc08256af864e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           user        item  rating         domain  \\\n",
       "0  AHAYX6YWLK52LPXFSE2QUNMMS44A  0783114222     5.0  Movies_and_TV   \n",
       "1  AG3S4FROO422V5KP7DJCBXVUQLJQ  0800185676     5.0  Movies_and_TV   \n",
       "2  AHVNRIAPM3GVNS3RH3MNIEVSSBNA  6303501281     5.0  Movies_and_TV   \n",
       "3  AHAYX6YWLK52LPXFSE2QUNMMS44A  6300215571     5.0  Movies_and_TV   \n",
       "4  AEKPXGAS7MDLNHMCEZMOOQUOYJLA  6304279485     5.0  Movies_and_TV   \n",
       "\n",
       "   verified_purchase     timestamp  \n",
       "0              False  913069725000  \n",
       "1               True  914267986000  \n",
       "2              False  914297420000  \n",
       "3               True  920170436000  \n",
       "4              False  921529732000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>domain</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHAYX6YWLK52LPXFSE2QUNMMS44A</td>\n",
       "      <td>0783114222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>913069725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AG3S4FROO422V5KP7DJCBXVUQLJQ</td>\n",
       "      <td>0800185676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>True</td>\n",
       "      <td>914267986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHVNRIAPM3GVNS3RH3MNIEVSSBNA</td>\n",
       "      <td>6303501281</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>914297420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHAYX6YWLK52LPXFSE2QUNMMS44A</td>\n",
       "      <td>6300215571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>True</td>\n",
       "      <td>920170436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEKPXGAS7MDLNHMCEZMOOQUOYJLA</td>\n",
       "      <td>6304279485</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>921529732000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:15.534870Z",
     "start_time": "2025-08-21T08:58:15.526646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df, min_user_interactions, min_item_interactions):\n",
    "    df[\"trust_weight\"] = df[\"verified_purchase\"].apply(lambda x: 1.0 if x else 0.8)\n",
    "\n",
    "    # Filtering interactions\n",
    "    user_counts = df[\"user\"].value_counts()\n",
    "    item_counts = df[\"item\"].value_counts()\n",
    "    active_users = user_counts[user_counts >= min_user_interactions].index\n",
    "    active_items = item_counts[item_counts >= min_item_interactions].index\n",
    "    df = df[df[\"user\"].isin(active_users) & df[\"item\"].isin(active_items)].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Final data length: {df.shape[0]}\")\n",
    "    print(f\"Unique users: {df['user'].nunique()}\")\n",
    "    print(f\"Unique items: {df['item'].nunique()}\")\n",
    "\n",
    "    # ensure dtypes\n",
    "    df[\"rating\"] = df[\"rating\"].astype(np.float32)\n",
    "    df[\"trust_weight\"] = df[\"trust_weight\"].astype(np.float32)\n",
    "    return df"
   ],
   "id": "34982c3d5f21dffd",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:15.945410Z",
     "start_time": "2025-08-21T08:58:15.662654Z"
    }
   },
   "cell_type": "code",
   "source": "processed_df = preprocess_data(df, MIN_USER_INTERACTIONS, MIN_ITEM_INTERACTIONS)",
   "id": "6a442b8cbff9256a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data length: 19933\n",
      "Unique users: 3169\n",
      "Unique items: 2567\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:15.974595Z",
     "start_time": "2025-08-21T08:58:15.953415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataEncoder():\n",
    "    def __init__(self):\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.item_encoders = {}  # Store encoders for each domain\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def label_encoder(self, df):\n",
    "        # Encode users (shared across domains)\n",
    "        df[\"user_id\"] = self.user_encoder.fit_transform(df[\"user\"])\n",
    "        print(f\"Encoded {len(self.user_encoder.classes_)} unique users.\")\n",
    "\n",
    "        domains = df[\"domain\"].unique()\n",
    "\n",
    "        # Encode items per domain (items might have same ID in different domains)\n",
    "        df[\"item_id\"] = -1  # Initialize with -1\n",
    "        for domain in domains:\n",
    "            domain_data = df[df[\"domain\"] == domain]\n",
    "            item_encoder = LabelEncoder()\n",
    "            encoded_items = item_encoder.fit_transform(domain_data[\"item\"])\n",
    "            df.loc[df[\"domain\"] == domain, \"item_id\"] = encoded_items\n",
    "            self.item_encoders[domain] = item_encoder\n",
    "\n",
    "            print(f\"Encoded {len(item_encoder.classes_)} unique items in domain '{domain}'.\")\n",
    "\n",
    "        # Convert to integer type\n",
    "        df[\"user_id\"] = df[\"user_id\"].astype(np.int64)\n",
    "        df[\"item_id\"] = df[\"item_id\"].astype(np.int64)\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return df\n",
    "\n",
    "    def transform_new_data(self, df):\n",
    "        # Transform new data using existing encoders. Useful for handling new reviews in production.\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"DataEncoder is not fitted. Call label_encoder() first.\")\n",
    "\n",
    "        # Encode users and items\n",
    "        df[\"user_id\"] = self.user_encoder.transform(df[\"user\"])\n",
    "        df[\"item_id\"] = self.item_encoders[df[\"domain\"]].transform(df[\"item\"])\n",
    "\n",
    "        return df"
   ],
   "id": "6407df1eb08d0650",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.025822Z",
     "start_time": "2025-08-21T08:58:15.983617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = DataEncoder()\n",
    "encoded_df = encoder.label_encoder(processed_df)"
   ],
   "id": "8ce5f1c7e50ee4c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 3169 unique users.\n",
      "Encoded 749 unique items in domain 'Movies_and_TV'.\n",
      "Encoded 1818 unique items in domain 'Video_Games'.\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.046898Z",
     "start_time": "2025-08-21T08:58:16.036836Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_df.head()",
   "id": "b238d471bac0d510",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           user        item  rating         domain  \\\n",
       "0  AHRGTIMQO47C2VLJILIDU53BQKSA  B00005ALS0     4.0  Movies_and_TV   \n",
       "1  AGX4QGDAQZQRII5YUAUAASPRUW3Q  B00000JRSB     5.0    Video_Games   \n",
       "2  AGX4QGDAQZQRII5YUAUAASPRUW3Q  B00004Y57G     5.0    Video_Games   \n",
       "3  AFCCY6D7QLYO3SVKCVFPYUXL6HPA  B00005O3VC     5.0  Movies_and_TV   \n",
       "4  AHVRJMMQMNEWRCZJZ6T5XHMER2PA  B0086VPV86     5.0    Video_Games   \n",
       "\n",
       "   verified_purchase      timestamp  trust_weight  user_id  item_id  \n",
       "0               True   990492274000           1.0     2986        7  \n",
       "1              False   994245315000           0.8     2349        4  \n",
       "2              False   994247742000           0.8     2349        9  \n",
       "3              False   998237072000           0.8     1027        9  \n",
       "4              False  1002634840000           0.8     3081      472  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>domain</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trust_weight</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHRGTIMQO47C2VLJILIDU53BQKSA</td>\n",
       "      <td>B00005ALS0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>True</td>\n",
       "      <td>990492274000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2986</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGX4QGDAQZQRII5YUAUAASPRUW3Q</td>\n",
       "      <td>B00000JRSB</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>994245315000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGX4QGDAQZQRII5YUAUAASPRUW3Q</td>\n",
       "      <td>B00004Y57G</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>994247742000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2349</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFCCY6D7QLYO3SVKCVFPYUXL6HPA</td>\n",
       "      <td>B00005O3VC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>False</td>\n",
       "      <td>998237072000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1027</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHVRJMMQMNEWRCZJZ6T5XHMER2PA</td>\n",
       "      <td>B0086VPV86</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>False</td>\n",
       "      <td>1002634840000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3081</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.080958Z",
     "start_time": "2025-08-21T08:58:16.074887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mean_rating = encoded_df[\"rating\"].mean()\n",
    "# encoded_df[\"rating\"] = encoded_df[\"rating\"] - mean_rating\n",
    "\n",
    "def create_data_splits(df, train_size=0.8):\n",
    "    train, temp = python_chrono_split(\n",
    "        df, ratio=train_size, filter_by=\"user\",\n",
    "        col_user=\"user_id\", col_item=\"item_id\", col_timestamp=\"timestamp\"\n",
    "    )\n",
    "\n",
    "    val, test = python_stratified_split(\n",
    "        temp, ratio=0.5, filter_by=\"user\",\n",
    "        col_user=\"user_id\", col_item=\"item_id\"\n",
    "    )\n",
    "\n",
    "    print(f\"Train set size: {train.shape[0]}\")\n",
    "    print(f\"Validation set size: {val.shape[0]}\")\n",
    "    print(f\"Test set size: {test.shape[0]}\")\n",
    "    print(f\"Common users in train and val: {len(set(train['user_id']).intersection(set(val['user_id'])))}\")\n",
    "    print(f\"Common users in train and test: {len(set(train['user_id']).intersection(set(test['user_id'])))}\")\n",
    "\n",
    "    return train, val, test"
   ],
   "id": "9e05a880ab9d772a",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.176447Z",
     "start_time": "2025-08-21T08:58:16.130813Z"
    }
   },
   "cell_type": "code",
   "source": "train_df, val_df, test_df = create_data_splits(encoded_df)",
   "id": "71bb93fd37c13f90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 16052\n",
      "Validation set size: 1286\n",
      "Test set size: 2595\n",
      "Common users in train and val: 890\n",
      "Common users in train and test: 2323\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.417730Z",
     "start_time": "2025-08-21T08:58:16.411949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_interaction_matrix(df, n_users=None, n_items=None):\n",
    "    if n_users is None:\n",
    "        n_users = df[\"user_id\"].nunique()\n",
    "    if n_items is None:\n",
    "        n_items = df[\"item_id\"].nunique()\n",
    "\n",
    "    # Create a sparse matrix for interactions\n",
    "    row = df[\"user_id\"].values\n",
    "    col = df[\"item_id\"].values\n",
    "    data = df[\"rating\"].values\n",
    "    interaction_matrix = csr_matrix((data, (row, col)), shape=(n_users, n_items))\n",
    "    density = interaction_matrix.nnz / (interaction_matrix.shape[0] * interaction_matrix.shape[1])\n",
    "\n",
    "    print(f\"Shape: {interaction_matrix.shape} (users x items)\")\n",
    "    print(f\"Non-zero entries: {interaction_matrix.nnz}\")\n",
    "    print(f\"Density: {density:.4f}\")\n",
    "\n",
    "    return interaction_matrix"
   ],
   "id": "6343ccf277802d3e",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.470651Z",
     "start_time": "2025-08-21T08:58:16.459465Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_df[\"user_id\"].max() + 1",
   "id": "ef134543745818fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3169)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.510107Z",
     "start_time": "2025-08-21T08:58:16.501683Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_df[\"user_id\"].nunique()",
   "id": "3af5de044ff0451c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.547079Z",
     "start_time": "2025-08-21T08:58:16.533815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "domain_df = train_df[train_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "domain_df[\"item_id\"].nunique()"
   ],
   "id": "8fdba24c1f23d2f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.583682Z",
     "start_time": "2025-08-21T08:58:16.578058Z"
    }
   },
   "cell_type": "code",
   "source": "domain_df[\"item_id\"].max() + 1",
   "id": "8faa74f17eb477ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(749)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.641237Z",
     "start_time": "2025-08-21T08:58:16.622693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "domains = encoded_df[\"domain\"].unique()\n",
    "interaction_matrices = {}\n",
    "\n",
    "for domain in domains:\n",
    "    print(f\"\\n{domain} domain interaction matrix:\")\n",
    "    domain_df = train_df[train_df[\"domain\"] == domain]\n",
    "\n",
    "    n_users = encoded_df[\"user_id\"].max() + 1\n",
    "    n_items = domain_df[\"item_id\"].max() + 1\n",
    "    interaction_matrix = create_interaction_matrix(domain_df, n_users, n_items)\n",
    "    interaction_matrices[domain] = interaction_matrix"
   ],
   "id": "28ed85fba3ad4398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies_and_TV domain interaction matrix:\n",
      "Shape: (3169, 749) (users x items)\n",
      "Non-zero entries: 5613\n",
      "Density: 0.0024\n",
      "\n",
      "Video_Games domain interaction matrix:\n",
      "Shape: (3169, 1818) (users x items)\n",
      "Non-zero entries: 10142\n",
      "Density: 0.0018\n"
     ]
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.657452Z",
     "start_time": "2025-08-21T08:58:16.652236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleMFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(df[\"item_id\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "        self.weights = torch.tensor(df[\"trust_weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx], self.weights[idx]"
   ],
   "id": "84e599757e1bfe8e",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.671900Z",
     "start_time": "2025-08-21T08:58:16.665481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleMatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        # nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        # nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        # init\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.05)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.05)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        dot_product = (user_embeds * item_embeds).sum(dim=1, keepdim=True)\n",
    "        out = dot_product + self.user_bias(user_ids) + self.item_bias(item_ids) + self.global_bias\n",
    "        return out.squeeze(1)\n",
    "\n",
    "    # def forward(self, user_ids, item_ids):\n",
    "    #     user_embeds = self.user_embedding(user_ids)\n",
    "    #     item_embeds = self.item_embedding(item_ids)\n",
    "    #     dot_product = (user_embeds * item_embeds).sum(dim=1)\n",
    "    #     return dot_product  # No bias terms for simplicity"
   ],
   "id": "f05da9d88669837f",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.690542Z",
     "start_time": "2025-08-21T08:58:16.675917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PyTorchMFModel:\n",
    "    def __init__(self,\n",
    "                 n_embeddings=64,\n",
    "                 n_epochs=10,\n",
    "                 lr=0.005,\n",
    "                 weight_decay=1e-5,\n",
    "                 batch_size=1024):\n",
    "        self.n_factors = n_embeddings\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, train_df, val_df, n_users, n_items):\n",
    "        print(f\"\\nðŸš€ Training PyTorch Matrix Factorization Model...\")\n",
    "        print(f\"   Device: {DEVICE}\")\n",
    "        print(f\"   Factors: {self.n_factors}, Epochs: {self.n_epochs}, LR: {self.lr}\")\n",
    "\n",
    "        train_loader = DataLoader(SimpleMFDataset(train_df), batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        val_loader   = DataLoader(SimpleMFDataset(val_df),   batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        self.model = SimpleMatrixFactorization(n_users, n_items, self.n_factors).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-5\n",
    "        )\n",
    "\n",
    "        best_val_rmse, best_state = float(\"inf\"), None\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # ---- train ----\n",
    "            self.model.train()\n",
    "            se_sum, denom = 0.0, 0.0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.n_epochs}\")\n",
    "            for users, items, ratings, weights in pbar:\n",
    "                users = users.to(DEVICE); items = items.to(DEVICE)\n",
    "                ratings = ratings.to(DEVICE); weights = weights.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.model(users, items)\n",
    "\n",
    "                # sample-weighted MSE on true rating\n",
    "                se = (preds - ratings) ** 2\n",
    "                loss = (weights * se).sum() / (weights.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                se_sum += se.detach().sum().item()\n",
    "                denom += ratings.numel()\n",
    "                pbar.set_postfix({\"Train RMSE\": f\"{math.sqrt(se_sum/denom):.4f}\"})\n",
    "\n",
    "            train_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "\n",
    "            # ---- validate ----\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                se_sum, denom = 0.0, 0.0\n",
    "                for users, items, ratings, _ in val_loader:\n",
    "                    users = users.to(DEVICE); items = items.to(DEVICE); ratings = ratings.to(DEVICE)\n",
    "                    preds = self.model(users, items)\n",
    "                    se_sum += torch.sum((preds - ratings) ** 2).item()\n",
    "                    denom += ratings.numel()\n",
    "            val_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "            scheduler.step(val_rmse)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} - Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            # track best\n",
    "            if val_rmse < best_val_rmse - 1e-4:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_state = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
    "        print(\"âœ… Training complete! Best Val RMSE:\", f\"{best_val_rmse:.4f}\")\n",
    "\n",
    "    def predict_dataframe(self, df):\n",
    "        \"\"\"df must contain columns: user_id, item_id\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        self.model.eval()\n",
    "\n",
    "        users = torch.tensor(df[\"user_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "        items = torch.tensor(df[\"item_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(df), self.batch_size):\n",
    "                pu = users[i:i+self.batch_size]\n",
    "                pi = items[i:i+self.batch_size]\n",
    "                p = self.model(pu, pi)\n",
    "                preds.append(p.detach().cpu().numpy())\n",
    "        return np.concatenate(preds)"
   ],
   "id": "a64242876a2fc1e1",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:58:16.711211Z",
     "start_time": "2025-08-21T08:58:16.695552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dcg_at_k(relevances, k):\n",
    "    \"\"\"relevances: list/array of true gains ordered by the *predicted* rank.\"\"\"\n",
    "    r = np.asarray(relevances)[:k]\n",
    "    if r.size == 0:\n",
    "        return 0.0\n",
    "    discounts = 1.0 / np.log2(np.arange(2, r.size + 2))\n",
    "    return float(np.sum(r * discounts))\n",
    "\n",
    "def ndcg_at_k(predicted_items, true_rel_map, k):\n",
    "    \"\"\"\n",
    "    predicted_items: list of item_ids sorted by predicted score (desc).\n",
    "    true_rel_map   : dict {item_id -> gain}. Items not present => 0 gain.\n",
    "    \"\"\"\n",
    "    # gains at predicted order\n",
    "    gains = [true_rel_map.get(i, 0.0) for i in predicted_items[:k]]\n",
    "    dcg = dcg_at_k(gains, k)\n",
    "\n",
    "    # ideal gains: sort all candidate items by their true gain desc\n",
    "    ideal_gains = sorted(true_rel_map.values(), reverse=True)\n",
    "    idcg = dcg_at_k(ideal_gains, k)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_ranking_metrics(\n",
    "    model,\n",
    "    test_df,\n",
    "    all_data_df,\n",
    "    domain: str,\n",
    "    k=10,\n",
    "    rating_threshold=4.0,\n",
    "    n_neg_samples=100,\n",
    "    rng_seed=42,\n",
    "    graded=False  # <- set True if you want graded gains\n",
    "):\n",
    "    \"\"\"\n",
    "    Domain-aware Precision@k, Recall@k, MAP@k, NDCG@k.\n",
    "    - Binary relevance by default: rating >= threshold -> 1, else 0\n",
    "    - Graded relevance (optional): gain = max(rating - (threshold - 1), 0)\n",
    "      e.g., threshold=4.0 => 4â˜…->1, 5â˜…->2, else 0\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Evaluating Ranking Metrics @k={k} for domain = {domain}\")\n",
    "    rs = np.random.RandomState(rng_seed)\n",
    "\n",
    "    # filter to target domain\n",
    "    test_dom = test_df[test_df[\"domain\"] == domain].copy()\n",
    "    hist_dom = all_data_df[all_data_df[\"domain\"] == domain].copy()\n",
    "\n",
    "    if test_dom.empty:\n",
    "        print(\"No test rows for this domain. Skipping.\")\n",
    "        return {\n",
    "            f'precision_at_{k}': 0.0,\n",
    "            f'recall_at_{k}': 0.0,\n",
    "            f'map_at_{k}': 0.0,\n",
    "            f'ndcg_at_{k}': 0.0\n",
    "        }\n",
    "\n",
    "    # candidate pool in this domain\n",
    "    domain_items = np.unique(hist_dom[\"item_id\"].values)\n",
    "    # seen items per user in this domain\n",
    "    seen_by_user = hist_dom.groupby(\"user_id\")[\"item_id\"].apply(set)\n",
    "\n",
    "    precisions, recalls, aps, ndcgs = [], [], [], []\n",
    "\n",
    "    for user_id, g in tqdm(test_dom.groupby(\"user_id\"), desc=\"Calculating Ranking Metrics\"):\n",
    "        # --- build relevance map for this user's test items ---\n",
    "        if graded:\n",
    "            # graded gains: only >= threshold contribute, and graded by how far above threshold\n",
    "            rel_map = {\n",
    "                iid: max(float(r) - (rating_threshold - 1.0), 0.0)\n",
    "                for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)\n",
    "            }\n",
    "        else:\n",
    "            # binary gains\n",
    "            rel_map = {\n",
    "                iid: 1.0 if (float(r) >= rating_threshold) else 0.0\n",
    "                for iid, r in zip(g[\"item_id\"].values, g[\"rating\"].values)\n",
    "            }\n",
    "        # positive (nonzero) items\n",
    "        rel_items = {iid for iid, gain in rel_map.items() if gain > 0.0}\n",
    "        if not rel_items:\n",
    "            continue  # skip users with no relevant items in test\n",
    "\n",
    "        seen = seen_by_user.get(user_id, set())\n",
    "        negatives = np.array(list(set(domain_items) - seen))\n",
    "        if negatives.size == 0:\n",
    "            continue\n",
    "\n",
    "        m = min(n_neg_samples, negatives.size)\n",
    "        neg_samples = rs.choice(negatives, size=m, replace=False)\n",
    "\n",
    "        # candidate set = relevant test items + sampled negatives\n",
    "        items_to_rank = np.array(list(rel_map.keys()))\n",
    "        items_to_rank = np.concatenate([items_to_rank, neg_samples])\n",
    "\n",
    "        pred_df = pd.DataFrame({\"user_id\": user_id, \"item_id\": items_to_rank})\n",
    "        pred_df[\"score\"] = model.predict_dataframe(pred_df)\n",
    "        pred_df = pred_df.sort_values(\"score\", ascending=False)\n",
    "        top_k = pred_df[\"item_id\"].values[:k]\n",
    "\n",
    "        # --- Precision@k / Recall@k ---\n",
    "        hit_set = set(top_k).intersection(rel_items)\n",
    "        precisions.append(len(hit_set) / k)\n",
    "        recalls.append(len(hit_set) / len(rel_items))\n",
    "\n",
    "        # --- MAP@k ---\n",
    "        ap, hits = 0.0, 0\n",
    "        for rank, item in enumerate(top_k, start=1):\n",
    "            if item in rel_items:\n",
    "                hits += 1\n",
    "                ap += hits / rank\n",
    "        aps.append(ap / len(rel_items))\n",
    "\n",
    "        # --- NDCG@k ---\n",
    "        ndcgs.append(ndcg_at_k(top_k.tolist(), rel_map, k))\n",
    "\n",
    "    out = {\n",
    "        f\"precision_at_{k}\": float(np.mean(precisions)) if precisions else 0.0,\n",
    "        f\"recall_at_{k}\":    float(np.mean(recalls))    if recalls    else 0.0,\n",
    "        f\"map_at_{k}\":       float(np.mean(aps))        if aps        else 0.0,\n",
    "        f\"ndcg_at_{k}\":      float(np.mean(ndcgs))      if ndcgs      else 0.0,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n--- Ranking Evaluation Results (domain={domain}, k={k}) ---\")\n",
    "    print(f\"   Precision@{k}: {out[f'precision_at_{k}']:.4f}\")\n",
    "    print(f\"   Recall@{k}:    {out[f'recall_at_{k}']:.4f}\")\n",
    "    print(f\"   MAP@{k}:       {out[f'map_at_{k}']:.4f}\")\n",
    "    print(f\"   NDCG@{k}:      {out[f'ndcg_at_{k}']:.4f}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    return out"
   ],
   "id": "105e0ebef5eabf71",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:59:53.257586Z",
     "start_time": "2025-08-21T08:59:45.907604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Training the PyTorch Model ---\n",
    "print(\"\\nTraining PyTorch Matrix Factorization on Movies domain:\")\n",
    "movies_train = train_df[train_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "movies_val   = val_df[val_df[\"domain\"]   == \"Movies_and_TV\"]\n",
    "movies_test  = test_df[test_df[\"domain\"] == \"Movies_and_TV\"]  # use test set for final eval\n",
    "\n",
    "n_total_users   = encoded_df[\"user_id\"].max() + 1\n",
    "n_movies_items  = encoded_df[encoded_df[\"domain\"] == \"Movies_and_TV\"][\"item_id\"].max() + 1\n",
    "\n",
    "mf_torch_model = PyTorchMFModel(n_embeddings=8, n_epochs=50, lr=0.05, weight_decay=5e-3, batch_size=1024)\n",
    "mf_torch_model.train(movies_train, movies_val, n_total_users, n_movies_items)"
   ],
   "id": "83b223c7259932fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training PyTorch Matrix Factorization on Movies domain:\n",
      "\n",
      "ðŸš€ Training PyTorch Matrix Factorization Model...\n",
      "   Device: cuda\n",
      "   Factors: 8, Epochs: 50, LR: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 46.67it/s, Train RMSE=4.2143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train RMSE: 4.2143, Val RMSE: 3.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 48.50it/s, Train RMSE=3.5086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train RMSE: 3.5086, Val RMSE: 3.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 15.81it/s, Train RMSE=2.8652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train RMSE: 2.8652, Val RMSE: 2.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 47.46it/s, Train RMSE=2.3070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train RMSE: 2.3070, Val RMSE: 1.9514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.46it/s, Train RMSE=1.8786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train RMSE: 1.8786, Val RMSE: 1.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.01it/s, Train RMSE=1.6232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train RMSE: 1.6232, Val RMSE: 1.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 58.67it/s, Train RMSE=1.4910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train RMSE: 1.4910, Val RMSE: 1.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.16it/s, Train RMSE=1.4170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train RMSE: 1.4170, Val RMSE: 1.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 47.09it/s, Train RMSE=1.3629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train RMSE: 1.3629, Val RMSE: 1.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.38it/s, Train RMSE=1.3214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train RMSE: 1.3214, Val RMSE: 1.3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.58it/s, Train RMSE=1.2882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train RMSE: 1.2882, Val RMSE: 1.2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 42.59it/s, Train RMSE=1.2577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train RMSE: 1.2577, Val RMSE: 1.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 60.22it/s, Train RMSE=1.2268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train RMSE: 1.2268, Val RMSE: 1.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 53.57it/s, Train RMSE=1.1927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train RMSE: 1.1927, Val RMSE: 1.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 53.08it/s, Train RMSE=1.1592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train RMSE: 1.1592, Val RMSE: 1.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 48.01it/s, Train RMSE=1.1265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Train RMSE: 1.1265, Val RMSE: 1.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 17.27it/s, Train RMSE=1.0965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Train RMSE: 1.0965, Val RMSE: 1.1556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 41.00it/s, Train RMSE=1.0695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Train RMSE: 1.0695, Val RMSE: 1.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 54.42it/s, Train RMSE=1.0462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Train RMSE: 1.0462, Val RMSE: 1.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 57.78it/s, Train RMSE=1.0258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train RMSE: 1.0258, Val RMSE: 1.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 54.51it/s, Train RMSE=1.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Train RMSE: 1.0085, Val RMSE: 1.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 57.54it/s, Train RMSE=0.9933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Train RMSE: 0.9933, Val RMSE: 1.0839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 57.30it/s, Train RMSE=0.9798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Train RMSE: 0.9798, Val RMSE: 1.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 57.39it/s, Train RMSE=0.9683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Train RMSE: 0.9683, Val RMSE: 1.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 60.62it/s, Train RMSE=0.9581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Train RMSE: 0.9581, Val RMSE: 1.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 49.67it/s, Train RMSE=0.9495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Train RMSE: 0.9495, Val RMSE: 1.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.28it/s, Train RMSE=0.9417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Train RMSE: 0.9417, Val RMSE: 1.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.06it/s, Train RMSE=0.9360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Train RMSE: 0.9360, Val RMSE: 1.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.38it/s, Train RMSE=0.9315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Train RMSE: 0.9315, Val RMSE: 1.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 50.33it/s, Train RMSE=0.9279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Train RMSE: 0.9279, Val RMSE: 1.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 16.78it/s, Train RMSE=0.9248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Train RMSE: 0.9248, Val RMSE: 1.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 41.49it/s, Train RMSE=0.9220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Train RMSE: 0.9220, Val RMSE: 1.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 51.57it/s, Train RMSE=0.9198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Train RMSE: 0.9198, Val RMSE: 1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 55.41it/s, Train RMSE=0.9183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Train RMSE: 0.9183, Val RMSE: 1.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 51.57it/s, Train RMSE=0.9169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Train RMSE: 0.9169, Val RMSE: 1.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.08it/s, Train RMSE=0.9159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Train RMSE: 0.9159, Val RMSE: 1.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 52.31it/s, Train RMSE=0.9152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Train RMSE: 0.9152, Val RMSE: 1.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.72it/s, Train RMSE=0.9143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Train RMSE: 0.9143, Val RMSE: 1.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 56.80it/s, Train RMSE=0.9116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Train RMSE: 0.9116, Val RMSE: 1.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 54.32it/s, Train RMSE=0.9113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Train RMSE: 0.9113, Val RMSE: 1.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 49.56it/s, Train RMSE=0.9114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Train RMSE: 0.9114, Val RMSE: 1.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 44.85it/s, Train RMSE=0.9102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Train RMSE: 0.9102, Val RMSE: 1.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 52.24it/s, Train RMSE=0.9102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Train RMSE: 0.9102, Val RMSE: 1.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 36.15it/s, Train RMSE=0.9101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Train RMSE: 0.9101, Val RMSE: 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 17.01it/s, Train RMSE=0.9094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Train RMSE: 0.9094, Val RMSE: 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 51.56it/s, Train RMSE=0.9094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Train RMSE: 0.9094, Val RMSE: 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 54.37it/s, Train RMSE=0.9093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Train RMSE: 0.9093, Val RMSE: 1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 54.74it/s, Train RMSE=0.9090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Train RMSE: 0.9090, Val RMSE: 1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 52.75it/s, Train RMSE=0.9090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train RMSE: 0.9090, Val RMSE: 1.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 47.68it/s, Train RMSE=0.9089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train RMSE: 0.9089, Val RMSE: 1.0413\n",
      "âœ… Training complete! Best Val RMSE: 1.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:00:01.235361Z",
     "start_time": "2025-08-21T08:59:59.010623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ranking_results = evaluate_ranking_metrics(\n",
    "    model=mf_torch_model,\n",
    "    test_df=movies_test,\n",
    "    all_data_df=encoded_df,\n",
    "    domain=\"Movies_and_TV\",\n",
    "    k=10,\n",
    "    rating_threshold=POSITIVE_THRESHOLD,  # 4.0\n",
    "    n_neg_samples=100\n",
    ")"
   ],
   "id": "fda6a9f4b6346554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluating Ranking Metrics @k=10 for domain = Movies_and_TV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Ranking Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [00:02<00:00, 419.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ranking Evaluation Results (domain=Movies_and_TV, k=10) ---\n",
      "   Precision@10: 0.0148\n",
      "   Recall@10:    0.1404\n",
      "   MAP@10:       0.0617\n",
      "   NDCG@10:      0.0805\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:00:06.397171Z",
     "start_time": "2025-08-21T09:00:06.384152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items: int,\n",
    "        factors_gmf: int = 32,\n",
    "        factors_mlp: int = 32,\n",
    "        mlp_layers=(128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        use_bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # GMF embeddings\n",
    "        self.gmf_user = nn.Embedding(n_users, factors_gmf)\n",
    "        self.gmf_item = nn.Embedding(n_items, factors_gmf)\n",
    "        # MLP embeddings\n",
    "        self.mlp_user = nn.Embedding(n_users, factors_mlp)\n",
    "        self.mlp_item = nn.Embedding(n_items, factors_mlp)\n",
    "\n",
    "        # MLP tower\n",
    "        in_dim = factors_mlp * 2\n",
    "        mlp = []\n",
    "        for h in mlp_layers:\n",
    "            mlp += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            in_dim = h\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "\n",
    "        # Prediction layer over [GMF âŠ• MLP]\n",
    "        pred_in = factors_gmf + (mlp_layers[-1] if len(mlp_layers) > 0 else factors_mlp * 2)\n",
    "        self.pred = nn.Linear(pred_in, 1)\n",
    "\n",
    "        # Optional biases + global mean (helpful for ratings)\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.user_bias = nn.Embedding(n_users, 1)\n",
    "            self.item_bias = nn.Embedding(n_items, 1)\n",
    "        else:\n",
    "            self.user_bias = None\n",
    "            self.item_bias = None\n",
    "        self.global_mean = nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "        # init\n",
    "        for emb in [self.gmf_user, self.gmf_item, self.mlp_user, self.mlp_item]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.pred.weight); nn.init.zeros_(self.pred.bias)\n",
    "        if self.use_bias:\n",
    "            nn.init.zeros_(self.user_bias.weight); nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        gmf = self.gmf_user(users) * self.gmf_item(items)  # elementwise product\n",
    "        mlp_in = torch.cat([self.mlp_user(users), self.mlp_item(items)], dim=1)\n",
    "        mlp_out = self.mlp(mlp_in)\n",
    "        x = torch.cat([gmf, mlp_out], dim=1)\n",
    "        y = self.pred(x).squeeze(1)\n",
    "        if self.use_bias:\n",
    "            y = y + self.user_bias(users).squeeze(1) + self.item_bias(items).squeeze(1) + self.global_mean\n",
    "        return y"
   ],
   "id": "4cb6e3c4ebae7a93",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:00:07.966756Z",
     "start_time": "2025-08-21T09:00:07.944122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class PyTorchNeuMFModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        factors_gmf=32,\n",
    "        factors_mlp=32,\n",
    "        mlp_layers=(128, 64, 32),\n",
    "        dropout=0.2,\n",
    "        use_bias=True,\n",
    "        n_epochs=30,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        batch_size=1024,\n",
    "        max_grad_norm=5.0,\n",
    "        patience=4,  # for ReduceLROnPlateau-driven convergence\n",
    "    ):\n",
    "        self.factors_gmf = factors_gmf\n",
    "        self.factors_mlp = factors_mlp\n",
    "        self.mlp_layers = mlp_layers\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.patience = patience\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, train_df, val_df, n_users, n_items):\n",
    "        print(\"\\nðŸš€ Training NeuMF (ratings regression with sample-weighted MSE)\")\n",
    "        print(f\"   Device: {DEVICE} | GMF:{self.factors_gmf} | MLP:{self.factors_mlp} \"\n",
    "              f\"| Layers:{self.mlp_layers} | Dropout:{self.dropout}\")\n",
    "\n",
    "        train_loader = DataLoader(SimpleMFDataset(train_df), batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(SimpleMFDataset(val_df),   batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.model = NeuMF(\n",
    "            n_users, n_items,\n",
    "            factors_gmf=self.factors_gmf,\n",
    "            factors_mlp=self.factors_mlp,\n",
    "            mlp_layers=self.mlp_layers,\n",
    "            dropout=self.dropout,\n",
    "            use_bias=self.use_bias\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # set global mean from train ratings\n",
    "        self.model.global_mean.data.fill_(float(train_df[\"rating\"].mean()))\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-5\n",
    "        )\n",
    "\n",
    "        best_val_rmse = float(\"inf\")\n",
    "        best_state = None\n",
    "        bad_epochs = 0\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # -------- train --------\n",
    "            self.model.train()\n",
    "            se_sum, denom = 0.0, 0.0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{self.n_epochs}\")\n",
    "            for users, items, ratings, weights in pbar:\n",
    "                users = users.to(DEVICE); items = items.to(DEVICE)\n",
    "                ratings = ratings.to(DEVICE); weights = weights.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.model(users, items)\n",
    "\n",
    "                se = (preds - ratings) ** 2\n",
    "                loss = (weights * se).sum() / (weights.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "\n",
    "                if self.max_grad_norm is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                se_sum += se.detach().sum().item()\n",
    "                denom += ratings.numel()\n",
    "                pbar.set_postfix({\"Train RMSE\": f\"{math.sqrt(se_sum/denom):.4f}\"})\n",
    "\n",
    "            train_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "\n",
    "            # -------- validate --------\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                se_sum, denom = 0.0, 0.0\n",
    "                for users, items, ratings, _ in val_loader:\n",
    "                    users = users.to(DEVICE); items = items.to(DEVICE); ratings = ratings.to(DEVICE)\n",
    "                    preds = self.model(users, items)\n",
    "                    se_sum += torch.sum((preds - ratings) ** 2).item()\n",
    "                    denom += ratings.numel()\n",
    "            val_rmse = math.sqrt(se_sum / max(1, denom))\n",
    "            scheduler.step(val_rmse)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} - Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            # early-stop restore\n",
    "            if val_rmse < best_val_rmse - 1e-4:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_state = {k: v.detach().cpu() for k, v in self.model.state_dict().items()}\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                bad_epochs += 1\n",
    "                if bad_epochs >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}. Best Val RMSE: {best_val_rmse:.4f}\")\n",
    "                    break\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
    "        print(\"âœ… Training complete! Best Val RMSE:\", f\"{best_val_rmse:.4f}\")\n",
    "\n",
    "    def predict_dataframe(self, df):\n",
    "        \"\"\"df must have user_id, item_id\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        self.model.eval()\n",
    "\n",
    "        users = torch.tensor(df[\"user_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "        items = torch.tensor(df[\"item_id\"].values, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(df), self.batch_size):\n",
    "                pu = users[i:i+self.batch_size]\n",
    "                pi = items[i:i+self.batch_size]\n",
    "                p = self.model(pu, pi)\n",
    "                preds.append(p.detach().cpu().numpy())\n",
    "        return np.concatenate(preds)"
   ],
   "id": "60811f9afd64ab3",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:04:07.186476Z",
     "start_time": "2025-08-21T09:04:05.901300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nTraining NeuMF on Movies domain:\")\n",
    "movies_train = train_df[train_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "movies_val   = val_df[val_df[\"domain\"]   == \"Movies_and_TV\"]\n",
    "movies_test  = test_df[test_df[\"domain\"] == \"Movies_and_TV\"]\n",
    "\n",
    "n_total_users  = encoded_df[\"user_id\"].max() + 1\n",
    "n_movies_items = encoded_df[encoded_df[\"domain\"] == \"Movies_and_TV\"][\"item_id\"].max() + 1\n",
    "\n",
    "neumf_model = PyTorchNeuMFModel(\n",
    "    factors_gmf=16, factors_mlp=16,\n",
    "    mlp_layers=(64, 32),\n",
    "    dropout=0.3,\n",
    "    use_bias=True,\n",
    "    n_epochs=50,\n",
    "    lr=5e-3,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=1024,\n",
    "    max_grad_norm=5.0,\n",
    "    patience=5\n",
    ")\n",
    "neumf_model.train(movies_train, movies_val, n_total_users, n_movies_items)"
   ],
   "id": "9d8d0a695243131f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NeuMF on Movies domain:\n",
      "\n",
      "ðŸš€ Training NeuMF (ratings regression with sample-weighted MSE)\n",
      "   Device: cuda | GMF:16 | MLP:16 | Layers:(64, 32) | Dropout:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 31.90it/s, Train RMSE=1.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train RMSE: 1.0685 | Val RMSE: 1.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 35.33it/s, Train RMSE=1.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train RMSE: 1.0167 | Val RMSE: 1.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 36.43it/s, Train RMSE=0.8932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train RMSE: 0.8932 | Val RMSE: 1.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 38.96it/s, Train RMSE=0.7898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train RMSE: 0.7898 | Val RMSE: 1.0990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 37.70it/s, Train RMSE=0.7241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train RMSE: 0.7241 | Val RMSE: 1.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 41.46it/s, Train RMSE=0.6882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train RMSE: 0.6882 | Val RMSE: 1.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 35.50it/s, Train RMSE=0.6685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train RMSE: 0.6685 | Val RMSE: 1.0710\n",
      "Early stopping at epoch 7. Best Val RMSE: 1.0479\n",
      "âœ… Training complete! Best Val RMSE: 1.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:04:11.151189Z",
     "start_time": "2025-08-21T09:04:08.529237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate with your domain-aware metrics (same protocol)\n",
    "neumf_results = evaluate_ranking_metrics(\n",
    "    model=neumf_model,\n",
    "    test_df=movies_test,\n",
    "    all_data_df=encoded_df,\n",
    "    domain=\"Movies_and_TV\",\n",
    "    k=10,\n",
    "    rating_threshold=POSITIVE_THRESHOLD,  # 4.0\n",
    "    n_neg_samples=100,\n",
    "    rng_seed=42,\n",
    "    graded=False\n",
    ")\n",
    "print(neumf_results)"
   ],
   "id": "f927d8212745c042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluating Ranking Metrics @k=10 for domain = Movies_and_TV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Ranking Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [00:02<00:00, 397.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ranking Evaluation Results (domain=Movies_and_TV, k=10) ---\n",
      "   Precision@10: 0.0130\n",
      "   Recall@10:    0.1246\n",
      "   MAP@10:       0.0432\n",
      "   NDCG@10:      0.0627\n",
      "-----------------------------------------\n",
      "{'precision_at_10': 0.013025780189959296, 'recall_at_10': 0.1246042514699231, 'map_at_10': 0.0432475070534772, 'ndcg_at_10': 0.06274462438909985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a8adde6ab794769"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
