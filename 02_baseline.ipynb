{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Baseline Recommender System\n",
    "This notebook implements a simple baseline which is content-based cosine similarity."
   ],
   "id": "7c822c18c3c50055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:37:23.552264Z",
     "start_time": "2025-08-18T15:37:22.640465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "5a6345db3eba7a39",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T14:57:17.854678Z",
     "start_time": "2025-08-18T14:57:17.806886Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"",
   "id": "2a1356b479a71c7c",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T13:37:14.948263Z",
     "start_time": "2025-08-18T13:37:14.673202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing processed dataset\n",
    "df = pd.read_csv(\"data/amazon_reviews_2023/amazon_reviews_2023_filtered.csv\")\n",
    "df.head()"
   ],
   "id": "c2f3a4c83817f559",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           user        item  rating  \\\n",
       "0  AGWDYYVVWM3DC3CASUZKXK67G6IA  0394800796     5.0   \n",
       "1  AF4KRDA6XVQE357OWPILTPXV7TSA  0805047905     5.0   \n",
       "2  AF4KRDA6XVQE357OWPILTPXV7TSA  0307120007     4.0   \n",
       "3  AHRGTIMQO47C2VLJILIDU53BQKSA  B00005ALS0     4.0   \n",
       "4  AEBTXSUFLRBUQXLA4RPUU7DJ7WPQ  B004O4C0G0     1.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  A grouchy Grinch turns loveable and reveals a ...   \n",
       "1                               Fun for mom AND baby   \n",
       "2                                   Kid loves it...I   \n",
       "3             It's a dog-eat-dog world out there ...   \n",
       "4                             What's with the BUGS??   \n",
       "\n",
       "                                                text         domain  \\\n",
       "0  When the Grinch looks down on Whoville from hi...          Books   \n",
       "1  ...The large colorful pictures are great (albe...          Books   \n",
       "2  My 15 month old son has enjoyed this book for ...          Books   \n",
       "3  ... and Christopher Guest manages to find the ...  Movies_and_TV   \n",
       "4  10-15 minutes in the game and it FREEZES(crash...    Video_Games   \n",
       "\n",
       "      timestamp  label  user_id  item_id  domain_id  \n",
       "0  974942691000      1     3154       58          0  \n",
       "1  989349077000      1     1196      167          0  \n",
       "2  989349159000      1     1196       22          0  \n",
       "3  990492274000      1     4054      397          1  \n",
       "4  992873810000      0      272     1230          2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>domain_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGWDYYVVWM3DC3CASUZKXK67G6IA</td>\n",
       "      <td>0394800796</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A grouchy Grinch turns loveable and reveals a ...</td>\n",
       "      <td>When the Grinch looks down on Whoville from hi...</td>\n",
       "      <td>Books</td>\n",
       "      <td>974942691000</td>\n",
       "      <td>1</td>\n",
       "      <td>3154</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF4KRDA6XVQE357OWPILTPXV7TSA</td>\n",
       "      <td>0805047905</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fun for mom AND baby</td>\n",
       "      <td>...The large colorful pictures are great (albe...</td>\n",
       "      <td>Books</td>\n",
       "      <td>989349077000</td>\n",
       "      <td>1</td>\n",
       "      <td>1196</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF4KRDA6XVQE357OWPILTPXV7TSA</td>\n",
       "      <td>0307120007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Kid loves it...I</td>\n",
       "      <td>My 15 month old son has enjoyed this book for ...</td>\n",
       "      <td>Books</td>\n",
       "      <td>989349159000</td>\n",
       "      <td>1</td>\n",
       "      <td>1196</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHRGTIMQO47C2VLJILIDU53BQKSA</td>\n",
       "      <td>B00005ALS0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a dog-eat-dog world out there ...</td>\n",
       "      <td>... and Christopher Guest manages to find the ...</td>\n",
       "      <td>Movies_and_TV</td>\n",
       "      <td>990492274000</td>\n",
       "      <td>1</td>\n",
       "      <td>4054</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEBTXSUFLRBUQXLA4RPUU7DJ7WPQ</td>\n",
       "      <td>B004O4C0G0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What's with the BUGS??</td>\n",
       "      <td>10-15 minutes in the game and it FREEZES(crash...</td>\n",
       "      <td>Video_Games</td>\n",
       "      <td>992873810000</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>1230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:47:52.061465Z",
     "start_time": "2025-08-18T15:47:51.927542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splitting the datasets into train and test sets by user and time\n",
    "def stratified_temporal_split(dataframe, val_ratio=0.1, test_ratio=0.1):\n",
    "    dataframe = dataframe.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    grouped = dataframe.groupby(\"user_id\")\n",
    "\n",
    "    train_indices, val_indices, test_indices = [], [], []\n",
    "    for _, group in grouped:\n",
    "        n_records = len(group)\n",
    "        indices = group.index\n",
    "\n",
    "        # If user has less that 3 interactions, put all in training set\n",
    "        if n_records < 3:\n",
    "            train_indices.extend(indices)\n",
    "            continue\n",
    "\n",
    "        # Calculate split points\n",
    "        test_split_idx = int(n_records * (1 - test_ratio))\n",
    "        val_split_idx = int(n_records * (1 - test_ratio - val_ratio))\n",
    "\n",
    "        # Ensure validation set has at least one record if percentages are non-zero\n",
    "        if val_split_idx <= 0:\n",
    "            val_split_idx = 1\n",
    "\n",
    "        # Assign indices to respective sets\n",
    "        train_indices.extend(indices[:val_split_idx])\n",
    "        val_indices.extend(indices[val_split_idx:test_split_idx])\n",
    "        test_indices.extend(indices[test_split_idx:])\n",
    "\n",
    "    # Create the final datasets\n",
    "    train_df = dataframe.loc[train_indices].sort_values(\"timestamp\")\n",
    "    val_df = dataframe.loc[val_indices].sort_values(\"timestamp\")\n",
    "    test_df = dataframe.loc[test_indices].sort_values(\"timestamp\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train, val, test = stratified_temporal_split(df, val_ratio=0.2, test_ratio=0.1)"
   ],
   "id": "f94d443d32e11f9e",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:19:27.636752Z",
     "start_time": "2025-08-18T15:19:24.896033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def leave_one_out_split(dataframe):\n",
    "#     train, val, test = [], [], []\n",
    "#     for u, g in dataframe.sort_values(\"timestamp\").groupby(\"user_id\"):\n",
    "#         items = g[\"item_id\"].tolist()\n",
    "#         if len(items) < 3:\n",
    "#             train += g.to_dict(\"records\")\n",
    "#             continue\n",
    "#         train += g.iloc[:-2].to_dict(\"records\")\n",
    "#         val += [g.iloc[-2].to_dict]\n",
    "#         test += [g.iloc[-1].to_dict]\n",
    "#     return pd.DataFrame(train), pd.DataFrame(val), pd.DataFrame(test)\n",
    "#\n",
    "# train, val, test = leave_one_out_split(df)"
   ],
   "id": "9fe02881c5f54bbf",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:47:55.840882Z",
     "start_time": "2025-08-18T15:47:55.833883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_users = len(df[\"user_id\"].unique())\n",
    "n_items = len(df[\"item_id\"].unique())\n",
    "n_domains = len(df[\"domain\"].unique())"
   ],
   "id": "d1d8c675ce789382",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:35:59.143980Z",
     "start_time": "2025-08-18T15:35:59.102734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Domain-aware item key\n",
    "df[\"item_key\"] = df[\"domain\"].astype(str) + \"::\" + df[\"item\"].astype(str)\n",
    "\n",
    "# Map ids to continuous integers\n",
    "uid2ix = {u:i for i, u in enumerate(df[\"user\"].unique())}\n",
    "ix2uid = {i:u for u, i in uid2ix.items()}\n",
    "\n",
    "iid2ix = {it:i for i, it in enumerate(df[\"item_key\"].unique())}\n",
    "ix2iid = {i:it for it, i in iid2ix.items()}\n",
    "\n",
    "df[\"uid\"] = df[\"user\"].map(uid2ix)\n",
    "df[\"iid\"] = df[\"item_key\"].map(iid2ix)\n",
    "dom2ix = {d:i for i, d in enumerate(df[\"domain\"].unique())}\n",
    "df[\"did\"] = df[\"domain\"].map(dom2ix)"
   ],
   "id": "6df83c4e379da6f4",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sample_negative(u, n=1):\n",
    "    pool = []\n",
    "    while len(pool) < n:\n",
    "        cand = np.random.randint(0, )"
   ],
   "id": "a65f8690478ec3f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:18:18.649807Z",
     "start_time": "2025-08-18T15:18:18.645321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MFDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__()\n",
    "        self.df = dataframe[[\"user_id\", \"item_id\", \"label\"]].copy()\n",
    "        self.x_user_item = list(zip(self.df[\"user_id\"].values, self.df[\"item_id\"].values))\n",
    "        self.y_label = self.df[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_user_item[idx], self.y_label[idx]"
   ],
   "id": "101cb147b78b4624",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:57:00.771655Z",
     "start_time": "2025-08-18T15:57:00.750962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the dataset\n",
    "train_ds = MFDataset(train)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "valid_ds = MFDataset(val)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "xb, yb = next(iter(train_dataloader))\n",
    "print(xb)\n",
    "print(\"\\n\")\n",
    "print(yb)"
   ],
   "id": "77414032d8ddbbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2167,  292,  286, 1537, 2502, 1494,  712, 1774,  330,  262, 3253, 1652,\n",
      "        2373, 3214, 1238, 3371, 1087, 3963, 3127, 1290,  769, 1788, 3020,  828,\n",
      "        1130, 1991, 1106,  401, 3522,  325,  941, 3780, 1537, 2257, 3179, 2759,\n",
      "        1754, 3419, 1354, 3446, 2725, 2481, 2423, 2944, 1747,  625, 2622, 1650,\n",
      "        2313, 3963, 1517, 2536,  772,  333, 3769, 1745,  957, 1528, 1670, 3648,\n",
      "        3272, 3020, 1227, 3578,  402, 3929, 3725, 3396, 2148, 2350, 3412, 2055,\n",
      "        1656, 1046, 1239, 3123, 1751, 1235, 2711, 2514, 2153, 3316,  458, 2425,\n",
      "        1603, 1257, 1529, 2717,  679,  262, 4314, 1689, 3353, 2339, 3666, 2507,\n",
      "         247,   35, 1721, 3151, 2272, 2194, 2347, 3806, 3543, 3570, 1558, 1169,\n",
      "         308, 2478, 3335, 3788, 1133, 4131, 1237,  980, 1837, 1088,  146, 1597,\n",
      "        1959, 3574,  426, 1333, 3564, 1017, 2876, 1254]), tensor([3784,  710, 1486, 3071,  626, 1547, 1356, 3634,  742,  581, 3576, 3810,\n",
      "        4385, 2423, 3010, 2580, 2408, 2197, 1380, 2258, 2894, 2404, 2240, 3070,\n",
      "        3880, 1211, 4288, 2312, 2151, 4515, 2159, 1976, 2782, 1838,  377,  327,\n",
      "         549, 4320, 1076, 2258, 3889, 4163,  506, 2572,  538,  871, 3655, 3422,\n",
      "        3257, 2633, 2771, 2186, 2116, 1951, 2580, 1153, 2787, 2680, 4422, 1960,\n",
      "        1011, 2119, 1297, 2151, 3954, 3128, 1228,   20, 4134, 1851, 4273, 1480,\n",
      "        4063, 1440,  629, 1532, 1252, 3655, 2283, 1731, 2401, 4330, 3538, 2090,\n",
      "        3152, 3979, 1042, 1929, 2869, 1190, 4170, 1213, 3332, 2402, 1253, 3080,\n",
      "        1735,  820, 1121, 3998,  943,  992, 3587,  606,  930, 1707, 2605, 4153,\n",
      "        1916, 4712, 3114, 2033, 4286, 2406, 1455, 2850,  225, 4252, 4336, 4019,\n",
      "        2188, 1089, 4011, 3490,  436,  861, 1480, 1080])]\n",
      "\n",
      "\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T15:59:00.195052Z",
     "start_time": "2025-08-18T15:59:00.188563Z"
    }
   },
   "source": [
    "# Simple matrix factorization\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.02)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.02)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        ue = self.dropout(self.user_embedding(user_ids))\n",
    "        ie = self.dropout(self.item_embedding(item_ids))\n",
    "        dot = (ue * ie).sum(dim=1)\n",
    "        out = dot + self.user_bias(user_ids).squeeze(1) + self.item_bias(item_ids).squeeze(1)\n",
    "        return torch.sigmoid(out)"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:59:02.752947Z",
     "start_time": "2025-08-18T15:59:02.740927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_users = len(df[\"user_id\"].unique())\n",
    "n_items = len(df[\"item_id\"].unique())\n",
    "baseline = MatrixFactorization(n_users, n_items, embedding_dim=32)\n",
    "baseline.to(DEVICE)\n",
    "print(baseline)"
   ],
   "id": "fe20a6981927b344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (user_embedding): Embedding(4320, 32)\n",
      "  (item_embedding): Embedding(4736, 32)\n",
      "  (user_bias): Embedding(4320, 1)\n",
      "  (item_bias): Embedding(4736, 1)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T15:59:33.374464Z",
     "start_time": "2025-08-18T15:59:13.272711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "# Hyperparameters\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "optimizer = optim.Adam(baseline.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.BCELoss()\n",
    "epoch_train_losses, epoch_val_losses = [], []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train_losses = []\n",
    "    baseline.train()\n",
    "    for xb, yb in train_dataloader:\n",
    "        x_user = xb[0].to(DEVICE, dtype=torch.long)\n",
    "        x_item = xb[1].to(DEVICE, dtype=torch.long)\n",
    "        y_label = yb.to(DEVICE, dtype=torch.float)\n",
    "        preds = baseline(x_user, x_item)\n",
    "        loss = loss_fn(preds, y_label)\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    baseline.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in valid_dataloader:\n",
    "            x_user = xb[0].to(DEVICE, dtype=torch.long)\n",
    "            x_item = xb[1].to(DEVICE, dtype=torch.long)\n",
    "            y_label = yb.to(DEVICE, dtype=torch.float)\n",
    "            preds = baseline(x_user, x_item)\n",
    "            loss = loss_fn(preds, y_label)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    # Start logging\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_losses.append(epoch_train_loss)\n",
    "    epoch_val_losses.append(epoch_val_loss)\n",
    "    print(f\"Epoch {i+1}/{EPOCHS} - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")"
   ],
   "id": "7fbcd0042ec3bc13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.6581, Val Loss: 0.6228\n",
      "Epoch 2/50 - Train Loss: 0.5415, Val Loss: 0.5676\n",
      "Epoch 3/50 - Train Loss: 0.3718, Val Loss: 0.5361\n",
      "Epoch 4/50 - Train Loss: 0.2130, Val Loss: 0.5290\n",
      "Epoch 5/50 - Train Loss: 0.1178, Val Loss: 0.5357\n",
      "Epoch 6/50 - Train Loss: 0.0697, Val Loss: 0.5475\n",
      "Epoch 7/50 - Train Loss: 0.0471, Val Loss: 0.5601\n",
      "Epoch 8/50 - Train Loss: 0.0332, Val Loss: 0.5730\n",
      "Epoch 9/50 - Train Loss: 0.0260, Val Loss: 0.5856\n",
      "Epoch 10/50 - Train Loss: 0.0205, Val Loss: 0.5973\n",
      "Epoch 11/50 - Train Loss: 0.0172, Val Loss: 0.6089\n",
      "Epoch 12/50 - Train Loss: 0.0140, Val Loss: 0.6195\n",
      "Epoch 13/50 - Train Loss: 0.0123, Val Loss: 0.6300\n",
      "Epoch 14/50 - Train Loss: 0.0111, Val Loss: 0.6399\n",
      "Epoch 15/50 - Train Loss: 0.0103, Val Loss: 0.6503\n",
      "Epoch 16/50 - Train Loss: 0.0088, Val Loss: 0.6597\n",
      "Epoch 17/50 - Train Loss: 0.0083, Val Loss: 0.6688\n",
      "Epoch 18/50 - Train Loss: 0.0074, Val Loss: 0.6792\n",
      "Epoch 19/50 - Train Loss: 0.0077, Val Loss: 0.6886\n",
      "Epoch 20/50 - Train Loss: 0.0068, Val Loss: 0.6985\n",
      "Epoch 21/50 - Train Loss: 0.0065, Val Loss: 0.7072\n",
      "Epoch 22/50 - Train Loss: 0.0066, Val Loss: 0.7172\n",
      "Epoch 23/50 - Train Loss: 0.0056, Val Loss: 0.7259\n",
      "Epoch 24/50 - Train Loss: 0.0061, Val Loss: 0.7353\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[106]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m xb, yb \u001B[38;5;129;01min\u001B[39;00m valid_dataloader:\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m         x_user = \u001B[43mxb\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlong\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m         x_item = xb[\u001B[32m1\u001B[39m].to(DEVICE, dtype=torch.long)\n\u001B[32m     30\u001B[39m         y_label = yb.to(DEVICE, dtype=torch.float)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20d791a726a41272"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
